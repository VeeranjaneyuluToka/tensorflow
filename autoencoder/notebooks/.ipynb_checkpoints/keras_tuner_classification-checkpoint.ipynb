{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU: Setting GPU to: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vuu/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/vuu/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/vuu/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/vuu/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/vuu/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/vuu/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/vuu/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/vuu/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/vuu/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/vuu/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/vuu/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/vuu/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import setGPU\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from kerastuner import HyperModel\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten\n",
    "from kerastuner.tuners import (BayesianOptimization, Hyperband, RandomSearch)\n",
    "import tensorflow as tf\n",
    "\n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (32, 32, 3)\n",
    "NUM_CLASSES = 10\n",
    "SEED = 1\n",
    "MAX_TRIALS = 20\n",
    "EXECUTION_PER_TRIAL = 2\n",
    "HYPERBAND_MAX_EPOCHS = 40\n",
    "BAYESIAN_NUM_INITIAL_POINTS = 1\n",
    "N_EPOCH_SEARCH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    x_train = x_train.astype(\"float32\")/255.0\n",
    "    x_test = x_test.astype(\"float32\")/255.0\n",
    "\n",
    "    return x_test, x_train, y_test, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_gpu_config():\n",
    "    # Set up GPU config\n",
    "    logger.info(\"Setting up GPU if found\")\n",
    "    physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "    if physical_devices:\n",
    "        for device in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(Conv2D(filters = 16, kernel_size=3, activation='relu', input_shape=self.input_shape))\n",
    "        model.add(Conv2D(filters=16, activation='relu', kernel_size=3))\n",
    "        model.add(MaxPooling2D(pool_size=2))\n",
    "        model.add(Dropout(rate=hp.Float('dropout_1', min_value=0.0, max_value=0.5, default=0.25, step=0.05,)))\n",
    "        model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "        model.add(Conv2D(filters=hp.Choice(\"num_filters\", values=[32, 64], default=64,), activation='relu', kernel_size=3))\n",
    "        model.add(MaxPooling2D(pool_size=2))\n",
    "        model.add(Dropout(rate=hp.Float(\"dropout_2\", min_value=0.0, max_value=0.5, default=0.25, step=0.05,)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(units=hp.Int(\"units\", min_value=32, max_value=512, step=32, default=128), activation=\n",
    "                        hp.Choice(\"dense_activation\", values=['relu', 'tanh', \"sigmoid\"], default='relu'),))\n",
    "        model.add(Dropout(rate=hp.Float(\"dropout_3\", min_value=0.0, max_value=0.5, default=0.25, step=0.05)))\n",
    "        model.add(Dense(self.num_classes, activation=\"softmax\"))\n",
    "        model.compile(optimizer=keras.optimizers.Adam(hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling='LOG', default=1e-3)),\n",
    "                     loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_tuners(hypermodel, directory, project_name):\n",
    "    random_tuner = RandomSearch(hypermodel, objective='val_acc', seed=SEED, max_trials=MAX_TRIALS, executions_per_trial=EXECUTION_PER_TRIAL,\n",
    "                                directory=f\"{directory}_random_search\", project_name=project_name)\n",
    "    hyperband_tuner = Hyperband(hypermodel, max_epochs=HYPERBAND_MAX_EPOCHS, objective=\"val_acc\", seed=SEED, executions_per_trial=EXECUTION_PER_TRIAL,\n",
    "        directory=f\"{directory}_hyperband\", project_name=project_name,)\n",
    "    \n",
    "    bayesian_tuner = BayesianOptimization(hypermodel, objective='val_acc',seed=SEED, num_initial_points=BAYESIAN_NUM_INITIAL_POINTS,\n",
    "        max_trials=MAX_TRIALS, directory=f\"{directory}_bayesian\", project_name=project_name)\n",
    "    return [random_tuner, hyperband_tuner, bayesian_tuner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuner_evaluation(tuner, x_test, x_train, y_test, y_train):\n",
    "    set_gpu_config()\n",
    "\n",
    "    # Overview of the task\n",
    "    tuner.search_space_summary()\n",
    "\n",
    "    # Performs the hyperparameter tuning\n",
    "    logger.info(\"Start hyperparameter tuning\")\n",
    "    search_start = time.time()\n",
    "    tuner.search(x_train, y_train, epochs=N_EPOCH_SEARCH, validation_split=0.1)\n",
    "    search_end = time.time()\n",
    "    elapsed_time = search_end - search_start\n",
    "\n",
    "    # Show a summary of the search\n",
    "    tuner.results_summary()\n",
    "\n",
    "    # Retrieve the best model.\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "    # Evaluate the best model.\n",
    "    loss, accuracy = best_model.evaluate(x_test, y_test)\n",
    "    return elapsed_time, loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hyper_parameter_training():\n",
    "    x_test, x_train, y_test, y_train = load_data()\n",
    "    \n",
    "    #print(x_test.shape, x_train.shape, y_test.shape, y_train.shape)\n",
    "    hypermodel = CNNHyperModel(input_shape=INPUT_SHAPE, num_classes = NUM_CLASSES)\n",
    "    output_dir = Path(\"../../outputs/cifar10/\")\n",
    "    \n",
    "    tuners = define_tuners(hypermodel, directory=output_dir, project_name=\"simple_cnn_tuning\")\n",
    "    \n",
    "    results = []\n",
    "    for tuner in tuners:\n",
    "        elapsed_time, loss, accuracy = tuner_evaluation(tuner, x_test, x_train, y_test, y_train)\n",
    "        logger.info(f\"Elapsed time = {elapsed_time:10.4f} s, accuracy = {accuracy}, loss = {loss}\")\n",
    "        results.append([elapsed_time, loss, accuracy])\n",
    "    logger.info(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-14 15:24:45.134 | INFO     | __main__:set_gpu_config:3 - Setting up GPU if found\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Default search space size: 7</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dropout_1 (Float)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 0.05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">num_filters (Choice)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-ordered: True</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-values: [32, 64]</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dropout_2 (Float)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 0.05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">units (Int)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dense_activation (Choice)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-ordered: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-values: ['relu', 'tanh', 'sigmoid']</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dropout_3 (Float)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 0.05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">learning_rate (Float)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: log</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-14 15:24:45.163 | INFO     | __main__:tuner_evaluation:8 - Start hyperparameter tuning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/40\n",
      "44896/45000 [============================>.] - ETA: 32:33 - loss: 2.4394 - acc: 0.12 - ETA: 3:44 - loss: 2.4813 - acc: 0.1007 - ETA: 2:02 - loss: 2.4586 - acc: 0.106 - ETA: 1:29 - loss: 2.4371 - acc: 0.119 - ETA: 1:11 - loss: 2.4174 - acc: 0.126 - ETA: 59s - loss: 2.4223 - acc: 0.120 - ETA: 51s - loss: 2.4272 - acc: 0.11 - ETA: 46s - loss: 2.4184 - acc: 0.11 - ETA: 41s - loss: 2.3911 - acc: 0.12 - ETA: 38s - loss: 2.3799 - acc: 0.12 - ETA: 35s - loss: 2.3659 - acc: 0.13 - ETA: 32s - loss: 2.3565 - acc: 0.13 - ETA: 30s - loss: 2.3460 - acc: 0.13 - ETA: 29s - loss: 2.3352 - acc: 0.13 - ETA: 27s - loss: 2.3242 - acc: 0.13 - ETA: 26s - loss: 2.3149 - acc: 0.13 - ETA: 25s - loss: 2.3008 - acc: 0.14 - ETA: 24s - loss: 2.2891 - acc: 0.14 - ETA: 23s - loss: 2.2763 - acc: 0.15 - ETA: 22s - loss: 2.2632 - acc: 0.15 - ETA: 21s - loss: 2.2560 - acc: 0.16 - ETA: 21s - loss: 2.2489 - acc: 0.16 - ETA: 20s - loss: 2.2401 - acc: 0.16 - ETA: 19s - loss: 2.2308 - acc: 0.16 - ETA: 19s - loss: 2.2239 - acc: 0.17 - ETA: 18s - loss: 2.2186 - acc: 0.17 - ETA: 18s - loss: 2.2127 - acc: 0.17 - ETA: 18s - loss: 2.2049 - acc: 0.17 - ETA: 17s - loss: 2.1962 - acc: 0.18 - ETA: 17s - loss: 2.1897 - acc: 0.18 - ETA: 16s - loss: 2.1833 - acc: 0.18 - ETA: 16s - loss: 2.1782 - acc: 0.18 - ETA: 16s - loss: 2.1716 - acc: 0.19 - ETA: 15s - loss: 2.1668 - acc: 0.19 - ETA: 15s - loss: 2.1594 - acc: 0.19 - ETA: 15s - loss: 2.1566 - acc: 0.19 - ETA: 15s - loss: 2.1530 - acc: 0.20 - ETA: 14s - loss: 2.1466 - acc: 0.20 - ETA: 14s - loss: 2.1419 - acc: 0.20 - ETA: 14s - loss: 2.1373 - acc: 0.21 - ETA: 14s - loss: 2.1308 - acc: 0.21 - ETA: 13s - loss: 2.1253 - acc: 0.21 - ETA: 13s - loss: 2.1212 - acc: 0.21 - ETA: 13s - loss: 2.1155 - acc: 0.21 - ETA: 13s - loss: 2.1122 - acc: 0.21 - ETA: 13s - loss: 2.1063 - acc: 0.22 - ETA: 12s - loss: 2.1034 - acc: 0.22 - ETA: 12s - loss: 2.0981 - acc: 0.22 - ETA: 12s - loss: 2.0918 - acc: 0.22 - ETA: 12s - loss: 2.0875 - acc: 0.22 - ETA: 12s - loss: 2.0818 - acc: 0.23 - ETA: 12s - loss: 2.0754 - acc: 0.23 - ETA: 11s - loss: 2.0713 - acc: 0.23 - ETA: 11s - loss: 2.0688 - acc: 0.23 - ETA: 11s - loss: 2.0652 - acc: 0.23 - ETA: 11s - loss: 2.0600 - acc: 0.23 - ETA: 11s - loss: 2.0573 - acc: 0.24 - ETA: 11s - loss: 2.0531 - acc: 0.24 - ETA: 11s - loss: 2.0486 - acc: 0.24 - ETA: 10s - loss: 2.0439 - acc: 0.24 - ETA: 10s - loss: 2.0397 - acc: 0.24 - ETA: 10s - loss: 2.0364 - acc: 0.24 - ETA: 10s - loss: 2.0324 - acc: 0.25 - ETA: 10s - loss: 2.0298 - acc: 0.25 - ETA: 10s - loss: 2.0253 - acc: 0.25 - ETA: 10s - loss: 2.0226 - acc: 0.25 - ETA: 10s - loss: 2.0187 - acc: 0.25 - ETA: 9s - loss: 2.0147 - acc: 0.2565 - ETA: 9s - loss: 2.0135 - acc: 0.257 - ETA: 9s - loss: 2.0097 - acc: 0.258 - ETA: 9s - loss: 2.0057 - acc: 0.261 - ETA: 9s - loss: 2.0022 - acc: 0.262 - ETA: 9s - loss: 2.0004 - acc: 0.263 - ETA: 9s - loss: 1.9984 - acc: 0.263 - ETA: 9s - loss: 1.9959 - acc: 0.264 - ETA: 9s - loss: 1.9917 - acc: 0.266 - ETA: 8s - loss: 1.9885 - acc: 0.267 - ETA: 8s - loss: 1.9864 - acc: 0.267 - ETA: 8s - loss: 1.9831 - acc: 0.269 - ETA: 8s - loss: 1.9811 - acc: 0.270 - ETA: 8s - loss: 1.9777 - acc: 0.271 - ETA: 8s - loss: 1.9747 - acc: 0.272 - ETA: 8s - loss: 1.9729 - acc: 0.273 - ETA: 8s - loss: 1.9709 - acc: 0.274 - ETA: 8s - loss: 1.9685 - acc: 0.275 - ETA: 8s - loss: 1.9663 - acc: 0.276 - ETA: 7s - loss: 1.9637 - acc: 0.276 - ETA: 7s - loss: 1.9614 - acc: 0.277 - ETA: 7s - loss: 1.9601 - acc: 0.278 - ETA: 7s - loss: 1.9578 - acc: 0.279 - ETA: 7s - loss: 1.9551 - acc: 0.280 - ETA: 7s - loss: 1.9521 - acc: 0.281 - ETA: 7s - loss: 1.9507 - acc: 0.281 - ETA: 7s - loss: 1.9474 - acc: 0.282 - ETA: 7s - loss: 1.9456 - acc: 0.283 - ETA: 7s - loss: 1.9436 - acc: 0.284 - ETA: 7s - loss: 1.9408 - acc: 0.286 - ETA: 7s - loss: 1.9380 - acc: 0.287 - ETA: 6s - loss: 1.9360 - acc: 0.287 - ETA: 6s - loss: 1.9335 - acc: 0.288 - ETA: 6s - loss: 1.9322 - acc: 0.289 - ETA: 6s - loss: 1.9301 - acc: 0.290 - ETA: 6s - loss: 1.9271 - acc: 0.291 - ETA: 6s - loss: 1.9254 - acc: 0.291 - ETA: 6s - loss: 1.9227 - acc: 0.292 - ETA: 6s - loss: 1.9213 - acc: 0.293 - ETA: 6s - loss: 1.9189 - acc: 0.294 - ETA: 6s - loss: 1.9184 - acc: 0.294 - ETA: 6s - loss: 1.9174 - acc: 0.294 - ETA: 6s - loss: 1.9153 - acc: 0.295 - ETA: 5s - loss: 1.9134 - acc: 0.296 - ETA: 5s - loss: 1.9116 - acc: 0.297 - ETA: 5s - loss: 1.9107 - acc: 0.297 - ETA: 5s - loss: 1.9087 - acc: 0.298 - ETA: 5s - loss: 1.9073 - acc: 0.298 - ETA: 5s - loss: 1.9055 - acc: 0.299 - ETA: 5s - loss: 1.9028 - acc: 0.300 - ETA: 5s - loss: 1.9007 - acc: 0.301 - ETA: 5s - loss: 1.8995 - acc: 0.301 - ETA: 5s - loss: 1.8978 - acc: 0.302 - ETA: 5s - loss: 1.8961 - acc: 0.303 - ETA: 5s - loss: 1.8955 - acc: 0.303 - ETA: 5s - loss: 1.8946 - acc: 0.304 - ETA: 5s - loss: 1.8933 - acc: 0.304 - ETA: 4s - loss: 1.8916 - acc: 0.305 - ETA: 4s - loss: 1.8901 - acc: 0.306 - ETA: 4s - loss: 1.8886 - acc: 0.306 - ETA: 4s - loss: 1.8875 - acc: 0.307 - ETA: 4s - loss: 1.8860 - acc: 0.307 - ETA: 4s - loss: 1.8835 - acc: 0.308 - ETA: 4s - loss: 1.8822 - acc: 0.309 - ETA: 4s - loss: 1.8803 - acc: 0.310 - ETA: 4s - loss: 1.8791 - acc: 0.310 - ETA: 4s - loss: 1.8778 - acc: 0.311 - ETA: 4s - loss: 1.8761 - acc: 0.312 - ETA: 4s - loss: 1.8740 - acc: 0.312 - ETA: 4s - loss: 1.8727 - acc: 0.313 - ETA: 4s - loss: 1.8712 - acc: 0.313 - ETA: 4s - loss: 1.8695 - acc: 0.314 - ETA: 3s - loss: 1.8683 - acc: 0.314 - ETA: 3s - loss: 1.8674 - acc: 0.314 - ETA: 3s - loss: 1.8657 - acc: 0.315 - ETA: 3s - loss: 1.8645 - acc: 0.316 - ETA: 3s - loss: 1.8624 - acc: 0.316 - ETA: 3s - loss: 1.8617 - acc: 0.316 - ETA: 3s - loss: 1.8601 - acc: 0.317 - ETA: 3s - loss: 1.8589 - acc: 0.318 - ETA: 3s - loss: 1.8581 - acc: 0.318 - ETA: 3s - loss: 1.8571 - acc: 0.319 - ETA: 3s - loss: 1.8562 - acc: 0.319 - ETA: 3s - loss: 1.8553 - acc: 0.319 - ETA: 3s - loss: 1.8540 - acc: 0.320 - ETA: 3s - loss: 1.8524 - acc: 0.320 - ETA: 3s - loss: 1.8514 - acc: 0.321 - ETA: 2s - loss: 1.8509 - acc: 0.321 - ETA: 2s - loss: 1.8499 - acc: 0.321 - ETA: 2s - loss: 1.8492 - acc: 0.321 - ETA: 2s - loss: 1.8478 - acc: 0.322 - ETA: 2s - loss: 1.8463 - acc: 0.323 - ETA: 2s - loss: 1.8454 - acc: 0.323 - ETA: 2s - loss: 1.8445 - acc: 0.324 - ETA: 2s - loss: 1.8427 - acc: 0.324 - ETA: 2s - loss: 1.8418 - acc: 0.324 - ETA: 2s - loss: 1.8406 - acc: 0.325 - ETA: 2s - loss: 1.8397 - acc: 0.325 - ETA: 2s - loss: 1.8387 - acc: 0.326 - ETA: 2s - loss: 1.8370 - acc: 0.326 - ETA: 2s - loss: 1.8357 - acc: 0.327 - ETA: 2s - loss: 1.8341 - acc: 0.327 - ETA: 1s - loss: 1.8328 - acc: 0.328 - ETA: 1s - loss: 1.8313 - acc: 0.328 - ETA: 1s - loss: 1.8306 - acc: 0.328 - ETA: 1s - loss: 1.8295 - acc: 0.329 - ETA: 1s - loss: 1.8285 - acc: 0.329 - ETA: 1s - loss: 1.8275 - acc: 0.330 - ETA: 1s - loss: 1.8265 - acc: 0.330 - ETA: 1s - loss: 1.8258 - acc: 0.330 - ETA: 1s - loss: 1.8243 - acc: 0.331 - ETA: 1s - loss: 1.8230 - acc: 0.331 - ETA: 1s - loss: 1.8222 - acc: 0.332 - ETA: 1s - loss: 1.8211 - acc: 0.332 - ETA: 1s - loss: 1.8198 - acc: 0.332 - ETA: 1s - loss: 1.8187 - acc: 0.333 - ETA: 1s - loss: 1.8173 - acc: 0.333 - ETA: 1s - loss: 1.8163 - acc: 0.333 - ETA: 0s - loss: 1.8148 - acc: 0.334 - ETA: 0s - loss: 1.8140 - acc: 0.334 - ETA: 0s - loss: 1.8128 - acc: 0.335 - ETA: 0s - loss: 1.8120 - acc: 0.335 - ETA: 0s - loss: 1.8109 - acc: 0.336 - ETA: 0s - loss: 1.8100 - acc: 0.336 - ETA: 0s - loss: 1.8087 - acc: 0.336 - ETA: 0s - loss: 1.8076 - acc: 0.337 - ETA: 0s - loss: 1.8068 - acc: 0.337 - ETA: 0s - loss: 1.8054 - acc: 0.338 - ETA: 0s - loss: 1.8038 - acc: 0.338 - ETA: 0s - loss: 1.8023 - acc: 0.339 - ETA: 0s - loss: 1.8012 - acc: 0.340 - ETA: 0s - loss: 1.8005 - acc: 0.340 - ETA: 0s - loss: 1.7999 - acc: 0.340 - ETA: 0s - loss: 1.7987 - acc: 0.3403WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "45000/45000 [==============================] - 13s 289us/sample - loss: 1.7984 - acc: 0.3405 - val_loss: 1.5237 - val_acc: 0.4432\n",
      "Epoch 2/40\n",
      "44832/45000 [============================>.] - ETA: 15s - loss: 1.3886 - acc: 0.40 - ETA: 11s - loss: 1.6456 - acc: 0.41 - ETA: 10s - loss: 1.6385 - acc: 0.41 - ETA: 10s - loss: 1.6434 - acc: 0.40 - ETA: 10s - loss: 1.6242 - acc: 0.40 - ETA: 10s - loss: 1.6360 - acc: 0.40 - ETA: 10s - loss: 1.6259 - acc: 0.40 - ETA: 10s - loss: 1.6104 - acc: 0.41 - ETA: 10s - loss: 1.5928 - acc: 0.42 - ETA: 10s - loss: 1.6024 - acc: 0.42 - ETA: 10s - loss: 1.5920 - acc: 0.42 - ETA: 10s - loss: 1.5932 - acc: 0.42 - ETA: 10s - loss: 1.5941 - acc: 0.42 - ETA: 10s - loss: 1.6014 - acc: 0.41 - ETA: 9s - loss: 1.6025 - acc: 0.4195 - ETA: 9s - loss: 1.5971 - acc: 0.419 - ETA: 9s - loss: 1.5920 - acc: 0.423 - ETA: 9s - loss: 1.5960 - acc: 0.419 - ETA: 9s - loss: 1.5936 - acc: 0.420 - ETA: 9s - loss: 1.5911 - acc: 0.420 - ETA: 9s - loss: 1.5896 - acc: 0.424 - ETA: 9s - loss: 1.5929 - acc: 0.421 - ETA: 9s - loss: 1.5914 - acc: 0.423 - ETA: 9s - loss: 1.5900 - acc: 0.423 - ETA: 9s - loss: 1.5878 - acc: 0.425 - ETA: 9s - loss: 1.5846 - acc: 0.426 - ETA: 9s - loss: 1.5860 - acc: 0.427 - ETA: 9s - loss: 1.5832 - acc: 0.427 - ETA: 9s - loss: 1.5860 - acc: 0.426 - ETA: 9s - loss: 1.5830 - acc: 0.428 - ETA: 9s - loss: 1.5823 - acc: 0.429 - ETA: 9s - loss: 1.5797 - acc: 0.429 - ETA: 9s - loss: 1.5807 - acc: 0.429 - ETA: 9s - loss: 1.5805 - acc: 0.427 - ETA: 8s - loss: 1.5786 - acc: 0.428 - ETA: 8s - loss: 1.5807 - acc: 0.427 - ETA: 8s - loss: 1.5813 - acc: 0.427 - ETA: 8s - loss: 1.5833 - acc: 0.427 - ETA: 8s - loss: 1.5855 - acc: 0.426 - ETA: 8s - loss: 1.5851 - acc: 0.426 - ETA: 8s - loss: 1.5831 - acc: 0.427 - ETA: 8s - loss: 1.5810 - acc: 0.427 - ETA: 8s - loss: 1.5832 - acc: 0.426 - ETA: 8s - loss: 1.5835 - acc: 0.426 - ETA: 8s - loss: 1.5846 - acc: 0.425 - ETA: 8s - loss: 1.5864 - acc: 0.424 - ETA: 8s - loss: 1.5845 - acc: 0.424 - ETA: 8s - loss: 1.5840 - acc: 0.424 - ETA: 8s - loss: 1.5850 - acc: 0.424 - ETA: 8s - loss: 1.5847 - acc: 0.424 - ETA: 8s - loss: 1.5830 - acc: 0.425 - ETA: 8s - loss: 1.5827 - acc: 0.425 - ETA: 7s - loss: 1.5813 - acc: 0.425 - ETA: 7s - loss: 1.5790 - acc: 0.427 - ETA: 7s - loss: 1.5789 - acc: 0.426 - ETA: 7s - loss: 1.5773 - acc: 0.427 - ETA: 7s - loss: 1.5761 - acc: 0.428 - ETA: 7s - loss: 1.5755 - acc: 0.427 - ETA: 7s - loss: 1.5739 - acc: 0.429 - ETA: 7s - loss: 1.5712 - acc: 0.430 - ETA: 7s - loss: 1.5686 - acc: 0.431 - ETA: 7s - loss: 1.5684 - acc: 0.431 - ETA: 7s - loss: 1.5673 - acc: 0.431 - ETA: 7s - loss: 1.5659 - acc: 0.431 - ETA: 7s - loss: 1.5651 - acc: 0.431 - ETA: 7s - loss: 1.5642 - acc: 0.431 - ETA: 7s - loss: 1.5641 - acc: 0.432 - ETA: 7s - loss: 1.5622 - acc: 0.432 - ETA: 7s - loss: 1.5621 - acc: 0.432 - ETA: 7s - loss: 1.5603 - acc: 0.433 - ETA: 7s - loss: 1.5588 - acc: 0.433 - ETA: 6s - loss: 1.5576 - acc: 0.434 - ETA: 6s - loss: 1.5577 - acc: 0.433 - ETA: 6s - loss: 1.5571 - acc: 0.433 - ETA: 6s - loss: 1.5565 - acc: 0.434 - ETA: 6s - loss: 1.5546 - acc: 0.434 - ETA: 6s - loss: 1.5538 - acc: 0.434 - ETA: 6s - loss: 1.5536 - acc: 0.434 - ETA: 6s - loss: 1.5537 - acc: 0.433 - ETA: 6s - loss: 1.5520 - acc: 0.434 - ETA: 6s - loss: 1.5504 - acc: 0.434 - ETA: 6s - loss: 1.5501 - acc: 0.434 - ETA: 6s - loss: 1.5508 - acc: 0.434 - ETA: 6s - loss: 1.5505 - acc: 0.434 - ETA: 6s - loss: 1.5498 - acc: 0.435 - ETA: 6s - loss: 1.5496 - acc: 0.435 - ETA: 6s - loss: 1.5489 - acc: 0.435 - ETA: 6s - loss: 1.5482 - acc: 0.436 - ETA: 6s - loss: 1.5481 - acc: 0.435 - ETA: 5s - loss: 1.5465 - acc: 0.436 - ETA: 5s - loss: 1.5452 - acc: 0.436 - ETA: 5s - loss: 1.5459 - acc: 0.436 - ETA: 5s - loss: 1.5460 - acc: 0.436 - ETA: 5s - loss: 1.5458 - acc: 0.436 - ETA: 5s - loss: 1.5465 - acc: 0.436 - ETA: 5s - loss: 1.5461 - acc: 0.436 - ETA: 5s - loss: 1.5453 - acc: 0.436 - ETA: 5s - loss: 1.5443 - acc: 0.437 - ETA: 5s - loss: 1.5435 - acc: 0.437 - ETA: 5s - loss: 1.5432 - acc: 0.437 - ETA: 5s - loss: 1.5421 - acc: 0.438 - ETA: 5s - loss: 1.5427 - acc: 0.437 - ETA: 5s - loss: 1.5427 - acc: 0.437 - ETA: 5s - loss: 1.5417 - acc: 0.438 - ETA: 5s - loss: 1.5408 - acc: 0.438 - ETA: 5s - loss: 1.5409 - acc: 0.438 - ETA: 5s - loss: 1.5411 - acc: 0.438 - ETA: 5s - loss: 1.5406 - acc: 0.438 - ETA: 4s - loss: 1.5406 - acc: 0.438 - ETA: 4s - loss: 1.5406 - acc: 0.438 - ETA: 4s - loss: 1.5401 - acc: 0.438 - ETA: 4s - loss: 1.5390 - acc: 0.438 - ETA: 4s - loss: 1.5398 - acc: 0.438 - ETA: 4s - loss: 1.5399 - acc: 0.438 - ETA: 4s - loss: 1.5399 - acc: 0.437 - ETA: 4s - loss: 1.5400 - acc: 0.438 - ETA: 4s - loss: 1.5395 - acc: 0.438 - ETA: 4s - loss: 1.5396 - acc: 0.438 - ETA: 4s - loss: 1.5392 - acc: 0.438 - ETA: 4s - loss: 1.5385 - acc: 0.439 - ETA: 4s - loss: 1.5381 - acc: 0.439 - ETA: 4s - loss: 1.5371 - acc: 0.439 - ETA: 4s - loss: 1.5372 - acc: 0.439 - ETA: 4s - loss: 1.5368 - acc: 0.439 - ETA: 4s - loss: 1.5363 - acc: 0.439 - ETA: 4s - loss: 1.5362 - acc: 0.439 - ETA: 4s - loss: 1.5359 - acc: 0.439 - ETA: 3s - loss: 1.5351 - acc: 0.439 - ETA: 3s - loss: 1.5350 - acc: 0.439 - ETA: 3s - loss: 1.5346 - acc: 0.439 - ETA: 3s - loss: 1.5345 - acc: 0.439 - ETA: 3s - loss: 1.5346 - acc: 0.439 - ETA: 3s - loss: 1.5345 - acc: 0.439 - ETA: 3s - loss: 1.5343 - acc: 0.439 - ETA: 3s - loss: 1.5338 - acc: 0.440 - ETA: 3s - loss: 1.5334 - acc: 0.440 - ETA: 3s - loss: 1.5327 - acc: 0.440 - ETA: 3s - loss: 1.5318 - acc: 0.440 - ETA: 3s - loss: 1.5316 - acc: 0.440 - ETA: 3s - loss: 1.5306 - acc: 0.441 - ETA: 3s - loss: 1.5295 - acc: 0.441 - ETA: 3s - loss: 1.5289 - acc: 0.441 - ETA: 3s - loss: 1.5280 - acc: 0.441 - ETA: 3s - loss: 1.5276 - acc: 0.442 - ETA: 3s - loss: 1.5277 - acc: 0.442 - ETA: 2s - loss: 1.5274 - acc: 0.442 - ETA: 2s - loss: 1.5271 - acc: 0.442 - ETA: 2s - loss: 1.5266 - acc: 0.442 - ETA: 2s - loss: 1.5262 - acc: 0.442 - ETA: 2s - loss: 1.5262 - acc: 0.442 - ETA: 2s - loss: 1.5258 - acc: 0.442 - ETA: 2s - loss: 1.5248 - acc: 0.443 - ETA: 2s - loss: 1.5241 - acc: 0.443 - ETA: 2s - loss: 1.5235 - acc: 0.443 - ETA: 2s - loss: 1.5224 - acc: 0.443 - ETA: 2s - loss: 1.5213 - acc: 0.444 - ETA: 2s - loss: 1.5221 - acc: 0.443 - ETA: 2s - loss: 1.5222 - acc: 0.444 - ETA: 2s - loss: 1.5215 - acc: 0.444 - ETA: 2s - loss: 1.5210 - acc: 0.444 - ETA: 2s - loss: 1.5207 - acc: 0.444 - ETA: 2s - loss: 1.5203 - acc: 0.445 - ETA: 2s - loss: 1.5200 - acc: 0.445 - ETA: 2s - loss: 1.5197 - acc: 0.445 - ETA: 1s - loss: 1.5193 - acc: 0.445 - ETA: 1s - loss: 1.5188 - acc: 0.445 - ETA: 1s - loss: 1.5187 - acc: 0.445 - ETA: 1s - loss: 1.5178 - acc: 0.446 - ETA: 1s - loss: 1.5171 - acc: 0.446 - ETA: 1s - loss: 1.5167 - acc: 0.446 - ETA: 1s - loss: 1.5163 - acc: 0.446 - ETA: 1s - loss: 1.5169 - acc: 0.446 - ETA: 1s - loss: 1.5161 - acc: 0.446 - ETA: 1s - loss: 1.5156 - acc: 0.446 - ETA: 1s - loss: 1.5146 - acc: 0.447 - ETA: 1s - loss: 1.5138 - acc: 0.447 - ETA: 1s - loss: 1.5128 - acc: 0.448 - ETA: 1s - loss: 1.5125 - acc: 0.447 - ETA: 1s - loss: 1.5124 - acc: 0.447 - ETA: 1s - loss: 1.5118 - acc: 0.448 - ETA: 1s - loss: 1.5112 - acc: 0.448 - ETA: 1s - loss: 1.5109 - acc: 0.448 - ETA: 1s - loss: 1.5105 - acc: 0.448 - ETA: 0s - loss: 1.5097 - acc: 0.448 - ETA: 0s - loss: 1.5092 - acc: 0.449 - ETA: 0s - loss: 1.5088 - acc: 0.449 - ETA: 0s - loss: 1.5086 - acc: 0.449 - ETA: 0s - loss: 1.5087 - acc: 0.449 - ETA: 0s - loss: 1.5091 - acc: 0.449 - ETA: 0s - loss: 1.5091 - acc: 0.449 - ETA: 0s - loss: 1.5087 - acc: 0.449 - ETA: 0s - loss: 1.5086 - acc: 0.449 - ETA: 0s - loss: 1.5083 - acc: 0.449 - ETA: 0s - loss: 1.5081 - acc: 0.449 - ETA: 0s - loss: 1.5078 - acc: 0.450 - ETA: 0s - loss: 1.5072 - acc: 0.450 - ETA: 0s - loss: 1.5070 - acc: 0.450 - ETA: 0s - loss: 1.5070 - acc: 0.450 - ETA: 0s - loss: 1.5067 - acc: 0.450 - ETA: 0s - loss: 1.5059 - acc: 0.450 - ETA: 0s - loss: 1.5053 - acc: 0.4511WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "45000/45000 [==============================] - 11s 253us/sample - loss: 1.5049 - acc: 0.4513 - val_loss: 1.3490 - val_acc: 0.5092\n",
      "Epoch 3/40\n",
      "44832/45000 [============================>.] - ETA: 14s - loss: 1.5118 - acc: 0.50 - ETA: 10s - loss: 1.3558 - acc: 0.48 - ETA: 10s - loss: 1.4123 - acc: 0.48 - ETA: 10s - loss: 1.4361 - acc: 0.47 - ETA: 10s - loss: 1.4211 - acc: 0.47 - ETA: 10s - loss: 1.4041 - acc: 0.48 - ETA: 10s - loss: 1.4027 - acc: 0.48 - ETA: 10s - loss: 1.3977 - acc: 0.49 - ETA: 10s - loss: 1.3913 - acc: 0.50 - ETA: 10s - loss: 1.3920 - acc: 0.50 - ETA: 10s - loss: 1.3965 - acc: 0.49 - ETA: 10s - loss: 1.3987 - acc: 0.49 - ETA: 10s - loss: 1.3969 - acc: 0.49 - ETA: 10s - loss: 1.3986 - acc: 0.49 - ETA: 9s - loss: 1.4010 - acc: 0.4956 - ETA: 9s - loss: 1.4031 - acc: 0.497 - ETA: 9s - loss: 1.4022 - acc: 0.497 - ETA: 9s - loss: 1.4058 - acc: 0.493 - ETA: 9s - loss: 1.4046 - acc: 0.492 - ETA: 9s - loss: 1.4015 - acc: 0.494 - ETA: 9s - loss: 1.4056 - acc: 0.492 - ETA: 9s - loss: 1.4102 - acc: 0.490 - ETA: 9s - loss: 1.4085 - acc: 0.490 - ETA: 9s - loss: 1.4061 - acc: 0.490 - ETA: 9s - loss: 1.4089 - acc: 0.491 - ETA: 9s - loss: 1.4100 - acc: 0.491 - ETA: 9s - loss: 1.4099 - acc: 0.491 - ETA: 9s - loss: 1.4090 - acc: 0.491 - ETA: 9s - loss: 1.4103 - acc: 0.490 - ETA: 9s - loss: 1.4123 - acc: 0.489 - ETA: 9s - loss: 1.4110 - acc: 0.489 - ETA: 9s - loss: 1.4112 - acc: 0.488 - ETA: 9s - loss: 1.4080 - acc: 0.489 - ETA: 9s - loss: 1.4068 - acc: 0.489 - ETA: 8s - loss: 1.4074 - acc: 0.489 - ETA: 8s - loss: 1.4049 - acc: 0.491 - ETA: 8s - loss: 1.4033 - acc: 0.491 - ETA: 8s - loss: 1.3992 - acc: 0.493 - ETA: 8s - loss: 1.3971 - acc: 0.493 - ETA: 8s - loss: 1.3951 - acc: 0.494 - ETA: 8s - loss: 1.3946 - acc: 0.496 - ETA: 8s - loss: 1.3968 - acc: 0.496 - ETA: 8s - loss: 1.3962 - acc: 0.496 - ETA: 8s - loss: 1.3963 - acc: 0.496 - ETA: 8s - loss: 1.3960 - acc: 0.496 - ETA: 8s - loss: 1.3971 - acc: 0.496 - ETA: 8s - loss: 1.3978 - acc: 0.495 - ETA: 8s - loss: 1.3971 - acc: 0.495 - ETA: 8s - loss: 1.3966 - acc: 0.495 - ETA: 8s - loss: 1.3949 - acc: 0.496 - ETA: 8s - loss: 1.3956 - acc: 0.496 - ETA: 8s - loss: 1.3953 - acc: 0.497 - ETA: 7s - loss: 1.3953 - acc: 0.496 - ETA: 7s - loss: 1.3941 - acc: 0.497 - ETA: 7s - loss: 1.3941 - acc: 0.498 - ETA: 7s - loss: 1.3948 - acc: 0.498 - ETA: 7s - loss: 1.3935 - acc: 0.498 - ETA: 7s - loss: 1.3912 - acc: 0.499 - ETA: 7s - loss: 1.3905 - acc: 0.499 - ETA: 7s - loss: 1.3899 - acc: 0.499 - ETA: 7s - loss: 1.3881 - acc: 0.500 - ETA: 7s - loss: 1.3889 - acc: 0.499 - ETA: 7s - loss: 1.3894 - acc: 0.499 - ETA: 7s - loss: 1.3917 - acc: 0.499 - ETA: 7s - loss: 1.3916 - acc: 0.498 - ETA: 7s - loss: 1.3922 - acc: 0.498 - ETA: 7s - loss: 1.3924 - acc: 0.497 - ETA: 7s - loss: 1.3939 - acc: 0.497 - ETA: 7s - loss: 1.3929 - acc: 0.498 - ETA: 7s - loss: 1.3930 - acc: 0.498 - ETA: 7s - loss: 1.3935 - acc: 0.499 - ETA: 6s - loss: 1.3949 - acc: 0.498 - ETA: 6s - loss: 1.3945 - acc: 0.498 - ETA: 6s - loss: 1.3965 - acc: 0.497 - ETA: 6s - loss: 1.3964 - acc: 0.497 - ETA: 6s - loss: 1.3970 - acc: 0.497 - ETA: 6s - loss: 1.3975 - acc: 0.497 - ETA: 6s - loss: 1.3981 - acc: 0.496 - ETA: 6s - loss: 1.3993 - acc: 0.496 - ETA: 6s - loss: 1.3996 - acc: 0.496 - ETA: 6s - loss: 1.3993 - acc: 0.497 - ETA: 6s - loss: 1.3993 - acc: 0.497 - ETA: 6s - loss: 1.3994 - acc: 0.496 - ETA: 6s - loss: 1.3996 - acc: 0.496 - ETA: 6s - loss: 1.3987 - acc: 0.497 - ETA: 6s - loss: 1.3992 - acc: 0.496 - ETA: 6s - loss: 1.3990 - acc: 0.496 - ETA: 6s - loss: 1.3996 - acc: 0.496 - ETA: 6s - loss: 1.4001 - acc: 0.496 - ETA: 5s - loss: 1.3985 - acc: 0.497 - ETA: 5s - loss: 1.3976 - acc: 0.497 - ETA: 5s - loss: 1.3980 - acc: 0.497 - ETA: 5s - loss: 1.3975 - acc: 0.497 - ETA: 5s - loss: 1.3964 - acc: 0.498 - ETA: 5s - loss: 1.3971 - acc: 0.498 - ETA: 5s - loss: 1.3976 - acc: 0.497 - ETA: 5s - loss: 1.3980 - acc: 0.497 - ETA: 5s - loss: 1.3982 - acc: 0.497 - ETA: 5s - loss: 1.3990 - acc: 0.497 - ETA: 5s - loss: 1.3983 - acc: 0.497 - ETA: 5s - loss: 1.3978 - acc: 0.497 - ETA: 5s - loss: 1.3977 - acc: 0.497 - ETA: 5s - loss: 1.3978 - acc: 0.497 - ETA: 5s - loss: 1.3975 - acc: 0.497 - ETA: 5s - loss: 1.3970 - acc: 0.497 - ETA: 5s - loss: 1.3966 - acc: 0.498 - ETA: 5s - loss: 1.3956 - acc: 0.498 - ETA: 5s - loss: 1.3954 - acc: 0.499 - ETA: 4s - loss: 1.3949 - acc: 0.499 - ETA: 4s - loss: 1.3951 - acc: 0.499 - ETA: 4s - loss: 1.3943 - acc: 0.499 - ETA: 4s - loss: 1.3940 - acc: 0.499 - ETA: 4s - loss: 1.3943 - acc: 0.498 - ETA: 4s - loss: 1.3944 - acc: 0.498 - ETA: 4s - loss: 1.3947 - acc: 0.498 - ETA: 4s - loss: 1.3942 - acc: 0.498 - ETA: 4s - loss: 1.3944 - acc: 0.498 - ETA: 4s - loss: 1.3943 - acc: 0.498 - ETA: 4s - loss: 1.3947 - acc: 0.498 - ETA: 4s - loss: 1.3951 - acc: 0.497 - ETA: 4s - loss: 1.3944 - acc: 0.497 - ETA: 4s - loss: 1.3945 - acc: 0.497 - ETA: 4s - loss: 1.3946 - acc: 0.497 - ETA: 4s - loss: 1.3937 - acc: 0.497 - ETA: 4s - loss: 1.3936 - acc: 0.497 - ETA: 4s - loss: 1.3942 - acc: 0.497 - ETA: 4s - loss: 1.3940 - acc: 0.497 - ETA: 3s - loss: 1.3938 - acc: 0.497 - ETA: 3s - loss: 1.3927 - acc: 0.498 - ETA: 3s - loss: 1.3923 - acc: 0.498 - ETA: 3s - loss: 1.3927 - acc: 0.497 - ETA: 3s - loss: 1.3922 - acc: 0.498 - ETA: 3s - loss: 1.3926 - acc: 0.498 - ETA: 3s - loss: 1.3921 - acc: 0.498 - ETA: 3s - loss: 1.3924 - acc: 0.498 - ETA: 3s - loss: 1.3924 - acc: 0.498 - ETA: 3s - loss: 1.3919 - acc: 0.499 - ETA: 3s - loss: 1.3906 - acc: 0.499 - ETA: 3s - loss: 1.3905 - acc: 0.499 - ETA: 3s - loss: 1.3908 - acc: 0.499 - ETA: 3s - loss: 1.3903 - acc: 0.499 - ETA: 3s - loss: 1.3894 - acc: 0.500 - ETA: 3s - loss: 1.3886 - acc: 0.500 - ETA: 3s - loss: 1.3888 - acc: 0.500 - ETA: 3s - loss: 1.3889 - acc: 0.500 - ETA: 2s - loss: 1.3889 - acc: 0.500 - ETA: 2s - loss: 1.3885 - acc: 0.500 - ETA: 2s - loss: 1.3875 - acc: 0.500 - ETA: 2s - loss: 1.3871 - acc: 0.500 - ETA: 2s - loss: 1.3879 - acc: 0.500 - ETA: 2s - loss: 1.3879 - acc: 0.500 - ETA: 2s - loss: 1.3879 - acc: 0.500 - ETA: 2s - loss: 1.3878 - acc: 0.500 - ETA: 2s - loss: 1.3867 - acc: 0.500 - ETA: 2s - loss: 1.3867 - acc: 0.500 - ETA: 2s - loss: 1.3868 - acc: 0.501 - ETA: 2s - loss: 1.3863 - acc: 0.501 - ETA: 2s - loss: 1.3860 - acc: 0.501 - ETA: 2s - loss: 1.3855 - acc: 0.501 - ETA: 2s - loss: 1.3853 - acc: 0.501 - ETA: 2s - loss: 1.3844 - acc: 0.502 - ETA: 2s - loss: 1.3847 - acc: 0.501 - ETA: 2s - loss: 1.3842 - acc: 0.502 - ETA: 2s - loss: 1.3843 - acc: 0.502 - ETA: 1s - loss: 1.3850 - acc: 0.502 - ETA: 1s - loss: 1.3849 - acc: 0.501 - ETA: 1s - loss: 1.3849 - acc: 0.501 - ETA: 1s - loss: 1.3849 - acc: 0.501 - ETA: 1s - loss: 1.3851 - acc: 0.501 - ETA: 1s - loss: 1.3851 - acc: 0.501 - ETA: 1s - loss: 1.3857 - acc: 0.501 - ETA: 1s - loss: 1.3857 - acc: 0.501 - ETA: 1s - loss: 1.3853 - acc: 0.501 - ETA: 1s - loss: 1.3849 - acc: 0.501 - ETA: 1s - loss: 1.3848 - acc: 0.501 - ETA: 1s - loss: 1.3848 - acc: 0.501 - ETA: 1s - loss: 1.3845 - acc: 0.501 - ETA: 1s - loss: 1.3839 - acc: 0.502 - ETA: 1s - loss: 1.3838 - acc: 0.502 - ETA: 1s - loss: 1.3832 - acc: 0.502 - ETA: 1s - loss: 1.3833 - acc: 0.502 - ETA: 1s - loss: 1.3831 - acc: 0.502 - ETA: 1s - loss: 1.3830 - acc: 0.502 - ETA: 0s - loss: 1.3827 - acc: 0.502 - ETA: 0s - loss: 1.3826 - acc: 0.502 - ETA: 0s - loss: 1.3818 - acc: 0.502 - ETA: 0s - loss: 1.3820 - acc: 0.502 - ETA: 0s - loss: 1.3812 - acc: 0.502 - ETA: 0s - loss: 1.3805 - acc: 0.503 - ETA: 0s - loss: 1.3802 - acc: 0.503 - ETA: 0s - loss: 1.3800 - acc: 0.503 - ETA: 0s - loss: 1.3796 - acc: 0.503 - ETA: 0s - loss: 1.3793 - acc: 0.503 - ETA: 0s - loss: 1.3783 - acc: 0.504 - ETA: 0s - loss: 1.3782 - acc: 0.504 - ETA: 0s - loss: 1.3778 - acc: 0.504 - ETA: 0s - loss: 1.3773 - acc: 0.504 - ETA: 0s - loss: 1.3773 - acc: 0.504 - ETA: 0s - loss: 1.3769 - acc: 0.504 - ETA: 0s - loss: 1.3770 - acc: 0.504 - ETA: 0s - loss: 1.3768 - acc: 0.5046WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "45000/45000 [==============================] - 11s 254us/sample - loss: 1.3770 - acc: 0.5048 - val_loss: 1.2488 - val_acc: 0.5472\n",
      "Epoch 4/40\n",
      "44832/45000 [============================>.] - ETA: 14s - loss: 1.3599 - acc: 0.50 - ETA: 10s - loss: 1.2568 - acc: 0.54 - ETA: 10s - loss: 1.2605 - acc: 0.53 - ETA: 10s - loss: 1.2844 - acc: 0.53 - ETA: 10s - loss: 1.3033 - acc: 0.52 - ETA: 10s - loss: 1.3043 - acc: 0.51 - ETA: 10s - loss: 1.2944 - acc: 0.52 - ETA: 10s - loss: 1.2763 - acc: 0.53 - ETA: 10s - loss: 1.2854 - acc: 0.53 - ETA: 10s - loss: 1.2764 - acc: 0.53 - ETA: 10s - loss: 1.2855 - acc: 0.53 - ETA: 10s - loss: 1.2917 - acc: 0.53 - ETA: 10s - loss: 1.2934 - acc: 0.53 - ETA: 10s - loss: 1.2975 - acc: 0.53 - ETA: 10s - loss: 1.3039 - acc: 0.53 - ETA: 9s - loss: 1.3057 - acc: 0.5333 - ETA: 9s - loss: 1.3039 - acc: 0.537 - ETA: 9s - loss: 1.3038 - acc: 0.538 - ETA: 9s - loss: 1.2993 - acc: 0.538 - ETA: 9s - loss: 1.2999 - acc: 0.538 - ETA: 9s - loss: 1.3064 - acc: 0.538 - ETA: 9s - loss: 1.3045 - acc: 0.539 - ETA: 9s - loss: 1.3061 - acc: 0.538 - ETA: 9s - loss: 1.3084 - acc: 0.536 - ETA: 9s - loss: 1.3026 - acc: 0.537 - ETA: 9s - loss: 1.3028 - acc: 0.535 - ETA: 9s - loss: 1.2962 - acc: 0.538 - ETA: 9s - loss: 1.2956 - acc: 0.539 - ETA: 9s - loss: 1.2961 - acc: 0.537 - ETA: 9s - loss: 1.2928 - acc: 0.539 - ETA: 9s - loss: 1.2923 - acc: 0.539 - ETA: 9s - loss: 1.2928 - acc: 0.538 - ETA: 9s - loss: 1.2911 - acc: 0.537 - ETA: 9s - loss: 1.2932 - acc: 0.537 - ETA: 8s - loss: 1.2956 - acc: 0.535 - ETA: 8s - loss: 1.2973 - acc: 0.535 - ETA: 8s - loss: 1.2954 - acc: 0.535 - ETA: 8s - loss: 1.2968 - acc: 0.534 - ETA: 8s - loss: 1.2988 - acc: 0.533 - ETA: 8s - loss: 1.3016 - acc: 0.532 - ETA: 8s - loss: 1.3046 - acc: 0.530 - ETA: 8s - loss: 1.3049 - acc: 0.530 - ETA: 8s - loss: 1.3071 - acc: 0.529 - ETA: 8s - loss: 1.3069 - acc: 0.529 - ETA: 8s - loss: 1.3054 - acc: 0.529 - ETA: 8s - loss: 1.3038 - acc: 0.530 - ETA: 8s - loss: 1.3061 - acc: 0.529 - ETA: 8s - loss: 1.3094 - acc: 0.528 - ETA: 8s - loss: 1.3069 - acc: 0.529 - ETA: 8s - loss: 1.3054 - acc: 0.530 - ETA: 8s - loss: 1.3075 - acc: 0.529 - ETA: 8s - loss: 1.3063 - acc: 0.529 - ETA: 8s - loss: 1.3075 - acc: 0.529 - ETA: 7s - loss: 1.3066 - acc: 0.529 - ETA: 7s - loss: 1.3077 - acc: 0.528 - ETA: 7s - loss: 1.3091 - acc: 0.528 - ETA: 7s - loss: 1.3081 - acc: 0.528 - ETA: 7s - loss: 1.3103 - acc: 0.527 - ETA: 7s - loss: 1.3098 - acc: 0.528 - ETA: 7s - loss: 1.3106 - acc: 0.528 - ETA: 7s - loss: 1.3111 - acc: 0.528 - ETA: 7s - loss: 1.3093 - acc: 0.529 - ETA: 7s - loss: 1.3104 - acc: 0.528 - ETA: 7s - loss: 1.3124 - acc: 0.528 - ETA: 7s - loss: 1.3104 - acc: 0.529 - ETA: 7s - loss: 1.3111 - acc: 0.529 - ETA: 7s - loss: 1.3125 - acc: 0.528 - ETA: 7s - loss: 1.3132 - acc: 0.528 - ETA: 7s - loss: 1.3136 - acc: 0.528 - ETA: 7s - loss: 1.3141 - acc: 0.528 - ETA: 7s - loss: 1.3146 - acc: 0.527 - ETA: 7s - loss: 1.3144 - acc: 0.528 - ETA: 6s - loss: 1.3152 - acc: 0.528 - ETA: 6s - loss: 1.3141 - acc: 0.528 - ETA: 6s - loss: 1.3157 - acc: 0.528 - ETA: 6s - loss: 1.3143 - acc: 0.529 - ETA: 6s - loss: 1.3134 - acc: 0.528 - ETA: 6s - loss: 1.3122 - acc: 0.528 - ETA: 6s - loss: 1.3150 - acc: 0.527 - ETA: 6s - loss: 1.3140 - acc: 0.528 - ETA: 6s - loss: 1.3144 - acc: 0.528 - ETA: 6s - loss: 1.3145 - acc: 0.528 - ETA: 6s - loss: 1.3160 - acc: 0.527 - ETA: 6s - loss: 1.3161 - acc: 0.527 - ETA: 6s - loss: 1.3155 - acc: 0.527 - ETA: 6s - loss: 1.3152 - acc: 0.527 - ETA: 6s - loss: 1.3137 - acc: 0.528 - ETA: 6s - loss: 1.3124 - acc: 0.529 - ETA: 6s - loss: 1.3145 - acc: 0.528 - ETA: 6s - loss: 1.3139 - acc: 0.528 - ETA: 5s - loss: 1.3132 - acc: 0.528 - ETA: 5s - loss: 1.3136 - acc: 0.528 - ETA: 5s - loss: 1.3117 - acc: 0.528 - ETA: 5s - loss: 1.3119 - acc: 0.529 - ETA: 5s - loss: 1.3109 - acc: 0.529 - ETA: 5s - loss: 1.3100 - acc: 0.529 - ETA: 5s - loss: 1.3087 - acc: 0.530 - ETA: 5s - loss: 1.3094 - acc: 0.530 - ETA: 5s - loss: 1.3080 - acc: 0.531 - ETA: 5s - loss: 1.3086 - acc: 0.531 - ETA: 5s - loss: 1.3092 - acc: 0.530 - ETA: 5s - loss: 1.3088 - acc: 0.530 - ETA: 5s - loss: 1.3085 - acc: 0.531 - ETA: 5s - loss: 1.3075 - acc: 0.531 - ETA: 5s - loss: 1.3073 - acc: 0.531 - ETA: 5s - loss: 1.3071 - acc: 0.531 - ETA: 5s - loss: 1.3063 - acc: 0.531 - ETA: 5s - loss: 1.3059 - acc: 0.532 - ETA: 5s - loss: 1.3057 - acc: 0.531 - ETA: 4s - loss: 1.3054 - acc: 0.531 - ETA: 4s - loss: 1.3061 - acc: 0.531 - ETA: 4s - loss: 1.3066 - acc: 0.531 - ETA: 4s - loss: 1.3062 - acc: 0.531 - ETA: 4s - loss: 1.3061 - acc: 0.531 - ETA: 4s - loss: 1.3055 - acc: 0.531 - ETA: 4s - loss: 1.3055 - acc: 0.531 - ETA: 4s - loss: 1.3057 - acc: 0.531 - ETA: 4s - loss: 1.3049 - acc: 0.532 - ETA: 4s - loss: 1.3051 - acc: 0.532 - ETA: 4s - loss: 1.3050 - acc: 0.532 - ETA: 4s - loss: 1.3045 - acc: 0.532 - ETA: 4s - loss: 1.3052 - acc: 0.532 - ETA: 4s - loss: 1.3039 - acc: 0.532 - ETA: 4s - loss: 1.3038 - acc: 0.532 - ETA: 4s - loss: 1.3035 - acc: 0.532 - ETA: 4s - loss: 1.3052 - acc: 0.532 - ETA: 4s - loss: 1.3048 - acc: 0.532 - ETA: 3s - loss: 1.3047 - acc: 0.532 - ETA: 3s - loss: 1.3047 - acc: 0.532 - ETA: 3s - loss: 1.3053 - acc: 0.532 - ETA: 3s - loss: 1.3047 - acc: 0.532 - ETA: 3s - loss: 1.3043 - acc: 0.533 - ETA: 3s - loss: 1.3036 - acc: 0.533 - ETA: 3s - loss: 1.3034 - acc: 0.533 - ETA: 3s - loss: 1.3035 - acc: 0.533 - ETA: 3s - loss: 1.3034 - acc: 0.533 - ETA: 3s - loss: 1.3026 - acc: 0.534 - ETA: 3s - loss: 1.3020 - acc: 0.534 - ETA: 3s - loss: 1.3013 - acc: 0.534 - ETA: 3s - loss: 1.3020 - acc: 0.534 - ETA: 3s - loss: 1.3021 - acc: 0.534 - ETA: 3s - loss: 1.3014 - acc: 0.534 - ETA: 3s - loss: 1.3013 - acc: 0.534 - ETA: 3s - loss: 1.3010 - acc: 0.534 - ETA: 3s - loss: 1.3003 - acc: 0.534 - ETA: 3s - loss: 1.2997 - acc: 0.535 - ETA: 2s - loss: 1.2994 - acc: 0.535 - ETA: 2s - loss: 1.2990 - acc: 0.535 - ETA: 2s - loss: 1.2990 - acc: 0.535 - ETA: 2s - loss: 1.2989 - acc: 0.535 - ETA: 2s - loss: 1.2993 - acc: 0.535 - ETA: 2s - loss: 1.2987 - acc: 0.535 - ETA: 2s - loss: 1.2985 - acc: 0.535 - ETA: 2s - loss: 1.2993 - acc: 0.535 - ETA: 2s - loss: 1.2991 - acc: 0.535 - ETA: 2s - loss: 1.2991 - acc: 0.535 - ETA: 2s - loss: 1.2994 - acc: 0.534 - ETA: 2s - loss: 1.2995 - acc: 0.535 - ETA: 2s - loss: 1.2994 - acc: 0.535 - ETA: 2s - loss: 1.2999 - acc: 0.535 - ETA: 2s - loss: 1.2997 - acc: 0.535 - ETA: 2s - loss: 1.2994 - acc: 0.535 - ETA: 2s - loss: 1.2989 - acc: 0.535 - ETA: 2s - loss: 1.2989 - acc: 0.535 - ETA: 1s - loss: 1.2988 - acc: 0.535 - ETA: 1s - loss: 1.2990 - acc: 0.535 - ETA: 1s - loss: 1.2982 - acc: 0.535 - ETA: 1s - loss: 1.2980 - acc: 0.535 - ETA: 1s - loss: 1.2983 - acc: 0.535 - ETA: 1s - loss: 1.2985 - acc: 0.535 - ETA: 1s - loss: 1.2982 - acc: 0.535 - ETA: 1s - loss: 1.2979 - acc: 0.535 - ETA: 1s - loss: 1.2978 - acc: 0.536 - ETA: 1s - loss: 1.2973 - acc: 0.536 - ETA: 1s - loss: 1.2975 - acc: 0.536 - ETA: 1s - loss: 1.2973 - acc: 0.536 - ETA: 1s - loss: 1.2973 - acc: 0.536 - ETA: 1s - loss: 1.2970 - acc: 0.536 - ETA: 1s - loss: 1.2966 - acc: 0.536 - ETA: 1s - loss: 1.2956 - acc: 0.536 - ETA: 1s - loss: 1.2955 - acc: 0.536 - ETA: 1s - loss: 1.2958 - acc: 0.536 - ETA: 1s - loss: 1.2959 - acc: 0.536 - ETA: 0s - loss: 1.2955 - acc: 0.536 - ETA: 0s - loss: 1.2949 - acc: 0.536 - ETA: 0s - loss: 1.2949 - acc: 0.537 - ETA: 0s - loss: 1.2939 - acc: 0.537 - ETA: 0s - loss: 1.2936 - acc: 0.537 - ETA: 0s - loss: 1.2929 - acc: 0.537 - ETA: 0s - loss: 1.2923 - acc: 0.538 - ETA: 0s - loss: 1.2920 - acc: 0.538 - ETA: 0s - loss: 1.2915 - acc: 0.538 - ETA: 0s - loss: 1.2912 - acc: 0.538 - ETA: 0s - loss: 1.2906 - acc: 0.538 - ETA: 0s - loss: 1.2896 - acc: 0.539 - ETA: 0s - loss: 1.2899 - acc: 0.538 - ETA: 0s - loss: 1.2902 - acc: 0.538 - ETA: 0s - loss: 1.2895 - acc: 0.538 - ETA: 0s - loss: 1.2893 - acc: 0.538 - ETA: 0s - loss: 1.2890 - acc: 0.538 - ETA: 0s - loss: 1.2882 - acc: 0.5390WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "45000/45000 [==============================] - 11s 254us/sample - loss: 1.2886 - acc: 0.5388 - val_loss: 1.1753 - val_acc: 0.5856\n",
      "Epoch 5/40\n",
      "44864/45000 [============================>.] - ETA: 14s - loss: 0.9057 - acc: 0.68 - ETA: 11s - loss: 1.2398 - acc: 0.55 - ETA: 10s - loss: 1.2213 - acc: 0.56 - ETA: 10s - loss: 1.2169 - acc: 0.56 - ETA: 10s - loss: 1.2441 - acc: 0.56 - ETA: 10s - loss: 1.2409 - acc: 0.56 - ETA: 10s - loss: 1.2546 - acc: 0.55 - ETA: 10s - loss: 1.2530 - acc: 0.54 - ETA: 10s - loss: 1.2382 - acc: 0.55 - ETA: 10s - loss: 1.2292 - acc: 0.56 - ETA: 10s - loss: 1.2301 - acc: 0.56 - ETA: 10s - loss: 1.2311 - acc: 0.56 - ETA: 10s - loss: 1.2277 - acc: 0.56 - ETA: 10s - loss: 1.2276 - acc: 0.56 - ETA: 10s - loss: 1.2267 - acc: 0.56 - ETA: 9s - loss: 1.2240 - acc: 0.5613 - ETA: 9s - loss: 1.2241 - acc: 0.562 - ETA: 9s - loss: 1.2257 - acc: 0.562 - ETA: 9s - loss: 1.2202 - acc: 0.563 - ETA: 9s - loss: 1.2275 - acc: 0.559 - ETA: 9s - loss: 1.2276 - acc: 0.558 - ETA: 9s - loss: 1.2304 - acc: 0.557 - ETA: 9s - loss: 1.2231 - acc: 0.561 - ETA: 9s - loss: 1.2271 - acc: 0.559 - ETA: 9s - loss: 1.2236 - acc: 0.562 - ETA: 9s - loss: 1.2260 - acc: 0.560 - ETA: 9s - loss: 1.2273 - acc: 0.559 - ETA: 9s - loss: 1.2244 - acc: 0.560 - ETA: 9s - loss: 1.2262 - acc: 0.560 - ETA: 9s - loss: 1.2296 - acc: 0.559 - ETA: 9s - loss: 1.2306 - acc: 0.558 - ETA: 9s - loss: 1.2297 - acc: 0.558 - ETA: 9s - loss: 1.2299 - acc: 0.558 - ETA: 8s - loss: 1.2303 - acc: 0.557 - ETA: 8s - loss: 1.2321 - acc: 0.556 - ETA: 8s - loss: 1.2291 - acc: 0.558 - ETA: 8s - loss: 1.2297 - acc: 0.557 - ETA: 8s - loss: 1.2284 - acc: 0.558 - ETA: 8s - loss: 1.2282 - acc: 0.558 - ETA: 8s - loss: 1.2285 - acc: 0.558 - ETA: 8s - loss: 1.2305 - acc: 0.558 - ETA: 8s - loss: 1.2311 - acc: 0.559 - ETA: 8s - loss: 1.2300 - acc: 0.560 - ETA: 8s - loss: 1.2305 - acc: 0.560 - ETA: 8s - loss: 1.2314 - acc: 0.559 - ETA: 8s - loss: 1.2301 - acc: 0.560 - ETA: 8s - loss: 1.2271 - acc: 0.561 - ETA: 8s - loss: 1.2298 - acc: 0.560 - ETA: 8s - loss: 1.2315 - acc: 0.559 - ETA: 8s - loss: 1.2287 - acc: 0.561 - ETA: 8s - loss: 1.2313 - acc: 0.558 - ETA: 8s - loss: 1.2313 - acc: 0.559 - ETA: 7s - loss: 1.2309 - acc: 0.559 - ETA: 7s - loss: 1.2325 - acc: 0.559 - ETA: 7s - loss: 1.2339 - acc: 0.559 - ETA: 7s - loss: 1.2349 - acc: 0.559 - ETA: 7s - loss: 1.2353 - acc: 0.559 - ETA: 7s - loss: 1.2347 - acc: 0.559 - ETA: 7s - loss: 1.2391 - acc: 0.557 - ETA: 7s - loss: 1.2374 - acc: 0.558 - ETA: 7s - loss: 1.2369 - acc: 0.558 - ETA: 7s - loss: 1.2396 - acc: 0.558 - ETA: 7s - loss: 1.2365 - acc: 0.560 - ETA: 7s - loss: 1.2345 - acc: 0.560 - ETA: 7s - loss: 1.2344 - acc: 0.561 - ETA: 7s - loss: 1.2343 - acc: 0.560 - ETA: 7s - loss: 1.2330 - acc: 0.561 - ETA: 7s - loss: 1.2319 - acc: 0.562 - ETA: 7s - loss: 1.2310 - acc: 0.562 - ETA: 7s - loss: 1.2301 - acc: 0.563 - ETA: 6s - loss: 1.2291 - acc: 0.564 - ETA: 6s - loss: 1.2289 - acc: 0.563 - ETA: 6s - loss: 1.2299 - acc: 0.563 - ETA: 6s - loss: 1.2281 - acc: 0.564 - ETA: 6s - loss: 1.2274 - acc: 0.564 - ETA: 6s - loss: 1.2264 - acc: 0.564 - ETA: 6s - loss: 1.2256 - acc: 0.565 - ETA: 6s - loss: 1.2254 - acc: 0.565 - ETA: 6s - loss: 1.2252 - acc: 0.565 - ETA: 6s - loss: 1.2262 - acc: 0.565 - ETA: 6s - loss: 1.2270 - acc: 0.565 - ETA: 6s - loss: 1.2253 - acc: 0.565 - ETA: 6s - loss: 1.2260 - acc: 0.565 - ETA: 6s - loss: 1.2261 - acc: 0.565 - ETA: 6s - loss: 1.2261 - acc: 0.565 - ETA: 6s - loss: 1.2253 - acc: 0.566 - ETA: 6s - loss: 1.2262 - acc: 0.565 - ETA: 6s - loss: 1.2257 - acc: 0.565 - ETA: 6s - loss: 1.2257 - acc: 0.565 - ETA: 5s - loss: 1.2255 - acc: 0.565 - ETA: 5s - loss: 1.2253 - acc: 0.565 - ETA: 5s - loss: 1.2256 - acc: 0.565 - ETA: 5s - loss: 1.2256 - acc: 0.564 - ETA: 5s - loss: 1.2265 - acc: 0.564 - ETA: 5s - loss: 1.2259 - acc: 0.565 - ETA: 5s - loss: 1.2273 - acc: 0.564 - ETA: 5s - loss: 1.2261 - acc: 0.564 - ETA: 5s - loss: 1.2245 - acc: 0.564 - ETA: 5s - loss: 1.2241 - acc: 0.565 - ETA: 5s - loss: 1.2248 - acc: 0.564 - ETA: 5s - loss: 1.2232 - acc: 0.565 - ETA: 5s - loss: 1.2228 - acc: 0.565 - ETA: 5s - loss: 1.2229 - acc: 0.565 - ETA: 5s - loss: 1.2225 - acc: 0.565 - ETA: 5s - loss: 1.2221 - acc: 0.565 - ETA: 5s - loss: 1.2203 - acc: 0.566 - ETA: 5s - loss: 1.2205 - acc: 0.566 - ETA: 5s - loss: 1.2224 - acc: 0.565 - ETA: 4s - loss: 1.2209 - acc: 0.566 - ETA: 4s - loss: 1.2216 - acc: 0.566 - ETA: 4s - loss: 1.2208 - acc: 0.566 - ETA: 4s - loss: 1.2194 - acc: 0.567 - ETA: 4s - loss: 1.2206 - acc: 0.566 - ETA: 4s - loss: 1.2201 - acc: 0.566 - ETA: 4s - loss: 1.2199 - acc: 0.566 - ETA: 4s - loss: 1.2185 - acc: 0.567 - ETA: 4s - loss: 1.2192 - acc: 0.567 - ETA: 4s - loss: 1.2187 - acc: 0.567 - ETA: 4s - loss: 1.2191 - acc: 0.567 - ETA: 4s - loss: 1.2189 - acc: 0.567 - ETA: 4s - loss: 1.2193 - acc: 0.567 - ETA: 4s - loss: 1.2203 - acc: 0.567 - ETA: 4s - loss: 1.2200 - acc: 0.567 - ETA: 4s - loss: 1.2196 - acc: 0.567 - ETA: 4s - loss: 1.2203 - acc: 0.567 - ETA: 4s - loss: 1.2198 - acc: 0.568 - ETA: 3s - loss: 1.2197 - acc: 0.568 - ETA: 3s - loss: 1.2198 - acc: 0.567 - ETA: 3s - loss: 1.2195 - acc: 0.568 - ETA: 3s - loss: 1.2201 - acc: 0.567 - ETA: 3s - loss: 1.2199 - acc: 0.567 - ETA: 3s - loss: 1.2205 - acc: 0.567 - ETA: 3s - loss: 1.2207 - acc: 0.567 - ETA: 3s - loss: 1.2215 - acc: 0.567 - ETA: 3s - loss: 1.2215 - acc: 0.567 - ETA: 3s - loss: 1.2211 - acc: 0.567 - ETA: 3s - loss: 1.2204 - acc: 0.568 - ETA: 3s - loss: 1.2209 - acc: 0.567 - ETA: 3s - loss: 1.2191 - acc: 0.568 - ETA: 3s - loss: 1.2193 - acc: 0.568 - ETA: 3s - loss: 1.2187 - acc: 0.568 - ETA: 3s - loss: 1.2181 - acc: 0.569 - ETA: 3s - loss: 1.2183 - acc: 0.568 - ETA: 3s - loss: 1.2175 - acc: 0.569 - ETA: 3s - loss: 1.2181 - acc: 0.568 - ETA: 2s - loss: 1.2182 - acc: 0.568 - ETA: 2s - loss: 1.2181 - acc: 0.568 - ETA: 2s - loss: 1.2175 - acc: 0.568 - ETA: 2s - loss: 1.2180 - acc: 0.568 - ETA: 2s - loss: 1.2183 - acc: 0.568 - ETA: 2s - loss: 1.2191 - acc: 0.568 - ETA: 2s - loss: 1.2192 - acc: 0.568 - ETA: 2s - loss: 1.2191 - acc: 0.568 - ETA: 2s - loss: 1.2188 - acc: 0.568 - ETA: 2s - loss: 1.2187 - acc: 0.568 - ETA: 2s - loss: 1.2185 - acc: 0.568 - ETA: 2s - loss: 1.2179 - acc: 0.568 - ETA: 2s - loss: 1.2179 - acc: 0.568 - ETA: 2s - loss: 1.2179 - acc: 0.568 - ETA: 2s - loss: 1.2172 - acc: 0.568 - ETA: 2s - loss: 1.2177 - acc: 0.568 - ETA: 2s - loss: 1.2173 - acc: 0.568 - ETA: 2s - loss: 1.2169 - acc: 0.568 - ETA: 2s - loss: 1.2168 - acc: 0.569 - ETA: 1s - loss: 1.2169 - acc: 0.568 - ETA: 1s - loss: 1.2168 - acc: 0.568 - ETA: 1s - loss: 1.2168 - acc: 0.568 - ETA: 1s - loss: 1.2164 - acc: 0.568 - ETA: 1s - loss: 1.2163 - acc: 0.568 - ETA: 1s - loss: 1.2158 - acc: 0.569 - ETA: 1s - loss: 1.2152 - acc: 0.569 - ETA: 1s - loss: 1.2150 - acc: 0.569 - ETA: 1s - loss: 1.2147 - acc: 0.569 - ETA: 1s - loss: 1.2140 - acc: 0.569 - ETA: 1s - loss: 1.2141 - acc: 0.569 - ETA: 1s - loss: 1.2140 - acc: 0.569 - ETA: 1s - loss: 1.2143 - acc: 0.569 - ETA: 1s - loss: 1.2147 - acc: 0.569 - ETA: 1s - loss: 1.2146 - acc: 0.569 - ETA: 1s - loss: 1.2144 - acc: 0.569 - ETA: 1s - loss: 1.2137 - acc: 0.569 - ETA: 1s - loss: 1.2138 - acc: 0.569 - ETA: 1s - loss: 1.2140 - acc: 0.569 - ETA: 0s - loss: 1.2144 - acc: 0.568 - ETA: 0s - loss: 1.2145 - acc: 0.568 - ETA: 0s - loss: 1.2143 - acc: 0.569 - ETA: 0s - loss: 1.2140 - acc: 0.569 - ETA: 0s - loss: 1.2134 - acc: 0.569 - ETA: 0s - loss: 1.2136 - acc: 0.569 - ETA: 0s - loss: 1.2133 - acc: 0.569 - ETA: 0s - loss: 1.2133 - acc: 0.569 - ETA: 0s - loss: 1.2137 - acc: 0.569 - ETA: 0s - loss: 1.2134 - acc: 0.569 - ETA: 0s - loss: 1.2132 - acc: 0.569 - ETA: 0s - loss: 1.2133 - acc: 0.569 - ETA: 0s - loss: 1.2123 - acc: 0.569 - ETA: 0s - loss: 1.2118 - acc: 0.569 - ETA: 0s - loss: 1.2114 - acc: 0.569 - ETA: 0s - loss: 1.2109 - acc: 0.570 - ETA: 0s - loss: 1.2105 - acc: 0.570 - ETA: 0s - loss: 1.2105 - acc: 0.5701WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "45000/45000 [==============================] - 11s 252us/sample - loss: 1.2101 - acc: 0.5702 - val_loss: 1.1113 - val_acc: 0.6086\n",
      "Epoch 6/40\n",
      "44832/45000 [============================>.] - ETA: 14s - loss: 1.0965 - acc: 0.59 - ETA: 10s - loss: 1.1951 - acc: 0.60 - ETA: 10s - loss: 1.1613 - acc: 0.59 - ETA: 10s - loss: 1.1758 - acc: 0.60 - ETA: 10s - loss: 1.1587 - acc: 0.59 - ETA: 10s - loss: 1.1534 - acc: 0.60 - ETA: 10s - loss: 1.1612 - acc: 0.60 - ETA: 10s - loss: 1.1549 - acc: 0.59 - ETA: 10s - loss: 1.1448 - acc: 0.60 - ETA: 10s - loss: 1.1434 - acc: 0.60 - ETA: 10s - loss: 1.1410 - acc: 0.60 - ETA: 10s - loss: 1.1474 - acc: 0.59 - ETA: 10s - loss: 1.1432 - acc: 0.60 - ETA: 10s - loss: 1.1467 - acc: 0.59 - ETA: 10s - loss: 1.1496 - acc: 0.59 - ETA: 9s - loss: 1.1481 - acc: 0.5967 - ETA: 9s - loss: 1.1447 - acc: 0.595 - ETA: 9s - loss: 1.1448 - acc: 0.593 - ETA: 9s - loss: 1.1470 - acc: 0.593 - ETA: 9s - loss: 1.1524 - acc: 0.589 - ETA: 9s - loss: 1.1583 - acc: 0.588 - ETA: 9s - loss: 1.1690 - acc: 0.584 - ETA: 9s - loss: 1.1720 - acc: 0.584 - ETA: 9s - loss: 1.1756 - acc: 0.582 - ETA: 9s - loss: 1.1816 - acc: 0.581 - ETA: 9s - loss: 1.1813 - acc: 0.581 - ETA: 9s - loss: 1.1780 - acc: 0.580 - ETA: 9s - loss: 1.1790 - acc: 0.580 - ETA: 9s - loss: 1.1786 - acc: 0.579 - ETA: 9s - loss: 1.1790 - acc: 0.579 - ETA: 9s - loss: 1.1837 - acc: 0.578 - ETA: 9s - loss: 1.1847 - acc: 0.578 - ETA: 9s - loss: 1.1806 - acc: 0.580 - ETA: 9s - loss: 1.1783 - acc: 0.581 - ETA: 8s - loss: 1.1758 - acc: 0.583 - ETA: 8s - loss: 1.1747 - acc: 0.582 - ETA: 8s - loss: 1.1725 - acc: 0.584 - ETA: 8s - loss: 1.1718 - acc: 0.584 - ETA: 8s - loss: 1.1738 - acc: 0.583 - ETA: 8s - loss: 1.1734 - acc: 0.583 - ETA: 8s - loss: 1.1713 - acc: 0.584 - ETA: 8s - loss: 1.1725 - acc: 0.583 - ETA: 8s - loss: 1.1728 - acc: 0.582 - ETA: 8s - loss: 1.1761 - acc: 0.581 - ETA: 8s - loss: 1.1752 - acc: 0.581 - ETA: 8s - loss: 1.1763 - acc: 0.582 - ETA: 8s - loss: 1.1769 - acc: 0.582 - ETA: 8s - loss: 1.1744 - acc: 0.582 - ETA: 8s - loss: 1.1727 - acc: 0.584 - ETA: 8s - loss: 1.1723 - acc: 0.583 - ETA: 8s - loss: 1.1706 - acc: 0.583 - ETA: 8s - loss: 1.1685 - acc: 0.584 - ETA: 8s - loss: 1.1691 - acc: 0.584 - ETA: 7s - loss: 1.1706 - acc: 0.584 - ETA: 7s - loss: 1.1710 - acc: 0.583 - ETA: 7s - loss: 1.1730 - acc: 0.583 - ETA: 7s - loss: 1.1715 - acc: 0.583 - ETA: 7s - loss: 1.1706 - acc: 0.584 - ETA: 7s - loss: 1.1718 - acc: 0.583 - ETA: 7s - loss: 1.1720 - acc: 0.583 - ETA: 7s - loss: 1.1711 - acc: 0.584 - ETA: 7s - loss: 1.1704 - acc: 0.584 - ETA: 7s - loss: 1.1704 - acc: 0.584 - ETA: 7s - loss: 1.1693 - acc: 0.584 - ETA: 7s - loss: 1.1706 - acc: 0.584 - ETA: 7s - loss: 1.1684 - acc: 0.585 - ETA: 7s - loss: 1.1691 - acc: 0.584 - ETA: 7s - loss: 1.1678 - acc: 0.585 - ETA: 7s - loss: 1.1684 - acc: 0.584 - ETA: 7s - loss: 1.1691 - acc: 0.584 - ETA: 7s - loss: 1.1688 - acc: 0.585 - ETA: 6s - loss: 1.1675 - acc: 0.586 - ETA: 6s - loss: 1.1700 - acc: 0.585 - ETA: 6s - loss: 1.1698 - acc: 0.585 - ETA: 6s - loss: 1.1714 - acc: 0.584 - ETA: 6s - loss: 1.1714 - acc: 0.584 - ETA: 6s - loss: 1.1710 - acc: 0.585 - ETA: 6s - loss: 1.1703 - acc: 0.585 - ETA: 6s - loss: 1.1698 - acc: 0.586 - ETA: 6s - loss: 1.1688 - acc: 0.586 - ETA: 6s - loss: 1.1707 - acc: 0.586 - ETA: 6s - loss: 1.1712 - acc: 0.585 - ETA: 6s - loss: 1.1705 - acc: 0.585 - ETA: 6s - loss: 1.1700 - acc: 0.585 - ETA: 6s - loss: 1.1693 - acc: 0.585 - ETA: 6s - loss: 1.1685 - acc: 0.586 - ETA: 6s - loss: 1.1679 - acc: 0.585 - ETA: 6s - loss: 1.1681 - acc: 0.585 - ETA: 6s - loss: 1.1676 - acc: 0.586 - ETA: 6s - loss: 1.1671 - acc: 0.586 - ETA: 5s - loss: 1.1661 - acc: 0.586 - ETA: 5s - loss: 1.1651 - acc: 0.586 - ETA: 5s - loss: 1.1647 - acc: 0.587 - ETA: 5s - loss: 1.1652 - acc: 0.587 - ETA: 5s - loss: 1.1646 - acc: 0.587 - ETA: 5s - loss: 1.1649 - acc: 0.587 - ETA: 5s - loss: 1.1645 - acc: 0.587 - ETA: 5s - loss: 1.1647 - acc: 0.587 - ETA: 5s - loss: 1.1643 - acc: 0.587 - ETA: 5s - loss: 1.1649 - acc: 0.587 - ETA: 5s - loss: 1.1647 - acc: 0.587 - ETA: 5s - loss: 1.1632 - acc: 0.588 - ETA: 5s - loss: 1.1640 - acc: 0.588 - ETA: 5s - loss: 1.1635 - acc: 0.588 - ETA: 5s - loss: 1.1634 - acc: 0.587 - ETA: 5s - loss: 1.1634 - acc: 0.587 - ETA: 5s - loss: 1.1638 - acc: 0.587 - ETA: 5s - loss: 1.1629 - acc: 0.587 - ETA: 4s - loss: 1.1630 - acc: 0.587 - ETA: 4s - loss: 1.1620 - acc: 0.587 - ETA: 4s - loss: 1.1607 - acc: 0.588 - ETA: 4s - loss: 1.1607 - acc: 0.588 - ETA: 4s - loss: 1.1609 - acc: 0.588 - ETA: 4s - loss: 1.1598 - acc: 0.588 - ETA: 4s - loss: 1.1605 - acc: 0.588 - ETA: 4s - loss: 1.1602 - acc: 0.588 - ETA: 4s - loss: 1.1596 - acc: 0.588 - ETA: 4s - loss: 1.1603 - acc: 0.588 - ETA: 4s - loss: 1.1599 - acc: 0.588 - ETA: 4s - loss: 1.1596 - acc: 0.588 - ETA: 4s - loss: 1.1586 - acc: 0.588 - ETA: 4s - loss: 1.1577 - acc: 0.589 - ETA: 4s - loss: 1.1570 - acc: 0.589 - ETA: 4s - loss: 1.1575 - acc: 0.588 - ETA: 4s - loss: 1.1566 - acc: 0.589 - ETA: 4s - loss: 1.1558 - acc: 0.589 - ETA: 4s - loss: 1.1563 - acc: 0.589 - ETA: 3s - loss: 1.1559 - acc: 0.590 - ETA: 3s - loss: 1.1566 - acc: 0.589 - ETA: 3s - loss: 1.1566 - acc: 0.589 - ETA: 3s - loss: 1.1566 - acc: 0.590 - ETA: 3s - loss: 1.1564 - acc: 0.590 - ETA: 3s - loss: 1.1554 - acc: 0.590 - ETA: 3s - loss: 1.1548 - acc: 0.590 - ETA: 3s - loss: 1.1544 - acc: 0.590 - ETA: 3s - loss: 1.1537 - acc: 0.591 - ETA: 3s - loss: 1.1535 - acc: 0.591 - ETA: 3s - loss: 1.1521 - acc: 0.591 - ETA: 3s - loss: 1.1516 - acc: 0.592 - ETA: 3s - loss: 1.1514 - acc: 0.592 - ETA: 3s - loss: 1.1514 - acc: 0.592 - ETA: 3s - loss: 1.1524 - acc: 0.591 - ETA: 3s - loss: 1.1517 - acc: 0.592 - ETA: 3s - loss: 1.1509 - acc: 0.592 - ETA: 3s - loss: 1.1506 - acc: 0.592 - ETA: 2s - loss: 1.1513 - acc: 0.592 - ETA: 2s - loss: 1.1512 - acc: 0.592 - ETA: 2s - loss: 1.1517 - acc: 0.591 - ETA: 2s - loss: 1.1520 - acc: 0.591 - ETA: 2s - loss: 1.1519 - acc: 0.591 - ETA: 2s - loss: 1.1523 - acc: 0.591 - ETA: 2s - loss: 1.1519 - acc: 0.591 - ETA: 2s - loss: 1.1526 - acc: 0.591 - ETA: 2s - loss: 1.1523 - acc: 0.591 - ETA: 2s - loss: 1.1529 - acc: 0.591 - ETA: 2s - loss: 1.1536 - acc: 0.591 - ETA: 2s - loss: 1.1538 - acc: 0.590 - ETA: 2s - loss: 1.1538 - acc: 0.590 - ETA: 2s - loss: 1.1535 - acc: 0.590 - ETA: 2s - loss: 1.1538 - acc: 0.590 - ETA: 2s - loss: 1.1535 - acc: 0.590 - ETA: 2s - loss: 1.1541 - acc: 0.590 - ETA: 2s - loss: 1.1540 - acc: 0.590 - ETA: 2s - loss: 1.1549 - acc: 0.589 - ETA: 1s - loss: 1.1547 - acc: 0.589 - ETA: 1s - loss: 1.1550 - acc: 0.589 - ETA: 1s - loss: 1.1545 - acc: 0.590 - ETA: 1s - loss: 1.1548 - acc: 0.590 - ETA: 1s - loss: 1.1548 - acc: 0.590 - ETA: 1s - loss: 1.1544 - acc: 0.590 - ETA: 1s - loss: 1.1538 - acc: 0.590 - ETA: 1s - loss: 1.1539 - acc: 0.590 - ETA: 1s - loss: 1.1544 - acc: 0.590 - ETA: 1s - loss: 1.1542 - acc: 0.590 - ETA: 1s - loss: 1.1535 - acc: 0.591 - ETA: 1s - loss: 1.1540 - acc: 0.590 - ETA: 1s - loss: 1.1539 - acc: 0.590 - ETA: 1s - loss: 1.1538 - acc: 0.590 - ETA: 1s - loss: 1.1533 - acc: 0.590 - ETA: 1s - loss: 1.1526 - acc: 0.591 - ETA: 1s - loss: 1.1524 - acc: 0.591 - ETA: 1s - loss: 1.1530 - acc: 0.591 - ETA: 1s - loss: 1.1523 - acc: 0.591 - ETA: 0s - loss: 1.1528 - acc: 0.591 - ETA: 0s - loss: 1.1534 - acc: 0.591 - ETA: 0s - loss: 1.1533 - acc: 0.591 - ETA: 0s - loss: 1.1527 - acc: 0.591 - ETA: 0s - loss: 1.1527 - acc: 0.591 - ETA: 0s - loss: 1.1527 - acc: 0.591 - ETA: 0s - loss: 1.1528 - acc: 0.590 - ETA: 0s - loss: 1.1524 - acc: 0.590 - ETA: 0s - loss: 1.1521 - acc: 0.591 - ETA: 0s - loss: 1.1515 - acc: 0.591 - ETA: 0s - loss: 1.1513 - acc: 0.591 - ETA: 0s - loss: 1.1508 - acc: 0.591 - ETA: 0s - loss: 1.1506 - acc: 0.591 - ETA: 0s - loss: 1.1503 - acc: 0.591 - ETA: 0s - loss: 1.1500 - acc: 0.591 - ETA: 0s - loss: 1.1496 - acc: 0.591 - ETA: 0s - loss: 1.1496 - acc: 0.591 - ETA: 0s - loss: 1.1495 - acc: 0.5917WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "45000/45000 [==============================] - 11s 254us/sample - loss: 1.1493 - acc: 0.5916 - val_loss: 1.0574 - val_acc: 0.6234\n",
      "Epoch 7/40\n",
      "44832/45000 [============================>.] - ETA: 14s - loss: 1.0892 - acc: 0.75 - ETA: 10s - loss: 1.0996 - acc: 0.64 - ETA: 10s - loss: 1.1251 - acc: 0.62 - ETA: 10s - loss: 1.0804 - acc: 0.64 - ETA: 10s - loss: 1.0763 - acc: 0.63 - ETA: 10s - loss: 1.0704 - acc: 0.63 - ETA: 10s - loss: 1.0724 - acc: 0.63 - ETA: 10s - loss: 1.0897 - acc: 0.62 - ETA: 10s - loss: 1.0943 - acc: 0.61 - ETA: 10s - loss: 1.0958 - acc: 0.61 - ETA: 10s - loss: 1.1087 - acc: 0.61 - ETA: 10s - loss: 1.1140 - acc: 0.60 - ETA: 10s - loss: 1.1050 - acc: 0.61 - ETA: 9s - loss: 1.0992 - acc: 0.6138 - ETA: 9s - loss: 1.0888 - acc: 0.613 - ETA: 9s - loss: 1.0895 - acc: 0.611 - ETA: 9s - loss: 1.0824 - acc: 0.613 - ETA: 9s - loss: 1.0856 - acc: 0.611 - ETA: 9s - loss: 1.0811 - acc: 0.614 - ETA: 9s - loss: 1.0848 - acc: 0.614 - ETA: 9s - loss: 1.0843 - acc: 0.615 - ETA: 9s - loss: 1.0906 - acc: 0.613 - ETA: 9s - loss: 1.0882 - acc: 0.614 - ETA: 9s - loss: 1.0925 - acc: 0.613 - ETA: 9s - loss: 1.0963 - acc: 0.611 - ETA: 9s - loss: 1.0967 - acc: 0.611 - ETA: 9s - loss: 1.0969 - acc: 0.611 - ETA: 9s - loss: 1.1032 - acc: 0.608 - ETA: 9s - loss: 1.1032 - acc: 0.608 - ETA: 9s - loss: 1.0995 - acc: 0.609 - ETA: 9s - loss: 1.0970 - acc: 0.610 - ETA: 9s - loss: 1.1016 - acc: 0.609 - ETA: 8s - loss: 1.1024 - acc: 0.609 - ETA: 8s - loss: 1.0967 - acc: 0.611 - ETA: 8s - loss: 1.0924 - acc: 0.614 - ETA: 8s - loss: 1.0928 - acc: 0.613 - ETA: 8s - loss: 1.0940 - acc: 0.613 - ETA: 8s - loss: 1.0964 - acc: 0.613 - ETA: 8s - loss: 1.0959 - acc: 0.614 - ETA: 8s - loss: 1.0988 - acc: 0.613 - ETA: 8s - loss: 1.1009 - acc: 0.612 - ETA: 8s - loss: 1.1021 - acc: 0.611 - ETA: 8s - loss: 1.1009 - acc: 0.612 - ETA: 8s - loss: 1.1016 - acc: 0.612 - ETA: 8s - loss: 1.1029 - acc: 0.611 - ETA: 8s - loss: 1.1034 - acc: 0.611 - ETA: 8s - loss: 1.1028 - acc: 0.611 - ETA: 8s - loss: 1.1021 - acc: 0.611 - ETA: 8s - loss: 1.1013 - acc: 0.612 - ETA: 8s - loss: 1.1028 - acc: 0.611 - ETA: 8s - loss: 1.1029 - acc: 0.610 - ETA: 7s - loss: 1.1061 - acc: 0.609 - ETA: 7s - loss: 1.1048 - acc: 0.609 - ETA: 7s - loss: 1.1065 - acc: 0.609 - ETA: 7s - loss: 1.1053 - acc: 0.609 - ETA: 7s - loss: 1.1034 - acc: 0.609 - ETA: 7s - loss: 1.1028 - acc: 0.610 - ETA: 7s - loss: 1.1047 - acc: 0.609 - ETA: 7s - loss: 1.1038 - acc: 0.610 - ETA: 7s - loss: 1.1020 - acc: 0.611 - ETA: 7s - loss: 1.1009 - acc: 0.611 - ETA: 7s - loss: 1.1008 - acc: 0.612 - ETA: 7s - loss: 1.1008 - acc: 0.612 - ETA: 7s - loss: 1.1002 - acc: 0.612 - ETA: 7s - loss: 1.0999 - acc: 0.612 - ETA: 7s - loss: 1.0985 - acc: 0.612 - ETA: 7s - loss: 1.0988 - acc: 0.612 - ETA: 7s - loss: 1.0985 - acc: 0.612 - ETA: 7s - loss: 1.0975 - acc: 0.612 - ETA: 7s - loss: 1.0969 - acc: 0.612 - ETA: 6s - loss: 1.0961 - acc: 0.612 - ETA: 6s - loss: 1.0960 - acc: 0.612 - ETA: 6s - loss: 1.0965 - acc: 0.612 - ETA: 6s - loss: 1.0952 - acc: 0.613 - ETA: 6s - loss: 1.0960 - acc: 0.612 - ETA: 6s - loss: 1.0947 - acc: 0.613 - ETA: 6s - loss: 1.0958 - acc: 0.612 - ETA: 6s - loss: 1.0953 - acc: 0.612 - ETA: 6s - loss: 1.0943 - acc: 0.613 - ETA: 6s - loss: 1.0949 - acc: 0.612 - ETA: 6s - loss: 1.0955 - acc: 0.612 - ETA: 6s - loss: 1.0958 - acc: 0.612 - ETA: 6s - loss: 1.0948 - acc: 0.613 - ETA: 6s - loss: 1.0961 - acc: 0.612 - ETA: 6s - loss: 1.0973 - acc: 0.611 - ETA: 6s - loss: 1.0990 - acc: 0.610 - ETA: 6s - loss: 1.1006 - acc: 0.610 - ETA: 6s - loss: 1.1006 - acc: 0.611 - ETA: 6s - loss: 1.1002 - acc: 0.610 - ETA: 5s - loss: 1.0997 - acc: 0.610 - ETA: 5s - loss: 1.1002 - acc: 0.610 - ETA: 5s - loss: 1.1002 - acc: 0.611 - ETA: 5s - loss: 1.0996 - acc: 0.611 - ETA: 5s - loss: 1.0996 - acc: 0.610 - ETA: 5s - loss: 1.0996 - acc: 0.610 - ETA: 5s - loss: 1.0989 - acc: 0.611 - ETA: 5s - loss: 1.0994 - acc: 0.610 - ETA: 5s - loss: 1.0991 - acc: 0.611 - ETA: 5s - loss: 1.1001 - acc: 0.610 - ETA: 5s - loss: 1.0996 - acc: 0.611 - ETA: 5s - loss: 1.0994 - acc: 0.610 - ETA: 5s - loss: 1.0996 - acc: 0.611 - ETA: 5s - loss: 1.0996 - acc: 0.611 - ETA: 5s - loss: 1.0994 - acc: 0.611 - ETA: 5s - loss: 1.0994 - acc: 0.611 - ETA: 5s - loss: 1.0991 - acc: 0.611 - ETA: 5s - loss: 1.0997 - acc: 0.610 - ETA: 5s - loss: 1.1000 - acc: 0.610 - ETA: 4s - loss: 1.1000 - acc: 0.610 - ETA: 4s - loss: 1.1001 - acc: 0.610 - ETA: 4s - loss: 1.1010 - acc: 0.610 - ETA: 4s - loss: 1.1010 - acc: 0.610 - ETA: 4s - loss: 1.1016 - acc: 0.610 - ETA: 4s - loss: 1.1015 - acc: 0.610 - ETA: 4s - loss: 1.1017 - acc: 0.610 - ETA: 4s - loss: 1.1017 - acc: 0.610 - ETA: 4s - loss: 1.1027 - acc: 0.609 - ETA: 4s - loss: 1.1031 - acc: 0.610 - ETA: 4s - loss: 1.1024 - acc: 0.610 - ETA: 4s - loss: 1.1020 - acc: 0.610 - ETA: 4s - loss: 1.1025 - acc: 0.610 - ETA: 4s - loss: 1.1018 - acc: 0.610 - ETA: 4s - loss: 1.1018 - acc: 0.610 - ETA: 4s - loss: 1.1021 - acc: 0.610 - ETA: 4s - loss: 1.1010 - acc: 0.611 - ETA: 4s - loss: 1.1012 - acc: 0.611 - ETA: 3s - loss: 1.1015 - acc: 0.611 - ETA: 3s - loss: 1.1015 - acc: 0.611 - ETA: 3s - loss: 1.1020 - acc: 0.610 - ETA: 3s - loss: 1.1019 - acc: 0.610 - ETA: 3s - loss: 1.1019 - acc: 0.610 - ETA: 3s - loss: 1.1014 - acc: 0.610 - ETA: 3s - loss: 1.1017 - acc: 0.610 - ETA: 3s - loss: 1.1016 - acc: 0.610 - ETA: 3s - loss: 1.1018 - acc: 0.610 - ETA: 3s - loss: 1.1025 - acc: 0.610 - ETA: 3s - loss: 1.1024 - acc: 0.610 - ETA: 3s - loss: 1.1027 - acc: 0.610 - ETA: 3s - loss: 1.1020 - acc: 0.610 - ETA: 3s - loss: 1.1018 - acc: 0.610 - ETA: 3s - loss: 1.1014 - acc: 0.610 - ETA: 3s - loss: 1.1013 - acc: 0.610 - ETA: 3s - loss: 1.1015 - acc: 0.609 - ETA: 3s - loss: 1.1017 - acc: 0.609 - ETA: 3s - loss: 1.1028 - acc: 0.609 - ETA: 2s - loss: 1.1019 - acc: 0.609 - ETA: 2s - loss: 1.1016 - acc: 0.609 - ETA: 2s - loss: 1.1018 - acc: 0.609 - ETA: 2s - loss: 1.1013 - acc: 0.609 - ETA: 2s - loss: 1.1013 - acc: 0.609 - ETA: 2s - loss: 1.1010 - acc: 0.609 - ETA: 2s - loss: 1.1009 - acc: 0.609 - ETA: 2s - loss: 1.1008 - acc: 0.609 - ETA: 2s - loss: 1.1007 - acc: 0.610 - ETA: 2s - loss: 1.1008 - acc: 0.610 - ETA: 2s - loss: 1.1011 - acc: 0.610 - ETA: 2s - loss: 1.1017 - acc: 0.609 - ETA: 2s - loss: 1.1021 - acc: 0.609 - ETA: 2s - loss: 1.1019 - acc: 0.609 - ETA: 2s - loss: 1.1014 - acc: 0.609 - ETA: 2s - loss: 1.1009 - acc: 0.609 - ETA: 2s - loss: 1.1009 - acc: 0.609 - ETA: 2s - loss: 1.1007 - acc: 0.609 - ETA: 2s - loss: 1.1010 - acc: 0.609 - ETA: 1s - loss: 1.1010 - acc: 0.609 - ETA: 1s - loss: 1.1011 - acc: 0.610 - ETA: 1s - loss: 1.1012 - acc: 0.610 - ETA: 1s - loss: 1.1012 - acc: 0.609 - ETA: 1s - loss: 1.1014 - acc: 0.609 - ETA: 1s - loss: 1.1014 - acc: 0.609 - ETA: 1s - loss: 1.1017 - acc: 0.609 - ETA: 1s - loss: 1.1018 - acc: 0.609 - ETA: 1s - loss: 1.1018 - acc: 0.609 - ETA: 1s - loss: 1.1020 - acc: 0.609 - ETA: 1s - loss: 1.1016 - acc: 0.610 - ETA: 1s - loss: 1.1015 - acc: 0.610 - ETA: 1s - loss: 1.1017 - acc: 0.610 - ETA: 1s - loss: 1.1018 - acc: 0.610 - ETA: 1s - loss: 1.1010 - acc: 0.610 - ETA: 1s - loss: 1.1007 - acc: 0.610 - ETA: 1s - loss: 1.1007 - acc: 0.610 - ETA: 1s - loss: 1.1005 - acc: 0.610 - ETA: 1s - loss: 1.1000 - acc: 0.610 - ETA: 0s - loss: 1.1000 - acc: 0.610 - ETA: 0s - loss: 1.0995 - acc: 0.611 - ETA: 0s - loss: 1.0992 - acc: 0.611 - ETA: 0s - loss: 1.0984 - acc: 0.611 - ETA: 0s - loss: 1.0980 - acc: 0.611 - ETA: 0s - loss: 1.0976 - acc: 0.611 - ETA: 0s - loss: 1.0979 - acc: 0.611 - ETA: 0s - loss: 1.0982 - acc: 0.611 - ETA: 0s - loss: 1.0984 - acc: 0.611 - ETA: 0s - loss: 1.0985 - acc: 0.611 - ETA: 0s - loss: 1.0991 - acc: 0.610 - ETA: 0s - loss: 1.0989 - acc: 0.610 - ETA: 0s - loss: 1.0995 - acc: 0.610 - ETA: 0s - loss: 1.0996 - acc: 0.610 - ETA: 0s - loss: 1.0994 - acc: 0.610 - ETA: 0s - loss: 1.0997 - acc: 0.610 - ETA: 0s - loss: 1.0996 - acc: 0.610 - ETA: 0s - loss: 1.1000 - acc: 0.6102WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "45000/45000 [==============================] - 11s 253us/sample - loss: 1.1003 - acc: 0.6101 - val_loss: 1.0201 - val_acc: 0.6428\n",
      "Epoch 8/40\n",
      "44832/45000 [============================>.] - ETA: 14s - loss: 1.4604 - acc: 0.53 - ETA: 10s - loss: 1.1976 - acc: 0.58 - ETA: 10s - loss: 1.1048 - acc: 0.61 - ETA: 10s - loss: 1.0499 - acc: 0.64 - ETA: 10s - loss: 1.0153 - acc: 0.64 - ETA: 10s - loss: 1.0273 - acc: 0.63 - ETA: 10s - loss: 1.0488 - acc: 0.63 - ETA: 10s - loss: 1.0453 - acc: 0.63 - ETA: 10s - loss: 1.0533 - acc: 0.63 - ETA: 10s - loss: 1.0599 - acc: 0.63 - ETA: 10s - loss: 1.0672 - acc: 0.63 - ETA: 10s - loss: 1.0577 - acc: 0.63 - ETA: 10s - loss: 1.0589 - acc: 0.63 - ETA: 10s - loss: 1.0542 - acc: 0.63 - ETA: 10s - loss: 1.0523 - acc: 0.63 - ETA: 9s - loss: 1.0583 - acc: 0.6274 - ETA: 9s - loss: 1.0583 - acc: 0.626 - ETA: 9s - loss: 1.0556 - acc: 0.625 - ETA: 9s - loss: 1.0640 - acc: 0.625 - ETA: 9s - loss: 1.0766 - acc: 0.619 - ETA: 9s - loss: 1.0784 - acc: 0.619 - ETA: 9s - loss: 1.0785 - acc: 0.621 - ETA: 9s - loss: 1.0796 - acc: 0.620 - ETA: 9s - loss: 1.0820 - acc: 0.620 - ETA: 9s - loss: 1.0793 - acc: 0.622 - ETA: 9s - loss: 1.0766 - acc: 0.622 - ETA: 9s - loss: 1.0715 - acc: 0.624 - ETA: 9s - loss: 1.0736 - acc: 0.622 - ETA: 9s - loss: 1.0754 - acc: 0.620 - ETA: 9s - loss: 1.0785 - acc: 0.618 - ETA: 9s - loss: 1.0797 - acc: 0.617 - ETA: 9s - loss: 1.0821 - acc: 0.615 - ETA: 9s - loss: 1.0804 - acc: 0.616 - ETA: 9s - loss: 1.0804 - acc: 0.616 - ETA: 8s - loss: 1.0775 - acc: 0.616 - ETA: 8s - loss: 1.0790 - acc: 0.616 - ETA: 8s - loss: 1.0824 - acc: 0.615 - ETA: 8s - loss: 1.0818 - acc: 0.614 - ETA: 8s - loss: 1.0810 - acc: 0.615 - ETA: 8s - loss: 1.0808 - acc: 0.616 - ETA: 8s - loss: 1.0780 - acc: 0.617 - ETA: 8s - loss: 1.0764 - acc: 0.617 - ETA: 8s - loss: 1.0763 - acc: 0.616 - ETA: 8s - loss: 1.0757 - acc: 0.617 - ETA: 8s - loss: 1.0755 - acc: 0.617 - ETA: 8s - loss: 1.0765 - acc: 0.617 - ETA: 8s - loss: 1.0746 - acc: 0.618 - ETA: 8s - loss: 1.0761 - acc: 0.618 - ETA: 8s - loss: 1.0775 - acc: 0.618 - ETA: 8s - loss: 1.0759 - acc: 0.619 - ETA: 8s - loss: 1.0781 - acc: 0.618 - ETA: 8s - loss: 1.0795 - acc: 0.618 - ETA: 7s - loss: 1.0785 - acc: 0.618 - ETA: 7s - loss: 1.0772 - acc: 0.619 - ETA: 7s - loss: 1.0780 - acc: 0.618 - ETA: 7s - loss: 1.0777 - acc: 0.618 - ETA: 7s - loss: 1.0772 - acc: 0.618 - ETA: 7s - loss: 1.0769 - acc: 0.618 - ETA: 7s - loss: 1.0805 - acc: 0.617 - ETA: 7s - loss: 1.0813 - acc: 0.617 - ETA: 7s - loss: 1.0812 - acc: 0.617 - ETA: 7s - loss: 1.0805 - acc: 0.617 - ETA: 7s - loss: 1.0807 - acc: 0.617 - ETA: 7s - loss: 1.0799 - acc: 0.618 - ETA: 7s - loss: 1.0793 - acc: 0.618 - ETA: 7s - loss: 1.0802 - acc: 0.618 - ETA: 7s - loss: 1.0798 - acc: 0.618 - ETA: 7s - loss: 1.0792 - acc: 0.618 - ETA: 7s - loss: 1.0804 - acc: 0.618 - ETA: 7s - loss: 1.0810 - acc: 0.618 - ETA: 7s - loss: 1.0803 - acc: 0.618 - ETA: 6s - loss: 1.0799 - acc: 0.618 - ETA: 6s - loss: 1.0803 - acc: 0.618 - ETA: 6s - loss: 1.0803 - acc: 0.618 - ETA: 6s - loss: 1.0791 - acc: 0.618 - ETA: 6s - loss: 1.0775 - acc: 0.619 - ETA: 6s - loss: 1.0767 - acc: 0.619 - ETA: 6s - loss: 1.0756 - acc: 0.620 - ETA: 6s - loss: 1.0760 - acc: 0.619 - ETA: 6s - loss: 1.0749 - acc: 0.620 - ETA: 6s - loss: 1.0754 - acc: 0.619 - ETA: 6s - loss: 1.0758 - acc: 0.619 - ETA: 6s - loss: 1.0746 - acc: 0.620 - ETA: 6s - loss: 1.0738 - acc: 0.620 - ETA: 6s - loss: 1.0750 - acc: 0.620 - ETA: 6s - loss: 1.0738 - acc: 0.621 - ETA: 6s - loss: 1.0748 - acc: 0.620 - ETA: 6s - loss: 1.0735 - acc: 0.621 - ETA: 6s - loss: 1.0727 - acc: 0.621 - ETA: 6s - loss: 1.0711 - acc: 0.622 - ETA: 5s - loss: 1.0714 - acc: 0.621 - ETA: 5s - loss: 1.0708 - acc: 0.622 - ETA: 5s - loss: 1.0708 - acc: 0.622 - ETA: 5s - loss: 1.0713 - acc: 0.622 - ETA: 5s - loss: 1.0706 - acc: 0.622 - ETA: 5s - loss: 1.0700 - acc: 0.623 - ETA: 5s - loss: 1.0697 - acc: 0.623 - ETA: 5s - loss: 1.0688 - acc: 0.623 - ETA: 5s - loss: 1.0693 - acc: 0.623 - ETA: 5s - loss: 1.0705 - acc: 0.622 - ETA: 5s - loss: 1.0707 - acc: 0.622 - ETA: 5s - loss: 1.0702 - acc: 0.623 - ETA: 5s - loss: 1.0698 - acc: 0.623 - ETA: 5s - loss: 1.0690 - acc: 0.623 - ETA: 5s - loss: 1.0691 - acc: 0.623 - ETA: 5s - loss: 1.0683 - acc: 0.623 - ETA: 5s - loss: 1.0682 - acc: 0.623 - ETA: 5s - loss: 1.0675 - acc: 0.623 - ETA: 4s - loss: 1.0674 - acc: 0.623 - ETA: 4s - loss: 1.0668 - acc: 0.623 - ETA: 4s - loss: 1.0659 - acc: 0.624 - ETA: 4s - loss: 1.0641 - acc: 0.624 - ETA: 4s - loss: 1.0640 - acc: 0.624 - ETA: 4s - loss: 1.0632 - acc: 0.625 - ETA: 4s - loss: 1.0629 - acc: 0.625 - ETA: 4s - loss: 1.0619 - acc: 0.625 - ETA: 4s - loss: 1.0616 - acc: 0.625 - ETA: 4s - loss: 1.0624 - acc: 0.624 - ETA: 4s - loss: 1.0628 - acc: 0.624 - ETA: 4s - loss: 1.0634 - acc: 0.624 - ETA: 4s - loss: 1.0627 - acc: 0.625 - ETA: 4s - loss: 1.0618 - acc: 0.625 - ETA: 4s - loss: 1.0627 - acc: 0.625 - ETA: 4s - loss: 1.0630 - acc: 0.625 - ETA: 4s - loss: 1.0626 - acc: 0.625 - ETA: 4s - loss: 1.0625 - acc: 0.625 - ETA: 4s - loss: 1.0623 - acc: 0.625 - ETA: 3s - loss: 1.0613 - acc: 0.625 - ETA: 3s - loss: 1.0620 - acc: 0.625 - ETA: 3s - loss: 1.0609 - acc: 0.625 - ETA: 3s - loss: 1.0604 - acc: 0.625 - ETA: 3s - loss: 1.0601 - acc: 0.625 - ETA: 3s - loss: 1.0607 - acc: 0.625 - ETA: 3s - loss: 1.0610 - acc: 0.625 - ETA: 3s - loss: 1.0617 - acc: 0.625 - ETA: 3s - loss: 1.0617 - acc: 0.625 - ETA: 3s - loss: 1.0612 - acc: 0.625 - ETA: 3s - loss: 1.0607 - acc: 0.625 - ETA: 3s - loss: 1.0607 - acc: 0.625 - ETA: 3s - loss: 1.0607 - acc: 0.625 - ETA: 3s - loss: 1.0602 - acc: 0.625 - ETA: 3s - loss: 1.0598 - acc: 0.625 - ETA: 3s - loss: 1.0596 - acc: 0.625 - ETA: 3s - loss: 1.0593 - acc: 0.626 - ETA: 3s - loss: 1.0592 - acc: 0.626 - ETA: 2s - loss: 1.0600 - acc: 0.625 - ETA: 2s - loss: 1.0596 - acc: 0.625 - ETA: 2s - loss: 1.0593 - acc: 0.626 - ETA: 2s - loss: 1.0596 - acc: 0.626 - ETA: 2s - loss: 1.0593 - acc: 0.626 - ETA: 2s - loss: 1.0592 - acc: 0.626 - ETA: 2s - loss: 1.0587 - acc: 0.626 - ETA: 2s - loss: 1.0579 - acc: 0.626 - ETA: 2s - loss: 1.0590 - acc: 0.626 - ETA: 2s - loss: 1.0591 - acc: 0.626 - ETA: 2s - loss: 1.0588 - acc: 0.626 - ETA: 2s - loss: 1.0592 - acc: 0.626 - ETA: 2s - loss: 1.0585 - acc: 0.626 - ETA: 2s - loss: 1.0587 - acc: 0.626 - ETA: 2s - loss: 1.0581 - acc: 0.626 - ETA: 2s - loss: 1.0584 - acc: 0.626 - ETA: 2s - loss: 1.0591 - acc: 0.626 - ETA: 2s - loss: 1.0586 - acc: 0.626 - ETA: 2s - loss: 1.0587 - acc: 0.626 - ETA: 1s - loss: 1.0589 - acc: 0.627 - ETA: 1s - loss: 1.0594 - acc: 0.626 - ETA: 1s - loss: 1.0584 - acc: 0.627 - ETA: 1s - loss: 1.0582 - acc: 0.627 - ETA: 1s - loss: 1.0578 - acc: 0.627 - ETA: 1s - loss: 1.0576 - acc: 0.627 - ETA: 1s - loss: 1.0579 - acc: 0.627 - ETA: 1s - loss: 1.0574 - acc: 0.627 - ETA: 1s - loss: 1.0582 - acc: 0.627 - ETA: 1s - loss: 1.0572 - acc: 0.627 - ETA: 1s - loss: 1.0578 - acc: 0.627 - ETA: 1s - loss: 1.0587 - acc: 0.626 - ETA: 1s - loss: 1.0588 - acc: 0.626 - ETA: 1s - loss: 1.0590 - acc: 0.626 - ETA: 1s - loss: 1.0593 - acc: 0.626 - ETA: 1s - loss: 1.0590 - acc: 0.626 - ETA: 1s - loss: 1.0587 - acc: 0.626 - ETA: 1s - loss: 1.0586 - acc: 0.626 - ETA: 1s - loss: 1.0585 - acc: 0.626 - ETA: 0s - loss: 1.0582 - acc: 0.626 - ETA: 0s - loss: 1.0579 - acc: 0.627 - ETA: 0s - loss: 1.0589 - acc: 0.626 - ETA: 0s - loss: 1.0587 - acc: 0.626 - ETA: 0s - loss: 1.0588 - acc: 0.626 - ETA: 0s - loss: 1.0591 - acc: 0.626 - ETA: 0s - loss: 1.0596 - acc: 0.626 - ETA: 0s - loss: 1.0594 - acc: 0.626 - ETA: 0s - loss: 1.0594 - acc: 0.626 - ETA: 0s - loss: 1.0593 - acc: 0.626 - ETA: 0s - loss: 1.0596 - acc: 0.626 - ETA: 0s - loss: 1.0596 - acc: 0.626 - ETA: 0s - loss: 1.0596 - acc: 0.626 - ETA: 0s - loss: 1.0592 - acc: 0.626 - ETA: 0s - loss: 1.0592 - acc: 0.626 - ETA: 0s - loss: 1.0590 - acc: 0.626 - ETA: 0s - loss: 1.0582 - acc: 0.627 - ETA: 0s - loss: 1.0582 - acc: 0.6270WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "45000/45000 [==============================] - 11s 254us/sample - loss: 1.0584 - acc: 0.6270 - val_loss: 0.9704 - val_acc: 0.6642\n",
      "Epoch 9/40\n",
      "44832/45000 [============================>.] - ETA: 15s - loss: 0.9835 - acc: 0.68 - ETA: 10s - loss: 1.1300 - acc: 0.57 - ETA: 10s - loss: 1.0443 - acc: 0.61 - ETA: 10s - loss: 1.0283 - acc: 0.61 - ETA: 10s - loss: 1.0815 - acc: 0.61 - ETA: 10s - loss: 1.0706 - acc: 0.61 - ETA: 10s - loss: 1.0653 - acc: 0.61 - ETA: 10s - loss: 1.0644 - acc: 0.62 - ETA: 10s - loss: 1.0577 - acc: 0.62 - ETA: 10s - loss: 1.0633 - acc: 0.62 - ETA: 10s - loss: 1.0508 - acc: 0.63 - ETA: 10s - loss: 1.0426 - acc: 0.63 - ETA: 10s - loss: 1.0430 - acc: 0.63 - ETA: 10s - loss: 1.0429 - acc: 0.63 - ETA: 10s - loss: 1.0455 - acc: 0.63 - ETA: 9s - loss: 1.0437 - acc: 0.6400 - ETA: 9s - loss: 1.0386 - acc: 0.641 - ETA: 9s - loss: 1.0421 - acc: 0.637 - ETA: 9s - loss: 1.0404 - acc: 0.636 - ETA: 9s - loss: 1.0454 - acc: 0.635 - ETA: 9s - loss: 1.0388 - acc: 0.637 - ETA: 9s - loss: 1.0374 - acc: 0.638 - ETA: 9s - loss: 1.0381 - acc: 0.638 - ETA: 9s - loss: 1.0366 - acc: 0.639 - ETA: 9s - loss: 1.0373 - acc: 0.638 - ETA: 9s - loss: 1.0396 - acc: 0.638 - ETA: 9s - loss: 1.0371 - acc: 0.640 - ETA: 9s - loss: 1.0317 - acc: 0.641 - ETA: 9s - loss: 1.0288 - acc: 0.641 - ETA: 9s - loss: 1.0262 - acc: 0.642 - ETA: 9s - loss: 1.0279 - acc: 0.640 - ETA: 9s - loss: 1.0251 - acc: 0.641 - ETA: 9s - loss: 1.0250 - acc: 0.639 - ETA: 9s - loss: 1.0232 - acc: 0.640 - ETA: 8s - loss: 1.0214 - acc: 0.640 - ETA: 8s - loss: 1.0230 - acc: 0.640 - ETA: 8s - loss: 1.0240 - acc: 0.640 - ETA: 8s - loss: 1.0198 - acc: 0.642 - ETA: 8s - loss: 1.0187 - acc: 0.643 - ETA: 8s - loss: 1.0195 - acc: 0.643 - ETA: 8s - loss: 1.0175 - acc: 0.642 - ETA: 8s - loss: 1.0192 - acc: 0.641 - ETA: 8s - loss: 1.0174 - acc: 0.642 - ETA: 8s - loss: 1.0187 - acc: 0.642 - ETA: 8s - loss: 1.0174 - acc: 0.643 - ETA: 8s - loss: 1.0186 - acc: 0.642 - ETA: 8s - loss: 1.0183 - acc: 0.641 - ETA: 8s - loss: 1.0174 - acc: 0.642 - ETA: 8s - loss: 1.0159 - acc: 0.643 - ETA: 8s - loss: 1.0150 - acc: 0.642 - ETA: 8s - loss: 1.0160 - acc: 0.642 - ETA: 8s - loss: 1.0160 - acc: 0.641 - ETA: 8s - loss: 1.0161 - acc: 0.641 - ETA: 7s - loss: 1.0164 - acc: 0.641 - ETA: 7s - loss: 1.0169 - acc: 0.642 - ETA: 7s - loss: 1.0171 - acc: 0.641 - ETA: 7s - loss: 1.0181 - acc: 0.641 - ETA: 7s - loss: 1.0168 - acc: 0.642 - ETA: 7s - loss: 1.0177 - acc: 0.642 - ETA: 7s - loss: 1.0171 - acc: 0.642 - ETA: 7s - loss: 1.0176 - acc: 0.642 - ETA: 7s - loss: 1.0173 - acc: 0.643 - ETA: 7s - loss: 1.0162 - acc: 0.643 - ETA: 7s - loss: 1.0152 - acc: 0.643 - ETA: 7s - loss: 1.0138 - acc: 0.644 - ETA: 7s - loss: 1.0123 - acc: 0.644 - ETA: 7s - loss: 1.0124 - acc: 0.644 - ETA: 7s - loss: 1.0136 - acc: 0.644 - ETA: 7s - loss: 1.0136 - acc: 0.644 - ETA: 7s - loss: 1.0146 - acc: 0.643 - ETA: 7s - loss: 1.0139 - acc: 0.644 - ETA: 6s - loss: 1.0142 - acc: 0.644 - ETA: 6s - loss: 1.0152 - acc: 0.643 - ETA: 6s - loss: 1.0180 - acc: 0.642 - ETA: 6s - loss: 1.0169 - acc: 0.642 - ETA: 6s - loss: 1.0172 - acc: 0.642 - ETA: 6s - loss: 1.0167 - acc: 0.643 - ETA: 6s - loss: 1.0190 - acc: 0.642 - ETA: 6s - loss: 1.0209 - acc: 0.642 - ETA: 6s - loss: 1.0205 - acc: 0.641 - ETA: 6s - loss: 1.0215 - acc: 0.641 - ETA: 6s - loss: 1.0210 - acc: 0.641 - ETA: 6s - loss: 1.0198 - acc: 0.641 - ETA: 6s - loss: 1.0192 - acc: 0.642 - ETA: 6s - loss: 1.0191 - acc: 0.642 - ETA: 6s - loss: 1.0201 - acc: 0.642 - ETA: 6s - loss: 1.0190 - acc: 0.642 - ETA: 6s - loss: 1.0182 - acc: 0.642 - ETA: 6s - loss: 1.0180 - acc: 0.643 - ETA: 6s - loss: 1.0156 - acc: 0.643 - ETA: 5s - loss: 1.0169 - acc: 0.643 - ETA: 5s - loss: 1.0178 - acc: 0.643 - ETA: 5s - loss: 1.0180 - acc: 0.643 - ETA: 5s - loss: 1.0180 - acc: 0.642 - ETA: 5s - loss: 1.0179 - acc: 0.642 - ETA: 5s - loss: 1.0185 - acc: 0.642 - ETA: 5s - loss: 1.0180 - acc: 0.642 - ETA: 5s - loss: 1.0196 - acc: 0.642 - ETA: 5s - loss: 1.0207 - acc: 0.641 - ETA: 5s - loss: 1.0206 - acc: 0.641 - ETA: 5s - loss: 1.0211 - acc: 0.640 - ETA: 5s - loss: 1.0213 - acc: 0.640 - ETA: 5s - loss: 1.0214 - acc: 0.640 - ETA: 5s - loss: 1.0209 - acc: 0.641 - ETA: 5s - loss: 1.0207 - acc: 0.641 - ETA: 5s - loss: 1.0212 - acc: 0.640 - ETA: 5s - loss: 1.0211 - acc: 0.640 - ETA: 5s - loss: 1.0218 - acc: 0.640 - ETA: 5s - loss: 1.0225 - acc: 0.640 - ETA: 4s - loss: 1.0236 - acc: 0.639 - ETA: 4s - loss: 1.0233 - acc: 0.640 - ETA: 4s - loss: 1.0237 - acc: 0.639 - ETA: 4s - loss: 1.0244 - acc: 0.639 - ETA: 4s - loss: 1.0238 - acc: 0.640 - ETA: 4s - loss: 1.0242 - acc: 0.639 - ETA: 4s - loss: 1.0239 - acc: 0.639 - ETA: 4s - loss: 1.0239 - acc: 0.639 - ETA: 4s - loss: 1.0244 - acc: 0.638 - ETA: 4s - loss: 1.0242 - acc: 0.638 - ETA: 4s - loss: 1.0239 - acc: 0.638 - ETA: 4s - loss: 1.0241 - acc: 0.638 - ETA: 4s - loss: 1.0236 - acc: 0.639 - ETA: 4s - loss: 1.0237 - acc: 0.638 - ETA: 4s - loss: 1.0234 - acc: 0.639 - ETA: 4s - loss: 1.0238 - acc: 0.638 - ETA: 4s - loss: 1.0235 - acc: 0.639 - ETA: 4s - loss: 1.0227 - acc: 0.639 - ETA: 3s - loss: 1.0222 - acc: 0.639 - ETA: 3s - loss: 1.0229 - acc: 0.639 - ETA: 3s - loss: 1.0223 - acc: 0.639 - ETA: 3s - loss: 1.0221 - acc: 0.639 - ETA: 3s - loss: 1.0226 - acc: 0.639 - ETA: 3s - loss: 1.0227 - acc: 0.639 - ETA: 3s - loss: 1.0226 - acc: 0.639 - ETA: 3s - loss: 1.0222 - acc: 0.639 - ETA: 3s - loss: 1.0217 - acc: 0.639 - ETA: 3s - loss: 1.0220 - acc: 0.639 - ETA: 3s - loss: 1.0219 - acc: 0.639 - ETA: 3s - loss: 1.0227 - acc: 0.639 - ETA: 3s - loss: 1.0223 - acc: 0.639 - ETA: 3s - loss: 1.0216 - acc: 0.639 - ETA: 3s - loss: 1.0218 - acc: 0.639 - ETA: 3s - loss: 1.0221 - acc: 0.639 - ETA: 3s - loss: 1.0228 - acc: 0.638 - ETA: 3s - loss: 1.0217 - acc: 0.639 - ETA: 2s - loss: 1.0215 - acc: 0.639 - ETA: 2s - loss: 1.0221 - acc: 0.638 - ETA: 2s - loss: 1.0220 - acc: 0.639 - ETA: 2s - loss: 1.0222 - acc: 0.639 - ETA: 2s - loss: 1.0221 - acc: 0.639 - ETA: 2s - loss: 1.0226 - acc: 0.639 - ETA: 2s - loss: 1.0224 - acc: 0.639 - ETA: 2s - loss: 1.0228 - acc: 0.638 - ETA: 2s - loss: 1.0224 - acc: 0.639 - ETA: 2s - loss: 1.0226 - acc: 0.638 - ETA: 2s - loss: 1.0227 - acc: 0.638 - ETA: 2s - loss: 1.0222 - acc: 0.638 - ETA: 2s - loss: 1.0226 - acc: 0.638 - ETA: 2s - loss: 1.0221 - acc: 0.639 - ETA: 2s - loss: 1.0215 - acc: 0.639 - ETA: 2s - loss: 1.0209 - acc: 0.639 - ETA: 2s - loss: 1.0211 - acc: 0.639 - ETA: 2s - loss: 1.0198 - acc: 0.639 - ETA: 2s - loss: 1.0196 - acc: 0.639 - ETA: 1s - loss: 1.0202 - acc: 0.639 - ETA: 1s - loss: 1.0201 - acc: 0.639 - ETA: 1s - loss: 1.0200 - acc: 0.639 - ETA: 1s - loss: 1.0206 - acc: 0.639 - ETA: 1s - loss: 1.0200 - acc: 0.639 - ETA: 1s - loss: 1.0200 - acc: 0.639 - ETA: 1s - loss: 1.0196 - acc: 0.640 - ETA: 1s - loss: 1.0190 - acc: 0.640 - ETA: 1s - loss: 1.0192 - acc: 0.640 - ETA: 1s - loss: 1.0182 - acc: 0.640 - ETA: 1s - loss: 1.0178 - acc: 0.640 - ETA: 1s - loss: 1.0175 - acc: 0.640 - ETA: 1s - loss: 1.0171 - acc: 0.640 - ETA: 1s - loss: 1.0169 - acc: 0.641 - ETA: 1s - loss: 1.0173 - acc: 0.640 - ETA: 1s - loss: 1.0177 - acc: 0.640 - ETA: 1s - loss: 1.0173 - acc: 0.640 - ETA: 1s - loss: 1.0172 - acc: 0.640 - ETA: 1s - loss: 1.0168 - acc: 0.641 - ETA: 0s - loss: 1.0170 - acc: 0.641 - ETA: 0s - loss: 1.0171 - acc: 0.640 - ETA: 0s - loss: 1.0171 - acc: 0.640 - ETA: 0s - loss: 1.0173 - acc: 0.640 - ETA: 0s - loss: 1.0161 - acc: 0.641 - ETA: 0s - loss: 1.0160 - acc: 0.641 - ETA: 0s - loss: 1.0155 - acc: 0.641 - ETA: 0s - loss: 1.0159 - acc: 0.641 - ETA: 0s - loss: 1.0154 - acc: 0.641 - ETA: 0s - loss: 1.0147 - acc: 0.641 - ETA: 0s - loss: 1.0149 - acc: 0.641 - ETA: 0s - loss: 1.0149 - acc: 0.641 - ETA: 0s - loss: 1.0146 - acc: 0.641 - ETA: 0s - loss: 1.0144 - acc: 0.641 - ETA: 0s - loss: 1.0137 - acc: 0.641 - ETA: 0s - loss: 1.0131 - acc: 0.641 - ETA: 0s - loss: 1.0133 - acc: 0.641 - ETA: 0s - loss: 1.0134 - acc: 0.6418WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "45000/45000 [==============================] - 11s 254us/sample - loss: 1.0135 - acc: 0.6418 - val_loss: 0.9459 - val_acc: 0.6754\n",
      "Epoch 10/40\n",
      "44832/45000 [============================>.] - ETA: 14s - loss: 1.2963 - acc: 0.50 - ETA: 11s - loss: 0.9624 - acc: 0.60 - ETA: 10s - loss: 1.0046 - acc: 0.61 - ETA: 10s - loss: 0.9830 - acc: 0.63 - ETA: 10s - loss: 1.0084 - acc: 0.63 - ETA: 10s - loss: 0.9817 - acc: 0.64 - ETA: 10s - loss: 0.9687 - acc: 0.65 - ETA: 10s - loss: 0.9848 - acc: 0.65 - ETA: 10s - loss: 0.9884 - acc: 0.65 - ETA: 10s - loss: 0.9879 - acc: 0.64 - ETA: 10s - loss: 0.9934 - acc: 0.64 - ETA: 10s - loss: 0.9901 - acc: 0.64 - ETA: 10s - loss: 0.9823 - acc: 0.64 - ETA: 10s - loss: 0.9855 - acc: 0.64 - ETA: 10s - loss: 0.9872 - acc: 0.64 - ETA: 9s - loss: 0.9794 - acc: 0.6471 - ETA: 9s - loss: 0.9808 - acc: 0.647 - ETA: 9s - loss: 0.9831 - acc: 0.645 - ETA: 9s - loss: 0.9775 - acc: 0.648 - ETA: 9s - loss: 0.9822 - acc: 0.646 - ETA: 9s - loss: 0.9861 - acc: 0.647 - ETA: 9s - loss: 0.9840 - acc: 0.650 - ETA: 9s - loss: 0.9766 - acc: 0.654 - ETA: 9s - loss: 0.9706 - acc: 0.656 - ETA: 9s - loss: 0.9705 - acc: 0.655 - ETA: 9s - loss: 0.9705 - acc: 0.656 - ETA: 9s - loss: 0.9730 - acc: 0.656 - ETA: 9s - loss: 0.9763 - acc: 0.655 - ETA: 9s - loss: 0.9822 - acc: 0.652 - ETA: 9s - loss: 0.9817 - acc: 0.653 - ETA: 9s - loss: 0.9860 - acc: 0.651 - ETA: 9s - loss: 0.9846 - acc: 0.651 - ETA: 9s - loss: 0.9874 - acc: 0.651 - ETA: 9s - loss: 0.9868 - acc: 0.652 - ETA: 8s - loss: 0.9838 - acc: 0.654 - ETA: 8s - loss: 0.9830 - acc: 0.655 - ETA: 8s - loss: 0.9802 - acc: 0.654 - ETA: 8s - loss: 0.9804 - acc: 0.653 - ETA: 8s - loss: 0.9810 - acc: 0.653 - ETA: 8s - loss: 0.9774 - acc: 0.654 - ETA: 8s - loss: 0.9759 - acc: 0.655 - ETA: 8s - loss: 0.9743 - acc: 0.654 - ETA: 8s - loss: 0.9740 - acc: 0.654 - ETA: 8s - loss: 0.9750 - acc: 0.654 - ETA: 8s - loss: 0.9741 - acc: 0.655 - ETA: 8s - loss: 0.9751 - acc: 0.655 - ETA: 8s - loss: 0.9760 - acc: 0.654 - ETA: 8s - loss: 0.9780 - acc: 0.653 - ETA: 8s - loss: 0.9808 - acc: 0.652 - ETA: 8s - loss: 0.9814 - acc: 0.652 - ETA: 8s - loss: 0.9791 - acc: 0.653 - ETA: 8s - loss: 0.9776 - acc: 0.654 - ETA: 7s - loss: 0.9797 - acc: 0.654 - ETA: 7s - loss: 0.9813 - acc: 0.653 - ETA: 7s - loss: 0.9808 - acc: 0.653 - ETA: 7s - loss: 0.9814 - acc: 0.653 - ETA: 7s - loss: 0.9803 - acc: 0.653 - ETA: 7s - loss: 0.9822 - acc: 0.653 - ETA: 7s - loss: 0.9839 - acc: 0.652 - ETA: 7s - loss: 0.9836 - acc: 0.652 - ETA: 7s - loss: 0.9830 - acc: 0.652 - ETA: 7s - loss: 0.9850 - acc: 0.652 - ETA: 7s - loss: 0.9850 - acc: 0.652 - ETA: 7s - loss: 0.9832 - acc: 0.653 - ETA: 7s - loss: 0.9838 - acc: 0.653 - ETA: 7s - loss: 0.9833 - acc: 0.653 - ETA: 7s - loss: 0.9840 - acc: 0.653 - ETA: 7s - loss: 0.9833 - acc: 0.654 - ETA: 7s - loss: 0.9829 - acc: 0.654 - ETA: 7s - loss: 0.9819 - acc: 0.654 - ETA: 7s - loss: 0.9812 - acc: 0.655 - ETA: 6s - loss: 0.9799 - acc: 0.655 - ETA: 6s - loss: 0.9783 - acc: 0.656 - ETA: 6s - loss: 0.9787 - acc: 0.656 - ETA: 6s - loss: 0.9781 - acc: 0.656 - ETA: 6s - loss: 0.9759 - acc: 0.657 - ETA: 6s - loss: 0.9756 - acc: 0.658 - ETA: 6s - loss: 0.9742 - acc: 0.658 - ETA: 6s - loss: 0.9729 - acc: 0.658 - ETA: 6s - loss: 0.9716 - acc: 0.659 - ETA: 6s - loss: 0.9724 - acc: 0.659 - ETA: 6s - loss: 0.9731 - acc: 0.659 - ETA: 6s - loss: 0.9742 - acc: 0.658 - ETA: 6s - loss: 0.9727 - acc: 0.659 - ETA: 6s - loss: 0.9730 - acc: 0.659 - ETA: 6s - loss: 0.9743 - acc: 0.658 - ETA: 6s - loss: 0.9748 - acc: 0.658 - ETA: 6s - loss: 0.9743 - acc: 0.658 - ETA: 6s - loss: 0.9751 - acc: 0.658 - ETA: 6s - loss: 0.9763 - acc: 0.657 - ETA: 5s - loss: 0.9771 - acc: 0.657 - ETA: 5s - loss: 0.9768 - acc: 0.657 - ETA: 5s - loss: 0.9767 - acc: 0.657 - ETA: 5s - loss: 0.9764 - acc: 0.657 - ETA: 5s - loss: 0.9752 - acc: 0.657 - ETA: 5s - loss: 0.9741 - acc: 0.658 - ETA: 5s - loss: 0.9727 - acc: 0.658 - ETA: 5s - loss: 0.9724 - acc: 0.658 - ETA: 5s - loss: 0.9712 - acc: 0.658 - ETA: 5s - loss: 0.9722 - acc: 0.658 - ETA: 5s - loss: 0.9716 - acc: 0.658 - ETA: 5s - loss: 0.9717 - acc: 0.658 - ETA: 5s - loss: 0.9720 - acc: 0.658 - ETA: 5s - loss: 0.9725 - acc: 0.657 - ETA: 5s - loss: 0.9744 - acc: 0.657 - ETA: 5s - loss: 0.9746 - acc: 0.657 - ETA: 5s - loss: 0.9739 - acc: 0.657 - ETA: 5s - loss: 0.9734 - acc: 0.658 - ETA: 4s - loss: 0.9728 - acc: 0.658 - ETA: 4s - loss: 0.9732 - acc: 0.658 - ETA: 4s - loss: 0.9729 - acc: 0.658 - ETA: 4s - loss: 0.9719 - acc: 0.658 - ETA: 4s - loss: 0.9709 - acc: 0.658 - ETA: 4s - loss: 0.9710 - acc: 0.658 - ETA: 4s - loss: 0.9720 - acc: 0.658 - ETA: 4s - loss: 0.9726 - acc: 0.657 - ETA: 4s - loss: 0.9731 - acc: 0.657 - ETA: 4s - loss: 0.9735 - acc: 0.657 - ETA: 4s - loss: 0.9725 - acc: 0.657 - ETA: 4s - loss: 0.9724 - acc: 0.657 - ETA: 4s - loss: 0.9726 - acc: 0.657 - ETA: 4s - loss: 0.9715 - acc: 0.658 - ETA: 4s - loss: 0.9721 - acc: 0.657 - ETA: 4s - loss: 0.9720 - acc: 0.657 - ETA: 4s - loss: 0.9728 - acc: 0.657 - ETA: 4s - loss: 0.9732 - acc: 0.657 - ETA: 4s - loss: 0.9733 - acc: 0.656 - ETA: 3s - loss: 0.9739 - acc: 0.656 - ETA: 3s - loss: 0.9742 - acc: 0.656 - ETA: 3s - loss: 0.9738 - acc: 0.656 - ETA: 3s - loss: 0.9745 - acc: 0.656 - ETA: 3s - loss: 0.9747 - acc: 0.656 - ETA: 3s - loss: 0.9752 - acc: 0.656 - ETA: 3s - loss: 0.9747 - acc: 0.656 - ETA: 3s - loss: 0.9754 - acc: 0.656 - ETA: 3s - loss: 0.9759 - acc: 0.656 - ETA: 3s - loss: 0.9761 - acc: 0.655 - ETA: 3s - loss: 0.9760 - acc: 0.655 - ETA: 3s - loss: 0.9767 - acc: 0.655 - ETA: 3s - loss: 0.9765 - acc: 0.655 - ETA: 3s - loss: 0.9764 - acc: 0.655 - ETA: 3s - loss: 0.9761 - acc: 0.655 - ETA: 3s - loss: 0.9764 - acc: 0.655 - ETA: 3s - loss: 0.9774 - acc: 0.654 - ETA: 3s - loss: 0.9778 - acc: 0.654 - ETA: 2s - loss: 0.9783 - acc: 0.654 - ETA: 2s - loss: 0.9783 - acc: 0.654 - ETA: 2s - loss: 0.9786 - acc: 0.654 - ETA: 2s - loss: 0.9779 - acc: 0.654 - ETA: 2s - loss: 0.9782 - acc: 0.654 - ETA: 2s - loss: 0.9791 - acc: 0.654 - ETA: 2s - loss: 0.9792 - acc: 0.654 - ETA: 2s - loss: 0.9792 - acc: 0.654 - ETA: 2s - loss: 0.9788 - acc: 0.654 - ETA: 2s - loss: 0.9782 - acc: 0.654 - ETA: 2s - loss: 0.9781 - acc: 0.655 - ETA: 2s - loss: 0.9781 - acc: 0.654 - ETA: 2s - loss: 0.9776 - acc: 0.655 - ETA: 2s - loss: 0.9775 - acc: 0.655 - ETA: 2s - loss: 0.9784 - acc: 0.655 - ETA: 2s - loss: 0.9774 - acc: 0.655 - ETA: 2s - loss: 0.9771 - acc: 0.655 - ETA: 2s - loss: 0.9776 - acc: 0.655 - ETA: 2s - loss: 0.9772 - acc: 0.655 - ETA: 1s - loss: 0.9769 - acc: 0.655 - ETA: 1s - loss: 0.9769 - acc: 0.655 - ETA: 1s - loss: 0.9765 - acc: 0.656 - ETA: 1s - loss: 0.9769 - acc: 0.656 - ETA: 1s - loss: 0.9769 - acc: 0.656 - ETA: 1s - loss: 0.9770 - acc: 0.655 - ETA: 1s - loss: 0.9764 - acc: 0.656 - ETA: 1s - loss: 0.9777 - acc: 0.655 - ETA: 1s - loss: 0.9781 - acc: 0.655 - ETA: 1s - loss: 0.9779 - acc: 0.655 - ETA: 1s - loss: 0.9779 - acc: 0.655 - ETA: 1s - loss: 0.9782 - acc: 0.655 - ETA: 1s - loss: 0.9786 - acc: 0.655 - ETA: 1s - loss: 0.9788 - acc: 0.655 - ETA: 1s - loss: 0.9780 - acc: 0.655 - ETA: 1s - loss: 0.9781 - acc: 0.655 - ETA: 1s - loss: 0.9778 - acc: 0.655 - ETA: 1s - loss: 0.9776 - acc: 0.655 - ETA: 1s - loss: 0.9769 - acc: 0.655 - ETA: 0s - loss: 0.9762 - acc: 0.656 - ETA: 0s - loss: 0.9762 - acc: 0.656 - ETA: 0s - loss: 0.9761 - acc: 0.656 - ETA: 0s - loss: 0.9763 - acc: 0.656 - ETA: 0s - loss: 0.9761 - acc: 0.656 - ETA: 0s - loss: 0.9760 - acc: 0.656 - ETA: 0s - loss: 0.9756 - acc: 0.656 - ETA: 0s - loss: 0.9753 - acc: 0.656 - ETA: 0s - loss: 0.9750 - acc: 0.656 - ETA: 0s - loss: 0.9760 - acc: 0.655 - ETA: 0s - loss: 0.9758 - acc: 0.655 - ETA: 0s - loss: 0.9758 - acc: 0.656 - ETA: 0s - loss: 0.9759 - acc: 0.656 - ETA: 0s - loss: 0.9760 - acc: 0.656 - ETA: 0s - loss: 0.9765 - acc: 0.655 - ETA: 0s - loss: 0.9769 - acc: 0.655 - ETA: 0s - loss: 0.9770 - acc: 0.655 - ETA: 0s - loss: 0.9774 - acc: 0.6556WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "45000/45000 [==============================] - 11s 254us/sample - loss: 0.9774 - acc: 0.6556 - val_loss: 0.9327 - val_acc: 0.6684\n",
      "Epoch 11/40\n",
      "44992/45000 [============================>.] - ETA: 14s - loss: 0.7279 - acc: 0.68 - ETA: 11s - loss: 0.9115 - acc: 0.66 - ETA: 10s - loss: 0.9391 - acc: 0.66 - ETA: 10s - loss: 0.9517 - acc: 0.66 - ETA: 10s - loss: 0.9597 - acc: 0.66 - ETA: 10s - loss: 0.9399 - acc: 0.67 - ETA: 10s - loss: 0.9599 - acc: 0.66 - ETA: 10s - loss: 0.9683 - acc: 0.66 - ETA: 10s - loss: 0.9583 - acc: 0.66 - ETA: 10s - loss: 0.9541 - acc: 0.66 - ETA: 10s - loss: 0.9428 - acc: 0.66 - ETA: 10s - loss: 0.9341 - acc: 0.67 - ETA: 10s - loss: 0.9445 - acc: 0.67 - ETA: 10s - loss: 0.9444 - acc: 0.66 - ETA: 10s - loss: 0.9421 - acc: 0.66 - ETA: 9s - loss: 0.9451 - acc: 0.6642 - ETA: 9s - loss: 0.9456 - acc: 0.665 - ETA: 9s - loss: 0.9388 - acc: 0.669 - ETA: 9s - loss: 0.9368 - acc: 0.669 - ETA: 9s - loss: 0.9373 - acc: 0.668 - ETA: 9s - loss: 0.9361 - acc: 0.669 - ETA: 9s - loss: 0.9340 - acc: 0.671 - ETA: 9s - loss: 0.9414 - acc: 0.667 - ETA: 9s - loss: 0.9418 - acc: 0.667 - ETA: 9s - loss: 0.9399 - acc: 0.669 - ETA: 9s - loss: 0.9381 - acc: 0.669 - ETA: 9s - loss: 0.9414 - acc: 0.669 - ETA: 9s - loss: 0.9478 - acc: 0.667 - ETA: 9s - loss: 0.9477 - acc: 0.668 - ETA: 9s - loss: 0.9532 - acc: 0.665 - ETA: 9s - loss: 0.9492 - acc: 0.668 - ETA: 9s - loss: 0.9535 - acc: 0.666 - ETA: 9s - loss: 0.9487 - acc: 0.668 - ETA: 8s - loss: 0.9531 - acc: 0.666 - ETA: 8s - loss: 0.9519 - acc: 0.666 - ETA: 8s - loss: 0.9522 - acc: 0.666 - ETA: 8s - loss: 0.9521 - acc: 0.667 - ETA: 8s - loss: 0.9537 - acc: 0.666 - ETA: 8s - loss: 0.9542 - acc: 0.666 - ETA: 8s - loss: 0.9563 - acc: 0.666 - ETA: 8s - loss: 0.9614 - acc: 0.663 - ETA: 8s - loss: 0.9596 - acc: 0.664 - ETA: 8s - loss: 0.9613 - acc: 0.664 - ETA: 8s - loss: 0.9627 - acc: 0.663 - ETA: 8s - loss: 0.9619 - acc: 0.663 - ETA: 8s - loss: 0.9618 - acc: 0.663 - ETA: 8s - loss: 0.9630 - acc: 0.663 - ETA: 8s - loss: 0.9624 - acc: 0.662 - ETA: 8s - loss: 0.9603 - acc: 0.663 - ETA: 8s - loss: 0.9587 - acc: 0.663 - ETA: 7s - loss: 0.9553 - acc: 0.665 - ETA: 7s - loss: 0.9552 - acc: 0.664 - ETA: 7s - loss: 0.9541 - acc: 0.665 - ETA: 7s - loss: 0.9545 - acc: 0.665 - ETA: 7s - loss: 0.9517 - acc: 0.665 - ETA: 7s - loss: 0.9514 - acc: 0.665 - ETA: 7s - loss: 0.9502 - acc: 0.665 - ETA: 7s - loss: 0.9505 - acc: 0.665 - ETA: 7s - loss: 0.9504 - acc: 0.665 - ETA: 7s - loss: 0.9499 - acc: 0.665 - ETA: 7s - loss: 0.9517 - acc: 0.664 - ETA: 7s - loss: 0.9502 - acc: 0.664 - ETA: 7s - loss: 0.9482 - acc: 0.666 - ETA: 6s - loss: 0.9503 - acc: 0.665 - ETA: 6s - loss: 0.9492 - acc: 0.665 - ETA: 6s - loss: 0.9515 - acc: 0.664 - ETA: 6s - loss: 0.9526 - acc: 0.664 - ETA: 6s - loss: 0.9532 - acc: 0.663 - ETA: 6s - loss: 0.9543 - acc: 0.663 - ETA: 6s - loss: 0.9540 - acc: 0.663 - ETA: 6s - loss: 0.9571 - acc: 0.662 - ETA: 6s - loss: 0.9569 - acc: 0.662 - ETA: 6s - loss: 0.9581 - acc: 0.661 - ETA: 6s - loss: 0.9568 - acc: 0.662 - ETA: 6s - loss: 0.9546 - acc: 0.663 - ETA: 6s - loss: 0.9542 - acc: 0.663 - ETA: 6s - loss: 0.9538 - acc: 0.663 - ETA: 6s - loss: 0.9531 - acc: 0.663 - ETA: 6s - loss: 0.9520 - acc: 0.664 - ETA: 6s - loss: 0.9529 - acc: 0.664 - ETA: 6s - loss: 0.9545 - acc: 0.663 - ETA: 6s - loss: 0.9546 - acc: 0.663 - ETA: 5s - loss: 0.9555 - acc: 0.663 - ETA: 5s - loss: 0.9551 - acc: 0.663 - ETA: 5s - loss: 0.9543 - acc: 0.663 - ETA: 5s - loss: 0.9541 - acc: 0.663 - ETA: 5s - loss: 0.9543 - acc: 0.663 - ETA: 5s - loss: 0.9542 - acc: 0.663 - ETA: 5s - loss: 0.9547 - acc: 0.663 - ETA: 5s - loss: 0.9553 - acc: 0.663 - ETA: 5s - loss: 0.9556 - acc: 0.663 - ETA: 5s - loss: 0.9543 - acc: 0.663 - ETA: 5s - loss: 0.9542 - acc: 0.663 - ETA: 5s - loss: 0.9548 - acc: 0.662 - ETA: 5s - loss: 0.9546 - acc: 0.663 - ETA: 5s - loss: 0.9560 - acc: 0.662 - ETA: 5s - loss: 0.9572 - acc: 0.662 - ETA: 5s - loss: 0.9575 - acc: 0.662 - ETA: 5s - loss: 0.9578 - acc: 0.662 - ETA: 5s - loss: 0.9584 - acc: 0.662 - ETA: 5s - loss: 0.9583 - acc: 0.662 - ETA: 5s - loss: 0.9576 - acc: 0.662 - ETA: 4s - loss: 0.9580 - acc: 0.662 - ETA: 4s - loss: 0.9577 - acc: 0.662 - ETA: 4s - loss: 0.9558 - acc: 0.663 - ETA: 4s - loss: 0.9557 - acc: 0.663 - ETA: 4s - loss: 0.9556 - acc: 0.663 - ETA: 4s - loss: 0.9560 - acc: 0.663 - ETA: 4s - loss: 0.9558 - acc: 0.663 - ETA: 4s - loss: 0.9550 - acc: 0.663 - ETA: 4s - loss: 0.9549 - acc: 0.663 - ETA: 4s - loss: 0.9538 - acc: 0.663 - ETA: 4s - loss: 0.9538 - acc: 0.663 - ETA: 4s - loss: 0.9527 - acc: 0.663 - ETA: 4s - loss: 0.9534 - acc: 0.663 - ETA: 4s - loss: 0.9533 - acc: 0.663 - ETA: 4s - loss: 0.9532 - acc: 0.663 - ETA: 4s - loss: 0.9536 - acc: 0.662 - ETA: 4s - loss: 0.9532 - acc: 0.662 - ETA: 4s - loss: 0.9522 - acc: 0.663 - ETA: 4s - loss: 0.9519 - acc: 0.663 - ETA: 4s - loss: 0.9521 - acc: 0.663 - ETA: 3s - loss: 0.9518 - acc: 0.663 - ETA: 3s - loss: 0.9519 - acc: 0.663 - ETA: 3s - loss: 0.9526 - acc: 0.663 - ETA: 3s - loss: 0.9531 - acc: 0.663 - ETA: 3s - loss: 0.9530 - acc: 0.663 - ETA: 3s - loss: 0.9532 - acc: 0.663 - ETA: 3s - loss: 0.9536 - acc: 0.663 - ETA: 3s - loss: 0.9536 - acc: 0.663 - ETA: 3s - loss: 0.9537 - acc: 0.663 - ETA: 3s - loss: 0.9535 - acc: 0.663 - ETA: 3s - loss: 0.9535 - acc: 0.663 - ETA: 3s - loss: 0.9534 - acc: 0.663 - ETA: 3s - loss: 0.9542 - acc: 0.662 - ETA: 3s - loss: 0.9543 - acc: 0.662 - ETA: 3s - loss: 0.9542 - acc: 0.662 - ETA: 3s - loss: 0.9546 - acc: 0.662 - ETA: 3s - loss: 0.9544 - acc: 0.662 - ETA: 3s - loss: 0.9544 - acc: 0.662 - ETA: 3s - loss: 0.9539 - acc: 0.663 - ETA: 2s - loss: 0.9537 - acc: 0.663 - ETA: 2s - loss: 0.9539 - acc: 0.662 - ETA: 2s - loss: 0.9539 - acc: 0.663 - ETA: 2s - loss: 0.9534 - acc: 0.663 - ETA: 2s - loss: 0.9540 - acc: 0.663 - ETA: 2s - loss: 0.9548 - acc: 0.662 - ETA: 2s - loss: 0.9545 - acc: 0.663 - ETA: 2s - loss: 0.9546 - acc: 0.663 - ETA: 2s - loss: 0.9547 - acc: 0.663 - ETA: 2s - loss: 0.9554 - acc: 0.662 - ETA: 2s - loss: 0.9551 - acc: 0.662 - ETA: 2s - loss: 0.9549 - acc: 0.662 - ETA: 2s - loss: 0.9548 - acc: 0.662 - ETA: 2s - loss: 0.9548 - acc: 0.662 - ETA: 2s - loss: 0.9542 - acc: 0.663 - ETA: 2s - loss: 0.9543 - acc: 0.663 - ETA: 2s - loss: 0.9543 - acc: 0.663 - ETA: 2s - loss: 0.9546 - acc: 0.663 - ETA: 2s - loss: 0.9549 - acc: 0.663 - ETA: 1s - loss: 0.9550 - acc: 0.662 - ETA: 1s - loss: 0.9544 - acc: 0.663 - ETA: 1s - loss: 0.9538 - acc: 0.663 - ETA: 1s - loss: 0.9542 - acc: 0.663 - ETA: 1s - loss: 0.9541 - acc: 0.663 - ETA: 1s - loss: 0.9534 - acc: 0.663 - ETA: 1s - loss: 0.9536 - acc: 0.663 - ETA: 1s - loss: 0.9534 - acc: 0.663 - ETA: 1s - loss: 0.9534 - acc: 0.663 - ETA: 1s - loss: 0.9539 - acc: 0.663 - ETA: 1s - loss: 0.9537 - acc: 0.663 - ETA: 1s - loss: 0.9535 - acc: 0.663 - ETA: 1s - loss: 0.9536 - acc: 0.663 - ETA: 1s - loss: 0.9532 - acc: 0.663 - ETA: 1s - loss: 0.9527 - acc: 0.663 - ETA: 1s - loss: 0.9527 - acc: 0.663 - ETA: 1s - loss: 0.9519 - acc: 0.663 - ETA: 1s - loss: 0.9519 - acc: 0.664 - ETA: 1s - loss: 0.9519 - acc: 0.664 - ETA: 1s - loss: 0.9519 - acc: 0.664 - ETA: 0s - loss: 0.9520 - acc: 0.664 - ETA: 0s - loss: 0.9523 - acc: 0.664 - ETA: 0s - loss: 0.9519 - acc: 0.664 - ETA: 0s - loss: 0.9518 - acc: 0.664 - ETA: 0s - loss: 0.9525 - acc: 0.664 - ETA: 0s - loss: 0.9532 - acc: 0.663 - ETA: 0s - loss: 0.9531 - acc: 0.663 - ETA: 0s - loss: 0.9532 - acc: 0.663 - ETA: 0s - loss: 0.9529 - acc: 0.663 - ETA: 0s - loss: 0.9536 - acc: 0.663 - ETA: 0s - loss: 0.9541 - acc: 0.663 - ETA: 0s - loss: 0.9542 - acc: 0.663 - ETA: 0s - loss: 0.9541 - acc: 0.663 - ETA: 0s - loss: 0.9541 - acc: 0.663 - ETA: 0s - loss: 0.9537 - acc: 0.663 - ETA: 0s - loss: 0.9539 - acc: 0.663 - ETA: 0s - loss: 0.9536 - acc: 0.663 - ETA: 0s - loss: 0.9537 - acc: 0.663 - ETA: 0s - loss: 0.9535 - acc: 0.6633WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "45000/45000 [==============================] - 11s 249us/sample - loss: 0.9534 - acc: 0.6633 - val_loss: 0.8978 - val_acc: 0.6838\n",
      "Epoch 12/40\n",
      "44832/45000 [============================>.] - ETA: 14s - loss: 0.6397 - acc: 0.81 - ETA: 11s - loss: 0.8811 - acc: 0.67 - ETA: 10s - loss: 0.8603 - acc: 0.69 - ETA: 10s - loss: 0.8847 - acc: 0.69 - ETA: 10s - loss: 0.9050 - acc: 0.68 - ETA: 10s - loss: 0.8997 - acc: 0. - ETA: 9s - loss: 0.6259 - acc: 0.7746 - ETA: 9s - loss: 0.6348 - acc: 0.771 - ETA: 9s - loss: 0.6375 - acc: 0.770 - ETA: 9s - loss: 0.6410 - acc: 0.770 - ETA: 9s - loss: 0.6388 - acc: 0.771 - ETA: 9s - loss: 0.6432 - acc: 0.770 - ETA: 9s - loss: 0.6427 - acc: 0.770 - ETA: 9s - loss: 0.6476 - acc: 0.769 - ETA: 9s - loss: 0.6462 - acc: 0.770 - ETA: 9s - loss: 0.6430 - acc: 0.771 - ETA: 9s - loss: 0.6441 - acc: 0.771 - ETA: 9s - loss: 0.6367 - acc: 0.773 - ETA: 9s - loss: 0.6373 - acc: 0.773 - ETA: 9s - loss: 0.6345 - acc: 0.774 - ETA: 9s - loss: 0.6370 - acc: 0.773 - ETA: 9s - loss: 0.6352 - acc: 0.773 - ETA: 9s - loss: 0.6332 - acc: 0.774 - ETA: 9s - loss: 0.6334 - acc: 0.774 - ETA: 9s - loss: 0.6372 - acc: 0.772 - ETA: 8s - loss: 0.6388 - acc: 0.772 - ETA: 8s - loss: 0.6401 - acc: 0.770 - ETA: 8s - loss: 0.6393 - acc: 0.770 - ETA: 8s - loss: 0.6420 - acc: 0.769 - ETA: 8s - loss: 0.6455 - acc: 0.768 - ETA: 8s - loss: 0.6458 - acc: 0.768 - ETA: 8s - loss: 0.6478 - acc: 0.767 - ETA: 8s - loss: 0.6484 - acc: 0.767 - ETA: 8s - loss: 0.6483 - acc: 0.768 - ETA: 8s - loss: 0.6478 - acc: 0.768 - ETA: 8s - loss: 0.6463 - acc: 0.768 - ETA: 8s - loss: 0.6460 - acc: 0.768 - ETA: 8s - loss: 0.6472 - acc: 0.768 - ETA: 8s - loss: 0.6460 - acc: 0.768 - ETA: 8s - loss: 0.6452 - acc: 0.769 - ETA: 8s - loss: 0.6450 - acc: 0.769 - ETA: 8s - loss: 0.6466 - acc: 0.769 - ETA: 8s - loss: 0.6490 - acc: 0.768 - ETA: 8s - loss: 0.6513 - acc: 0.767 - ETA: 7s - loss: 0.6506 - acc: 0.767 - ETA: 7s - loss: 0.6502 - acc: 0.767 - ETA: 7s - loss: 0.6502 - acc: 0.766 - ETA: 7s - loss: 0.6498 - acc: 0.766 - ETA: 7s - loss: 0.6489 - acc: 0.767 - ETA: 7s - loss: 0.6490 - acc: 0.766 - ETA: 7s - loss: 0.6505 - acc: 0.766 - ETA: 7s - loss: 0.6508 - acc: 0.766 - ETA: 7s - loss: 0.6502 - acc: 0.766 - ETA: 7s - loss: 0.6494 - acc: 0.766 - ETA: 7s - loss: 0.6481 - acc: 0.766 - ETA: 7s - loss: 0.6488 - acc: 0.766 - ETA: 7s - loss: 0.6488 - acc: 0.766 - ETA: 7s - loss: 0.6485 - acc: 0.766 - ETA: 7s - loss: 0.6498 - acc: 0.766 - ETA: 7s - loss: 0.6507 - acc: 0.766 - ETA: 7s - loss: 0.6510 - acc: 0.765 - ETA: 7s - loss: 0.6497 - acc: 0.766 - ETA: 6s - loss: 0.6502 - acc: 0.765 - ETA: 6s - loss: 0.6496 - acc: 0.766 - ETA: 6s - loss: 0.6500 - acc: 0.766 - ETA: 6s - loss: 0.6504 - acc: 0.766 - ETA: 6s - loss: 0.6509 - acc: 0.766 - ETA: 6s - loss: 0.6516 - acc: 0.766 - ETA: 6s - loss: 0.6500 - acc: 0.766 - ETA: 6s - loss: 0.6509 - acc: 0.766 - ETA: 6s - loss: 0.6517 - acc: 0.766 - ETA: 6s - loss: 0.6506 - acc: 0.767 - ETA: 6s - loss: 0.6503 - acc: 0.766 - ETA: 6s - loss: 0.6490 - acc: 0.767 - ETA: 6s - loss: 0.6495 - acc: 0.767 - ETA: 6s - loss: 0.6510 - acc: 0.766 - ETA: 6s - loss: 0.6520 - acc: 0.766 - ETA: 6s - loss: 0.6502 - acc: 0.767 - ETA: 6s - loss: 0.6505 - acc: 0.767 - ETA: 6s - loss: 0.6505 - acc: 0.767 - ETA: 6s - loss: 0.6492 - acc: 0.767 - ETA: 5s - loss: 0.6491 - acc: 0.768 - ETA: 5s - loss: 0.6489 - acc: 0.768 - ETA: 5s - loss: 0.6499 - acc: 0.767 - ETA: 5s - loss: 0.6504 - acc: 0.767 - ETA: 5s - loss: 0.6500 - acc: 0.767 - ETA: 5s - loss: 0.6492 - acc: 0.768 - ETA: 5s - loss: 0.6511 - acc: 0.767 - ETA: 5s - loss: 0.6512 - acc: 0.767 - ETA: 5s - loss: 0.6508 - acc: 0.767 - ETA: 5s - loss: 0.6509 - acc: 0.767 - ETA: 5s - loss: 0.6509 - acc: 0.767 - ETA: 5s - loss: 0.6513 - acc: 0.767 - ETA: 5s - loss: 0.6514 - acc: 0.767 - ETA: 5s - loss: 0.6502 - acc: 0.768 - ETA: 5s - loss: 0.6497 - acc: 0.768 - ETA: 5s - loss: 0.6493 - acc: 0.768 - ETA: 5s - loss: 0.6499 - acc: 0.767 - ETA: 5s - loss: 0.6504 - acc: 0.767 - ETA: 5s - loss: 0.6506 - acc: 0.767 - ETA: 4s - loss: 0.6510 - acc: 0.767 - ETA: 4s - loss: 0.6505 - acc: 0.767 - ETA: 4s - loss: 0.6508 - acc: 0.766 - ETA: 4s - loss: 0.6513 - acc: 0.766 - ETA: 4s - loss: 0.6516 - acc: 0.766 - ETA: 4s - loss: 0.6510 - acc: 0.766 - ETA: 4s - loss: 0.6505 - acc: 0.766 - ETA: 4s - loss: 0.6503 - acc: 0.766 - ETA: 4s - loss: 0.6501 - acc: 0.767 - ETA: 4s - loss: 0.6499 - acc: 0.766 - ETA: 4s - loss: 0.6504 - acc: 0.766 - ETA: 4s - loss: 0.6521 - acc: 0.766 - ETA: 4s - loss: 0.6516 - acc: 0.766 - ETA: 4s - loss: 0.6509 - acc: 0.767 - ETA: 4s - loss: 0.6505 - acc: 0.767 - ETA: 4s - loss: 0.6510 - acc: 0.767 - ETA: 4s - loss: 0.6506 - acc: 0.767 - ETA: 4s - loss: 0.6510 - acc: 0.767 - ETA: 3s - loss: 0.6510 - acc: 0.767 - ETA: 3s - loss: 0.6509 - acc: 0.767 - ETA: 3s - loss: 0.6502 - acc: 0.767 - ETA: 3s - loss: 0.6503 - acc: 0.767 - ETA: 3s - loss: 0.6508 - acc: 0.767 - ETA: 3s - loss: 0.6526 - acc: 0.766 - ETA: 3s - loss: 0.6530 - acc: 0.766 - ETA: 3s - loss: 0.6526 - acc: 0.766 - ETA: 3s - loss: 0.6532 - acc: 0.766 - ETA: 3s - loss: 0.6533 - acc: 0.766 - ETA: 3s - loss: 0.6533 - acc: 0.766 - ETA: 3s - loss: 0.6535 - acc: 0.766 - ETA: 3s - loss: 0.6536 - acc: 0.766 - ETA: 3s - loss: 0.6532 - acc: 0.766 - ETA: 3s - loss: 0.6529 - acc: 0.766 - ETA: 3s - loss: 0.6532 - acc: 0.766 - ETA: 3s - loss: 0.6532 - acc: 0.766 - ETA: 3s - loss: 0.6531 - acc: 0.766 - ETA: 3s - loss: 0.6525 - acc: 0.766 - ETA: 2s - loss: 0.6527 - acc: 0.766 - ETA: 2s - loss: 0.6528 - acc: 0.766 - ETA: 2s - loss: 0.6527 - acc: 0.766 - ETA: 2s - loss: 0.6531 - acc: 0.766 - ETA: 2s - loss: 0.6532 - acc: 0.766 - ETA: 2s - loss: 0.6544 - acc: 0.766 - ETA: 2s - loss: 0.6540 - acc: 0.766 - ETA: 2s - loss: 0.6542 - acc: 0.765 - ETA: 2s - loss: 0.6542 - acc: 0.765 - ETA: 2s - loss: 0.6542 - acc: 0.765 - ETA: 2s - loss: 0.6539 - acc: 0.765 - ETA: 2s - loss: 0.6536 - acc: 0.766 - ETA: 2s - loss: 0.6532 - acc: 0.766 - ETA: 2s - loss: 0.6534 - acc: 0.766 - ETA: 2s - loss: 0.6538 - acc: 0.766 - ETA: 2s - loss: 0.6538 - acc: 0.766 - ETA: 2s - loss: 0.6538 - acc: 0.766 - ETA: 2s - loss: 0.6537 - acc: 0.766 - ETA: 2s - loss: 0.6539 - acc: 0.766 - ETA: 1s - loss: 0.6540 - acc: 0.766 - ETA: 1s - loss: 0.6546 - acc: 0.765 - ETA: 1s - loss: 0.6544 - acc: 0.765 - ETA: 1s - loss: 0.6548 - acc: 0.765 - ETA: 1s - loss: 0.6543 - acc: 0.765 - ETA: 1s - loss: 0.6538 - acc: 0.766 - ETA: 1s - loss: 0.6540 - acc: 0.766 - ETA: 1s - loss: 0.6539 - acc: 0.766 - ETA: 1s - loss: 0.6539 - acc: 0.766 - ETA: 1s - loss: 0.6533 - acc: 0.766 - ETA: 1s - loss: 0.6540 - acc: 0.766 - ETA: 1s - loss: 0.6542 - acc: 0.766 - ETA: 1s - loss: 0.6543 - acc: 0.766 - ETA: 1s - loss: 0.6543 - acc: 0.766 - ETA: 1s - loss: 0.6544 - acc: 0.766 - ETA: 1s - loss: 0.6542 - acc: 0.766 - ETA: 1s - loss: 0.6541 - acc: 0.766 - ETA: 1s - loss: 0.6537 - acc: 0.766 - ETA: 1s - loss: 0.6547 - acc: 0.766 - ETA: 0s - loss: 0.6547 - acc: 0.766 - ETA: 0s - loss: 0.6548 - acc: 0.766 - ETA: 0s - loss: 0.6545 - acc: 0.766 - ETA: 0s - loss: 0.6549 - acc: 0.766 - ETA: 0s - loss: 0.6556 - acc: 0.766 - ETA: 0s - loss: 0.6561 - acc: 0.766 - ETA: 0s - loss: 0.6559 - acc: 0.766 - ETA: 0s - loss: 0.6557 - acc: 0.766 - ETA: 0s - loss: 0.6562 - acc: 0.766 - ETA: 0s - loss: 0.6564 - acc: 0.766 - ETA: 0s - loss: 0.6567 - acc: 0.765 - ETA: 0s - loss: 0.6567 - acc: 0.765 - ETA: 0s - loss: 0.6568 - acc: 0.765 - ETA: 0s - loss: 0.6573 - acc: 0.765 - ETA: 0s - loss: 0.6574 - acc: 0.765 - ETA: 0s - loss: 0.6575 - acc: 0.765 - ETA: 0s - loss: 0.6578 - acc: 0.765 - ETA: 0s - loss: 0.6583 - acc: 0.7657WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "45000/45000 [==============================] - 11s 253us/sample - loss: 0.6585 - acc: 0.7657 - val_loss: 0.7907 - val_acc: 0.7228\n",
      "Epoch 36/40\n",
      "44832/45000 [============================>.] - ETA: 14s - loss: 0.5462 - acc: 0.81 - ETA: 11s - loss: 0.5798 - acc: 0.81 - ETA: 10s - loss: 0.6291 - acc: 0.79 - ETA: 10s - loss: 0.6180 - acc: 0.79 - ETA: 10s - loss: 0.6391 - acc: 0.78 - ETA: 10s - loss: 0.6330 - acc: 0.77 - ETA: 10s - loss: 0.6364 - acc: 0.77 - ETA: 10s - loss: 0.6255 - acc: 0.78 - ETA: 10s - loss: 0.6347 - acc: 0.77 - ETA: 10s - loss: 0.6220 - acc: 0.77 - ETA: 10s - loss: 0.6299 - acc: 0.77 - ETA: 10s - loss: 0.6169 - acc: 0.77 - ETA: 10s - loss: 0.6190 - acc: 0.77 - ETA: 10s - loss: 0.6238 - acc: 0.77 - ETA: 10s - loss: 0.6217 - acc: 0.77 - ETA: 9s - loss: 0.6191 - acc: 0.7786 - ETA: 9s - loss: 0.6166 - acc: 0.780 - ETA: 9s - loss: 0.6180 - acc: 0.779 - ETA: 9s - loss: 0.6242 - acc: 0.779 - ETA: 9s - loss: 0.6206 - acc: 0.780 - ETA: 9s - loss: 0.6233 - acc: 0.778 - ETA: 9s - loss: 0.6211 - acc: 0.778 - ETA: 9s - loss: 0.6199 - acc: 0.779 - ETA: 9s - loss: 0.6274 - acc: 0.776 - ETA: 9s - loss: 0.6255 - acc: 0.777 - ETA: 9s - loss: 0.6291 - acc: 0.776 - ETA: 9s - loss: 0.6331 - acc: 0.774 - ETA: 9s - loss: 0.6344 - acc: 0.774 - ETA: 9s - loss: 0.6384 - acc: 0.773 - ETA: 9s - loss: 0.6382 - acc: 0.774 - ETA: 9s - loss: 0.6390 - acc: 0.773 - ETA: 9s - loss: 0.6386 - acc: 0.773 - ETA: 9s - loss: 0.6372 - acc: 0.773 - ETA: 8s - loss: 0.6367 - acc: 0.773 - ETA: 8s - loss: 0.6373 - acc: 0.773 - ETA: 8s - loss: 0.6372 - acc: 0.773 - ETA: 8s - loss: 0.6363 - acc: 0.773 - ETA: 8s - loss: 0.6386 - acc: 0.773 - ETA: 8s - loss: 0.6364 - acc: 0.773 - ETA: 8s - loss: 0.6340 - acc: 0.774 - ETA: 8s - loss: 0.6340 - acc: 0.775 - ETA: 8s - loss: 0.6349 - acc: 0.774 - ETA: 8s - loss: 0.6366 - acc: 0.774 - ETA: 8s - loss: 0.6378 - acc: 0.774 - ETA: 8s - loss: 0.6381 - acc: 0.774 - ETA: 8s - loss: 0.6385 - acc: 0.774 - ETA: 8s - loss: 0.6375 - acc: 0.775 - ETA: 8s - loss: 0.6400 - acc: 0.774 - ETA: 8s - loss: 0.6386 - acc: 0.774 - ETA: 8s - loss: 0.6392 - acc: 0.774 - ETA: 8s - loss: 0.6377 - acc: 0.774 - ETA: 8s - loss: 0.6396 - acc: 0.773 - ETA: 7s - loss: 0.6381 - acc: 0.774 - ETA: 7s - loss: 0.6363 - acc: 0.774 - ETA: 7s - loss: 0.6366 - acc: 0.775 - ETA: 7s - loss: 0.6352 - acc: 0.775 - ETA: 7s - loss: 0.6340 - acc: 0.775 - ETA: 7s - loss: 0.6330 - acc: 0.776 - ETA: 7s - loss: 0.6334 - acc: 0.776 - ETA: 7s - loss: 0.6331 - acc: 0.776 - ETA: 7s - loss: 0.6335 - acc: 0.776 - ETA: 7s - loss: 0.6322 - acc: 0.777 - ETA: 7s - loss: 0.6349 - acc: 0.776 - ETA: 7s - loss: 0.6338 - acc: 0.777 - ETA: 7s - loss: 0.6338 - acc: 0.777 - ETA: 7s - loss: 0.6324 - acc: 0.778 - ETA: 7s - loss: 0.6328 - acc: 0.778 - ETA: 7s - loss: 0.6333 - acc: 0.777 - ETA: 7s - loss: 0.6356 - acc: 0.776 - ETA: 7s - loss: 0.6370 - acc: 0.776 - ETA: 6s - loss: 0.6379 - acc: 0.775 - ETA: 6s - loss: 0.6385 - acc: 0.775 - ETA: 6s - loss: 0.6394 - acc: 0.774 - ETA: 6s - loss: 0.6385 - acc: 0.775 - ETA: 6s - loss: 0.6379 - acc: 0.775 - ETA: 6s - loss: 0.6382 - acc: 0.775 - ETA: 6s - loss: 0.6389 - acc: 0.775 - ETA: 6s - loss: 0.6392 - acc: 0.774 - ETA: 6s - loss: 0.6381 - acc: 0.775 - ETA: 6s - loss: 0.6385 - acc: 0.774 - ETA: 6s - loss: 0.6386 - acc: 0.774 - ETA: 6s - loss: 0.6399 - acc: 0.774 - ETA: 6s - loss: 0.6401 - acc: 0.774 - ETA: 6s - loss: 0.6404 - acc: 0.774 - ETA: 6s - loss: 0.6419 - acc: 0.774 - ETA: 6s - loss: 0.6427 - acc: 0.773 - ETA: 6s - loss: 0.6414 - acc: 0.773 - ETA: 6s - loss: 0.6419 - acc: 0.774 - ETA: 6s - loss: 0.6425 - acc: 0.773 - ETA: 5s - loss: 0.6429 - acc: 0.773 - ETA: 5s - loss: 0.6432 - acc: 0.773 - ETA: 5s - loss: 0.6432 - acc: 0.773 - ETA: 5s - loss: 0.6441 - acc: 0.773 - ETA: 5s - loss: 0.6444 - acc: 0.772 - ETA: 5s - loss: 0.6436 - acc: 0.773 - ETA: 5s - loss: 0.6427 - acc: 0.773 - ETA: 5s - loss: 0.6432 - acc: 0.773 - ETA: 5s - loss: 0.6439 - acc: 0.773 - ETA: 5s - loss: 0.6432 - acc: 0.773 - ETA: 5s - loss: 0.6434 - acc: 0.773 - ETA: 5s - loss: 0.6444 - acc: 0.772 - ETA: 5s - loss: 0.6434 - acc: 0.773 - ETA: 5s - loss: 0.6436 - acc: 0.773 - ETA: 5s - loss: 0.6435 - acc: 0.773 - ETA: 5s - loss: 0.6427 - acc: 0.773 - ETA: 5s - loss: 0.6420 - acc: 0.774 - ETA: 5s - loss: 0.6430 - acc: 0.773 - ETA: 5s - loss: 0.6426 - acc: 0.773 - ETA: 4s - loss: 0.6432 - acc: 0.773 - ETA: 4s - loss: 0.6436 - acc: 0.773 - ETA: 4s - loss: 0.6432 - acc: 0.773 - ETA: 4s - loss: 0.6427 - acc: 0.773 - ETA: 4s - loss: 0.6424 - acc: 0.773 - ETA: 4s - loss: 0.6432 - acc: 0.772 - ETA: 4s - loss: 0.6421 - acc: 0.773 - ETA: 4s - loss: 0.6428 - acc: 0.772 - ETA: 4s - loss: 0.6426 - acc: 0.773 - ETA: 4s - loss: 0.6425 - acc: 0.772 - ETA: 4s - loss: 0.6426 - acc: 0.772 - ETA: 4s - loss: 0.6442 - acc: 0.772 - ETA: 4s - loss: 0.6446 - acc: 0.772 - ETA: 4s - loss: 0.6449 - acc: 0.772 - ETA: 4s - loss: 0.6442 - acc: 0.772 - ETA: 4s - loss: 0.6442 - acc: 0.772 - ETA: 4s - loss: 0.6448 - acc: 0.772 - ETA: 4s - loss: 0.6455 - acc: 0.772 - ETA: 4s - loss: 0.6456 - acc: 0.771 - ETA: 3s - loss: 0.6460 - acc: 0.771 - ETA: 3s - loss: 0.6458 - acc: 0.771 - ETA: 3s - loss: 0.6462 - acc: 0.771 - ETA: 3s - loss: 0.6459 - acc: 0.771 - ETA: 3s - loss: 0.6454 - acc: 0.771 - ETA: 3s - loss: 0.6461 - acc: 0.771 - ETA: 3s - loss: 0.6461 - acc: 0.771 - ETA: 3s - loss: 0.6459 - acc: 0.771 - ETA: 3s - loss: 0.6454 - acc: 0.771 - ETA: 3s - loss: 0.6455 - acc: 0.771 - ETA: 3s - loss: 0.6463 - acc: 0.771 - ETA: 3s - loss: 0.6467 - acc: 0.771 - ETA: 3s - loss: 0.6464 - acc: 0.771 - ETA: 3s - loss: 0.6460 - acc: 0.771 - ETA: 3s - loss: 0.6457 - acc: 0.771 - ETA: 3s - loss: 0.6455 - acc: 0.771 - ETA: 3s - loss: 0.6453 - acc: 0.771 - ETA: 3s - loss: 0.6448 - acc: 0.772 - ETA: 2s - loss: 0.6451 - acc: 0.771 - ETA: 2s - loss: 0.6446 - acc: 0.772 - ETA: 2s - loss: 0.6453 - acc: 0.771 - ETA: 2s - loss: 0.6450 - acc: 0.771 - ETA: 2s - loss: 0.6454 - acc: 0.771 - ETA: 2s - loss: 0.6465 - acc: 0.771 - ETA: 2s - loss: 0.6467 - acc: 0.771 - ETA: 2s - loss: 0.6470 - acc: 0.771 - ETA: 2s - loss: 0.6473 - acc: 0.770 - ETA: 2s - loss: 0.6473 - acc: 0.770 - ETA: 2s - loss: 0.6474 - acc: 0.770 - ETA: 2s - loss: 0.6473 - acc: 0.770 - ETA: 2s - loss: 0.6476 - acc: 0.770 - ETA: 2s - loss: 0.6474 - acc: 0.770 - ETA: 2s - loss: 0.6473 - acc: 0.770 - ETA: 2s - loss: 0.6473 - acc: 0.770 - ETA: 2s - loss: 0.6471 - acc: 0.770 - ETA: 2s - loss: 0.6473 - acc: 0.770 - ETA: 2s - loss: 0.6473 - acc: 0.770 - ETA: 1s - loss: 0.6473 - acc: 0.770 - ETA: 1s - loss: 0.6481 - acc: 0.770 - ETA: 1s - loss: 0.6489 - acc: 0.770 - ETA: 1s - loss: 0.6495 - acc: 0.770 - ETA: 1s - loss: 0.6489 - acc: 0.770 - ETA: 1s - loss: 0.6489 - acc: 0.770 - ETA: 1s - loss: 0.6489 - acc: 0.770 - ETA: 1s - loss: 0.6492 - acc: 0.770 - ETA: 1s - loss: 0.6494 - acc: 0.770 - ETA: 1s - loss: 0.6481 - acc: 0.770 - ETA: 1s - loss: 0.6485 - acc: 0.770 - ETA: 1s - loss: 0.6479 - acc: 0.770 - ETA: 1s - loss: 0.6479 - acc: 0.770 - ETA: 1s - loss: 0.6479 - acc: 0.770 - ETA: 1s - loss: 0.6480 - acc: 0.770 - ETA: 1s - loss: 0.6484 - acc: 0.770 - ETA: 1s - loss: 0.6490 - acc: 0.770 - ETA: 1s - loss: 0.6488 - acc: 0.770 - ETA: 1s - loss: 0.6490 - acc: 0.770 - ETA: 0s - loss: 0.6494 - acc: 0.770 - ETA: 0s - loss: 0.6492 - acc: 0.770 - ETA: 0s - loss: 0.6494 - acc: 0.770 - ETA: 0s - loss: 0.6504 - acc: 0.770 - ETA: 0s - loss: 0.6498 - acc: 0.770 - ETA: 0s - loss: 0.6497 - acc: 0.770 - ETA: 0s - loss: 0.6497 - acc: 0.770 - ETA: 0s - loss: 0.6493 - acc: 0.770 - ETA: 0s - loss: 0.6492 - acc: 0.770 - ETA: 0s - loss: 0.6493 - acc: 0.770 - ETA: 0s - loss: 0.6490 - acc: 0.770 - ETA: 0s - loss: 0.6491 - acc: 0.770 - ETA: 0s - loss: 0.6493 - acc: 0.770 - ETA: 0s - loss: 0.6491 - acc: 0.770 - ETA: 0s - loss: 0.6492 - acc: 0.770 - ETA: 0s - loss: 0.6485 - acc: 0.770 - ETA: 0s - loss: 0.6490 - acc: 0.770 - ETA: 0s - loss: 0.6496 - acc: 0.7701WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "45000/45000 [==============================] - 11s 253us/sample - loss: 0.6496 - acc: 0.7702 - val_loss: 0.7769 - val_acc: 0.7292\n",
      "Epoch 37/40\n",
      "44832/45000 [============================>.] - ETA: 14s - loss: 0.5058 - acc: 0.78 - ETA: 11s - loss: 0.6077 - acc: 0.77 - ETA: 10s - loss: 0.6345 - acc: 0.76 - ETA: 10s - loss: 0.6410 - acc: 0.76 - ETA: 10s - loss: 0.6472 - acc: 0.75 - ETA: 10s - loss: 0.6335 - acc: 0.75 - ETA: 10s - loss: 0.6373 - acc: 0.75 - ETA: 10s - loss: 0.6258 - acc: 0.76 - ETA: 10s - loss: 0.6281 - acc: 0.76 - ETA: 10s - loss: 0.6316 - acc: 0.75 - ETA: 10s - loss: 0.6395 - acc: 0.75 - ETA: 10s - loss: 0.6293 - acc: 0.76 - ETA: 10s - loss: 0.6384 - acc: 0.76 - ETA: 10s - loss: 0.6365 - acc: 0.76 - ETA: 9s - loss: 0.6319 - acc: 0.7626 - ETA: 9s - loss: 0.6345 - acc: 0.764 - ETA: 9s - loss: 0.6374 - acc: 0.764 - ETA: 9s - loss: 0.6408 - acc: 0.763 - ETA: 9s - loss: 0.6432 - acc: 0.763 - ETA: 9s - loss: 0.6413 - acc: 0.764 - ETA: 9s - loss: 0.6415 - acc: 0.764 - ETA: 9s - loss: 0.6449 - acc: 0.763 - ETA: 9s - loss: 0.6420 - acc: 0.766 - ETA: 9s - loss: 0.6451 - acc: 0.766 - ETA: 9s - loss: 0.6436 - acc: 0.767 - ETA: 9s - loss: 0.6409 - acc: 0.770 - ETA: 9s - loss: 0.6437 - acc: 0.770 - ETA: 9s - loss: 0.6437 - acc: 0.770 - ETA: 9s - loss: 0.6447 - acc: 0.768 - ETA: 9s - loss: 0.6471 - acc: 0.767 - ETA: 9s - loss: 0.6488 - acc: 0.767 - ETA: 9s - loss: 0.6500 - acc: 0.767 - ETA: 9s - loss: 0.6506 - acc: 0.767 - ETA: 8s - loss: 0.6520 - acc: 0.767 - ETA: 8s - loss: 0.6507 - acc: 0.768 - ETA: 8s - loss: 0.6509 - acc: 0.767 - ETA: 8s - loss: 0.6537 - acc: 0.767 - ETA: 8s - loss: 0.6524 - acc: 0.768 - ETA: 8s - loss: 0.6520 - acc: 0.768 - ETA: 8s - loss: 0.6514 - acc: 0.767 - ETA: 8s - loss: 0.6505 - acc: 0.768 - ETA: 8s - loss: 0.6500 - acc: 0.768 - ETA: 8s - loss: 0.6483 - acc: 0.769 - ETA: 8s - loss: 0.6478 - acc: 0.769 - ETA: 8s - loss: 0.6469 - acc: 0.769 - ETA: 8s - loss: 0.6491 - acc: 0.769 - ETA: 8s - loss: 0.6463 - acc: 0.770 - ETA: 8s - loss: 0.6464 - acc: 0.770 - ETA: 8s - loss: 0.6490 - acc: 0.769 - ETA: 8s - loss: 0.6482 - acc: 0.769 - ETA: 8s - loss: 0.6486 - acc: 0.768 - ETA: 7s - loss: 0.6509 - acc: 0.768 - ETA: 7s - loss: 0.6505 - acc: 0.768 - ETA: 7s - loss: 0.6498 - acc: 0.768 - ETA: 7s - loss: 0.6494 - acc: 0.768 - ETA: 7s - loss: 0.6480 - acc: 0.768 - ETA: 7s - loss: 0.6502 - acc: 0.768 - ETA: 7s - loss: 0.6489 - acc: 0.769 - ETA: 7s - loss: 0.6480 - acc: 0.769 - ETA: 7s - loss: 0.6475 - acc: 0.768 - ETA: 7s - loss: 0.6454 - acc: 0.769 - ETA: 7s - loss: 0.6447 - acc: 0.769 - ETA: 7s - loss: 0.6462 - acc: 0.769 - ETA: 7s - loss: 0.6456 - acc: 0.769 - ETA: 7s - loss: 0.6469 - acc: 0.768 - ETA: 7s - loss: 0.6459 - acc: 0.769 - ETA: 7s - loss: 0.6474 - acc: 0.768 - ETA: 7s - loss: 0.6474 - acc: 0.768 - ETA: 7s - loss: 0.6455 - acc: 0.769 - ETA: 7s - loss: 0.6439 - acc: 0.769 - ETA: 6s - loss: 0.6449 - acc: 0.769 - ETA: 6s - loss: 0.6446 - acc: 0.769 - ETA: 6s - loss: 0.6449 - acc: 0.769 - ETA: 6s - loss: 0.6445 - acc: 0.769 - ETA: 6s - loss: 0.6434 - acc: 0.769 - ETA: 6s - loss: 0.6432 - acc: 0.769 - ETA: 6s - loss: 0.6432 - acc: 0.769 - ETA: 6s - loss: 0.6429 - acc: 0.770 - ETA: 6s - loss: 0.6442 - acc: 0.769 - ETA: 6s - loss: 0.6467 - acc: 0.768 - ETA: 6s - loss: 0.6465 - acc: 0.768 - ETA: 6s - loss: 0.6464 - acc: 0.768 - ETA: 6s - loss: 0.6456 - acc: 0.768 - ETA: 6s - loss: 0.6457 - acc: 0.768 - ETA: 6s - loss: 0.6469 - acc: 0.768 - ETA: 6s - loss: 0.6479 - acc: 0.768 - ETA: 6s - loss: 0.6477 - acc: 0.768 - ETA: 6s - loss: 0.6463 - acc: 0.769 - ETA: 6s - loss: 0.6459 - acc: 0.769 - ETA: 5s - loss: 0.6454 - acc: 0.769 - ETA: 5s - loss: 0.6458 - acc: 0.769 - ETA: 5s - loss: 0.6458 - acc: 0.769 - ETA: 5s - loss: 0.6469 - acc: 0.768 - ETA: 5s - loss: 0.6459 - acc: 0.769 - ETA: 5s - loss: 0.6460 - acc: 0.769 - ETA: 5s - loss: 0.6456 - acc: 0.769 - ETA: 5s - loss: 0.6451 - acc: 0.769 - ETA: 5s - loss: 0.6443 - acc: 0.769 - ETA: 5s - loss: 0.6447 - acc: 0.770 - ETA: 5s - loss: 0.6435 - acc: 0.770 - ETA: 5s - loss: 0.6426 - acc: 0.770 - ETA: 5s - loss: 0.6420 - acc: 0.771 - ETA: 5s - loss: 0.6418 - acc: 0.771 - ETA: 5s - loss: 0.6423 - acc: 0.771 - ETA: 5s - loss: 0.6430 - acc: 0.770 - ETA: 5s - loss: 0.6429 - acc: 0.770 - ETA: 5s - loss: 0.6432 - acc: 0.770 - ETA: 4s - loss: 0.6433 - acc: 0.770 - ETA: 4s - loss: 0.6442 - acc: 0.770 - ETA: 4s - loss: 0.6437 - acc: 0.770 - ETA: 4s - loss: 0.6438 - acc: 0.770 - ETA: 4s - loss: 0.6432 - acc: 0.770 - ETA: 4s - loss: 0.6438 - acc: 0.770 - ETA: 4s - loss: 0.6439 - acc: 0.770 - ETA: 4s - loss: 0.6440 - acc: 0.770 - ETA: 4s - loss: 0.6432 - acc: 0.770 - ETA: 4s - loss: 0.6441 - acc: 0.770 - ETA: 4s - loss: 0.6438 - acc: 0.770 - ETA: 4s - loss: 0.6443 - acc: 0.770 - ETA: 4s - loss: 0.6443 - acc: 0.770 - ETA: 4s - loss: 0.6449 - acc: 0.769 - ETA: 4s - loss: 0.6446 - acc: 0.769 - ETA: 4s - loss: 0.6443 - acc: 0.769 - ETA: 4s - loss: 0.6442 - acc: 0.769 - ETA: 4s - loss: 0.6442 - acc: 0.769 - ETA: 4s - loss: 0.6438 - acc: 0.770 - ETA: 3s - loss: 0.6448 - acc: 0.769 - ETA: 3s - loss: 0.6450 - acc: 0.769 - ETA: 3s - loss: 0.6454 - acc: 0.769 - ETA: 3s - loss: 0.6453 - acc: 0.769 - ETA: 3s - loss: 0.6459 - acc: 0.769 - ETA: 3s - loss: 0.6459 - acc: 0.769 - ETA: 3s - loss: 0.6464 - acc: 0.768 - ETA: 3s - loss: 0.6469 - acc: 0.768 - ETA: 3s - loss: 0.6471 - acc: 0.768 - ETA: 3s - loss: 0.6468 - acc: 0.769 - ETA: 3s - loss: 0.6463 - acc: 0.769 - ETA: 3s - loss: 0.6460 - acc: 0.769 - ETA: 3s - loss: 0.6458 - acc: 0.769 - ETA: 3s - loss: 0.6456 - acc: 0.769 - ETA: 3s - loss: 0.6457 - acc: 0.769 - ETA: 3s - loss: 0.6467 - acc: 0.768 - ETA: 3s - loss: 0.6459 - acc: 0.768 - ETA: 3s - loss: 0.6464 - acc: 0.768 - ETA: 3s - loss: 0.6470 - acc: 0.768 - ETA: 2s - loss: 0.6469 - acc: 0.768 - ETA: 2s - loss: 0.6464 - acc: 0.768 - ETA: 2s - loss: 0.6467 - acc: 0.768 - ETA: 2s - loss: 0.6464 - acc: 0.768 - ETA: 2s - loss: 0.6464 - acc: 0.768 - ETA: 2s - loss: 0.6467 - acc: 0.769 - ETA: 2s - loss: 0.6469 - acc: 0.769 - ETA: 2s - loss: 0.6468 - acc: 0.768 - ETA: 2s - loss: 0.6468 - acc: 0.768 - ETA: 2s - loss: 0.6462 - acc: 0.769 - ETA: 2s - loss: 0.6460 - acc: 0.769 - ETA: 2s - loss: 0.6457 - acc: 0.769 - ETA: 2s - loss: 0.6458 - acc: 0.769 - ETA: 2s - loss: 0.6461 - acc: 0.769 - ETA: 2s - loss: 0.6460 - acc: 0.769 - ETA: 2s - loss: 0.6463 - acc: 0.769 - ETA: 2s - loss: 0.6459 - acc: 0.769 - ETA: 2s - loss: 0.6462 - acc: 0.769 - ETA: 2s - loss: 0.6464 - acc: 0.769 - ETA: 1s - loss: 0.6465 - acc: 0.769 - ETA: 1s - loss: 0.6464 - acc: 0.769 - ETA: 1s - loss: 0.6462 - acc: 0.769 - ETA: 1s - loss: 0.6460 - acc: 0.769 - ETA: 1s - loss: 0.6457 - acc: 0.770 - ETA: 1s - loss: 0.6453 - acc: 0.770 - ETA: 1s - loss: 0.6456 - acc: 0.770 - ETA: 1s - loss: 0.6460 - acc: 0.770 - ETA: 1s - loss: 0.6464 - acc: 0.770 - ETA: 1s - loss: 0.6463 - acc: 0.770 - ETA: 1s - loss: 0.6466 - acc: 0.770 - ETA: 1s - loss: 0.6465 - acc: 0.770 - ETA: 1s - loss: 0.6461 - acc: 0.770 - ETA: 1s - loss: 0.6455 - acc: 0.770 - ETA: 1s - loss: 0.6459 - acc: 0.770 - ETA: 1s - loss: 0.6457 - acc: 0.770 - ETA: 1s - loss: 0.6464 - acc: 0.770 - ETA: 1s - loss: 0.6462 - acc: 0.770 - ETA: 0s - loss: 0.6462 - acc: 0.770 - ETA: 0s - loss: 0.6469 - acc: 0.770 - ETA: 0s - loss: 0.6471 - acc: 0.769 - ETA: 0s - loss: 0.6469 - acc: 0.769 - ETA: 0s - loss: 0.6474 - acc: 0.769 - ETA: 0s - loss: 0.6477 - acc: 0.769 - ETA: 0s - loss: 0.6483 - acc: 0.769 - ETA: 0s - loss: 0.6486 - acc: 0.769 - ETA: 0s - loss: 0.6485 - acc: 0.769 - ETA: 0s - loss: 0.6481 - acc: 0.769 - ETA: 0s - loss: 0.6480 - acc: 0.769 - ETA: 0s - loss: 0.6481 - acc: 0.769 - ETA: 0s - loss: 0.6485 - acc: 0.769 - ETA: 0s - loss: 0.6482 - acc: 0.769 - ETA: 0s - loss: 0.6481 - acc: 0.769 - ETA: 0s - loss: 0.6487 - acc: 0.769 - ETA: 0s - loss: 0.6486 - acc: 0.769 - ETA: 0s - loss: 0.6480 - acc: 0.769 - ETA: 0s - loss: 0.6482 - acc: 0.7693WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "45000/45000 [==============================] - 11s 252us/sample - loss: 0.6478 - acc: 0.7694 - val_loss: 0.7711 - val_acc: 0.7298\n",
      "Epoch 38/40\n",
      "44832/45000 [============================>.] - ETA: 15s - loss: 0.8461 - acc: 0.56 - ETA: 11s - loss: 0.5735 - acc: 0.78 - ETA: 10s - loss: 0.6011 - acc: 0.78 - ETA: 10s - loss: 0.6189 - acc: 0.78 - ETA: 10s - loss: 0.6179 - acc: 0.78 - ETA: 10s - loss: 0.6087 - acc: 0.78 - ETA: 10s - loss: 0.6192 - acc: 0.77 - ETA: 10s - loss: 0.6190 - acc: 0.77 - ETA: 10s - loss: 0.6311 - acc: 0.76 - ETA: 10s - loss: 0.6322 - acc: 0.76 - ETA: 10s - loss: 0.6224 - acc: 0.77 - ETA: 10s - loss: 0.6168 - acc: 0.77 - ETA: 10s - loss: 0.6147 - acc: 0.77 - ETA: 10s - loss: 0.6148 - acc: 0.77 - ETA: 10s - loss: 0.6161 - acc: 0.77 - ETA: 9s - loss: 0.6184 - acc: 0.7751 - ETA: 9s - loss: 0.6130 - acc: 0.776 - ETA: 9s - loss: 0.6106 - acc: 0.777 - ETA: 9s - loss: 0.6063 - acc: 0.779 - ETA: 9s - loss: 0.6072 - acc: 0.778 - ETA: 9s - loss: 0.6060 - acc: 0.780 - ETA: 9s - loss: 0.6092 - acc: 0.777 - ETA: 9s - loss: 0.6075 - acc: 0.779 - ETA: 9s - loss: 0.6084 - acc: 0.780 - ETA: 9s - loss: 0.6079 - acc: 0.781 - ETA: 9s - loss: 0.6083 - acc: 0.781 - ETA: 9s - loss: 0.6076 - acc: 0.781 - ETA: 9s - loss: 0.6115 - acc: 0.780 - ETA: 9s - loss: 0.6102 - acc: 0.780 - ETA: 9s - loss: 0.6083 - acc: 0.780 - ETA: 9s - loss: 0.6081 - acc: 0.781 - ETA: 9s - loss: 0.6041 - acc: 0.783 - ETA: 9s - loss: 0.6021 - acc: 0.782 - ETA: 9s - loss: 0.6039 - acc: 0.781 - ETA: 8s - loss: 0.6028 - acc: 0.782 - ETA: 8s - loss: 0.6034 - acc: 0.782 - ETA: 8s - loss: 0.6054 - acc: 0.781 - ETA: 8s - loss: 0.6053 - acc: 0.781 - ETA: 8s - loss: 0.6089 - acc: 0.779 - ETA: 8s - loss: 0.6111 - acc: 0.778 - ETA: 8s - loss: 0.6121 - acc: 0.778 - ETA: 8s - loss: 0.6131 - acc: 0.777 - ETA: 8s - loss: 0.6123 - acc: 0.778 - ETA: 8s - loss: 0.6126 - acc: 0.778 - ETA: 8s - loss: 0.6119 - acc: 0.778 - ETA: 8s - loss: 0.6110 - acc: 0.779 - ETA: 8s - loss: 0.6104 - acc: 0.779 - ETA: 8s - loss: 0.6101 - acc: 0.779 - ETA: 8s - loss: 0.6116 - acc: 0.778 - ETA: 8s - loss: 0.6144 - acc: 0.777 - ETA: 8s - loss: 0.6158 - acc: 0.777 - ETA: 8s - loss: 0.6165 - acc: 0.777 - ETA: 7s - loss: 0.6178 - acc: 0.776 - ETA: 7s - loss: 0.6193 - acc: 0.775 - ETA: 7s - loss: 0.6189 - acc: 0.775 - ETA: 7s - loss: 0.6197 - acc: 0.774 - ETA: 7s - loss: 0.6198 - acc: 0.775 - ETA: 7s - loss: 0.6208 - acc: 0.775 - ETA: 7s - loss: 0.6204 - acc: 0.775 - ETA: 7s - loss: 0.6199 - acc: 0.775 - ETA: 7s - loss: 0.6192 - acc: 0.775 - ETA: 7s - loss: 0.6174 - acc: 0.776 - ETA: 7s - loss: 0.6187 - acc: 0.776 - ETA: 7s - loss: 0.6178 - acc: 0.776 - ETA: 7s - loss: 0.6173 - acc: 0.777 - ETA: 7s - loss: 0.6181 - acc: 0.776 - ETA: 7s - loss: 0.6181 - acc: 0.776 - ETA: 7s - loss: 0.6169 - acc: 0.777 - ETA: 7s - loss: 0.6176 - acc: 0.777 - ETA: 7s - loss: 0.6173 - acc: 0.777 - ETA: 7s - loss: 0.6172 - acc: 0.777 - ETA: 6s - loss: 0.6150 - acc: 0.779 - ETA: 6s - loss: 0.6159 - acc: 0.779 - ETA: 6s - loss: 0.6170 - acc: 0.778 - ETA: 6s - loss: 0.6164 - acc: 0.779 - ETA: 6s - loss: 0.6177 - acc: 0.779 - ETA: 6s - loss: 0.6194 - acc: 0.778 - ETA: 6s - loss: 0.6192 - acc: 0.778 - ETA: 6s - loss: 0.6197 - acc: 0.778 - ETA: 6s - loss: 0.6201 - acc: 0.778 - ETA: 6s - loss: 0.6205 - acc: 0.778 - ETA: 6s - loss: 0.6208 - acc: 0.777 - ETA: 6s - loss: 0.6221 - acc: 0.777 - ETA: 6s - loss: 0.6208 - acc: 0.778 - ETA: 6s - loss: 0.6216 - acc: 0.777 - ETA: 6s - loss: 0.6208 - acc: 0.777 - ETA: 6s - loss: 0.6192 - acc: 0.778 - ETA: 6s - loss: 0.6193 - acc: 0.778 - ETA: 6s - loss: 0.6189 - acc: 0.778 - ETA: 6s - loss: 0.6186 - acc: 0.778 - ETA: 5s - loss: 0.6181 - acc: 0.779 - ETA: 5s - loss: 0.6180 - acc: 0.779 - ETA: 5s - loss: 0.6179 - acc: 0.779 - ETA: 5s - loss: 0.6191 - acc: 0.778 - ETA: 5s - loss: 0.6192 - acc: 0.778 - ETA: 5s - loss: 0.6201 - acc: 0.778 - ETA: 5s - loss: 0.6213 - acc: 0.778 - ETA: 5s - loss: 0.6221 - acc: 0.777 - ETA: 5s - loss: 0.6227 - acc: 0.777 - ETA: 5s - loss: 0.6225 - acc: 0.777 - ETA: 5s - loss: 0.6231 - acc: 0.777 - ETA: 5s - loss: 0.6227 - acc: 0.777 - ETA: 5s - loss: 0.6231 - acc: 0.777 - ETA: 5s - loss: 0.6235 - acc: 0.776 - ETA: 5s - loss: 0.6239 - acc: 0.776 - ETA: 5s - loss: 0.6244 - acc: 0.776 - ETA: 5s - loss: 0.6242 - acc: 0.776 - ETA: 5s - loss: 0.6241 - acc: 0.776 - ETA: 4s - loss: 0.6236 - acc: 0.776 - ETA: 4s - loss: 0.6245 - acc: 0.776 - ETA: 4s - loss: 0.6244 - acc: 0.776 - ETA: 4s - loss: 0.6239 - acc: 0.776 - ETA: 4s - loss: 0.6233 - acc: 0.776 - ETA: 4s - loss: 0.6237 - acc: 0.776 - ETA: 4s - loss: 0.6241 - acc: 0.776 - ETA: 4s - loss: 0.6244 - acc: 0.776 - ETA: 4s - loss: 0.6244 - acc: 0.776 - ETA: 4s - loss: 0.6249 - acc: 0.776 - ETA: 4s - loss: 0.6257 - acc: 0.775 - ETA: 4s - loss: 0.6264 - acc: 0.775 - ETA: 4s - loss: 0.6268 - acc: 0.775 - ETA: 4s - loss: 0.6262 - acc: 0.775 - ETA: 4s - loss: 0.6263 - acc: 0.775 - ETA: 4s - loss: 0.6262 - acc: 0.775 - ETA: 4s - loss: 0.6266 - acc: 0.775 - ETA: 4s - loss: 0.6266 - acc: 0.775 - ETA: 4s - loss: 0.6271 - acc: 0.774 - ETA: 3s - loss: 0.6277 - acc: 0.774 - ETA: 3s - loss: 0.6276 - acc: 0.774 - ETA: 3s - loss: 0.6280 - acc: 0.774 - ETA: 3s - loss: 0.6278 - acc: 0.774 - ETA: 3s - loss: 0.6273 - acc: 0.775 - ETA: 3s - loss: 0.6278 - acc: 0.774 - ETA: 3s - loss: 0.6276 - acc: 0.774 - ETA: 3s - loss: 0.6272 - acc: 0.774 - ETA: 3s - loss: 0.6268 - acc: 0.774 - ETA: 3s - loss: 0.6262 - acc: 0.775 - ETA: 3s - loss: 0.6262 - acc: 0.775 - ETA: 3s - loss: 0.6264 - acc: 0.774 - ETA: 3s - loss: 0.6267 - acc: 0.774 - ETA: 3s - loss: 0.6274 - acc: 0.774 - ETA: 3s - loss: 0.6270 - acc: 0.774 - ETA: 3s - loss: 0.6282 - acc: 0.774 - ETA: 3s - loss: 0.6282 - acc: 0.774 - ETA: 3s - loss: 0.6278 - acc: 0.774 - ETA: 2s - loss: 0.6281 - acc: 0.774 - ETA: 2s - loss: 0.6282 - acc: 0.774 - ETA: 2s - loss: 0.6284 - acc: 0.773 - ETA: 2s - loss: 0.6286 - acc: 0.773 - ETA: 2s - loss: 0.6293 - acc: 0.773 - ETA: 2s - loss: 0.6304 - acc: 0.773 - ETA: 2s - loss: 0.6316 - acc: 0.772 - ETA: 2s - loss: 0.6313 - acc: 0.772 - ETA: 2s - loss: 0.6312 - acc: 0.772 - ETA: 2s - loss: 0.6317 - acc: 0.772 - ETA: 2s - loss: 0.6321 - acc: 0.772 - ETA: 2s - loss: 0.6325 - acc: 0.772 - ETA: 2s - loss: 0.6329 - acc: 0.772 - ETA: 2s - loss: 0.6329 - acc: 0.771 - ETA: 2s - loss: 0.6331 - acc: 0.771 - ETA: 2s - loss: 0.6328 - acc: 0.771 - ETA: 2s - loss: 0.6326 - acc: 0.772 - ETA: 2s - loss: 0.6323 - acc: 0.772 - ETA: 2s - loss: 0.6319 - acc: 0.772 - ETA: 1s - loss: 0.6316 - acc: 0.772 - ETA: 1s - loss: 0.6315 - acc: 0.772 - ETA: 1s - loss: 0.6309 - acc: 0.772 - ETA: 1s - loss: 0.6310 - acc: 0.772 - ETA: 1s - loss: 0.6313 - acc: 0.772 - ETA: 1s - loss: 0.6309 - acc: 0.772 - ETA: 1s - loss: 0.6307 - acc: 0.773 - ETA: 1s - loss: 0.6307 - acc: 0.773 - ETA: 1s - loss: 0.6309 - acc: 0.772 - ETA: 1s - loss: 0.6311 - acc: 0.772 - ETA: 1s - loss: 0.6305 - acc: 0.773 - ETA: 1s - loss: 0.6303 - acc: 0.773 - ETA: 1s - loss: 0.6305 - acc: 0.773 - ETA: 1s - loss: 0.6309 - acc: 0.773 - ETA: 1s - loss: 0.6312 - acc: 0.773 - ETA: 1s - loss: 0.6316 - acc: 0.772 - ETA: 1s - loss: 0.6318 - acc: 0.772 - ETA: 1s - loss: 0.6322 - acc: 0.772 - ETA: 1s - loss: 0.6319 - acc: 0.773 - ETA: 0s - loss: 0.6321 - acc: 0.772 - ETA: 0s - loss: 0.6319 - acc: 0.773 - ETA: 0s - loss: 0.6321 - acc: 0.773 - ETA: 0s - loss: 0.6327 - acc: 0.772 - ETA: 0s - loss: 0.6335 - acc: 0.772 - ETA: 0s - loss: 0.6338 - acc: 0.772 - ETA: 0s - loss: 0.6332 - acc: 0.772 - ETA: 0s - loss: 0.6339 - acc: 0.772 - ETA: 0s - loss: 0.6337 - acc: 0.772 - ETA: 0s - loss: 0.6336 - acc: 0.772 - ETA: 0s - loss: 0.6340 - acc: 0.772 - ETA: 0s - loss: 0.6340 - acc: 0.772 - ETA: 0s - loss: 0.6341 - acc: 0.772 - ETA: 0s - loss: 0.6341 - acc: 0.772 - ETA: 0s - loss: 0.6346 - acc: 0.772 - ETA: 0s - loss: 0.6344 - acc: 0.772 - ETA: 0s - loss: 0.6345 - acc: 0.772 - ETA: 0s - loss: 0.6343 - acc: 0.7723WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "45000/45000 [==============================] - 11s 254us/sample - loss: 0.6344 - acc: 0.7724 - val_loss: 0.7939 - val_acc: 0.7258\n",
      "Epoch 39/40\n",
      "44832/45000 [============================>.] - ETA: 15s - loss: 0.5601 - acc: 0.75 - ETA: 11s - loss: 0.6209 - acc: 0.75 - ETA: 10s - loss: 0.5964 - acc: 0.76 - ETA: 10s - loss: 0.5823 - acc: 0.78 - ETA: 10s - loss: 0.6162 - acc: 0.78 - ETA: 10s - loss: 0.5945 - acc: 0.79 - ETA: 10s - loss: 0.5924 - acc: 0.79 - ETA: 10s - loss: 0.5885 - acc: 0.79 - ETA: 10s - loss: 0.6018 - acc: 0.79 - ETA: 10s - loss: 0.5974 - acc: 0.79 - ETA: 10s - loss: 0.5983 - acc: 0.79 - ETA: 10s - loss: 0.5931 - acc: 0.79 - ETA: 10s - loss: 0.5975 - acc: 0.79 - ETA: 10s - loss: 0.5925 - acc: 0.79 - ETA: 10s - loss: 0.5991 - acc: 0.78 - ETA: 10s - loss: 0.6017 - acc: 0.78 - ETA: 9s - loss: 0.5996 - acc: 0.7898 - ETA: 9s - loss: 0.6069 - acc: 0.786 - ETA: 9s - loss: 0.6094 - acc: 0.784 - ETA: 9s - loss: 0.6118 - acc: 0.785 - ETA: 9s - loss: 0.6103 - acc: 0.786 - ETA: 9s - loss: 0.6064 - acc: 0.787 - ETA: 9s - loss: 0.6019 - acc: 0.789 - ETA: 9s - loss: 0.6028 - acc: 0.789 - ETA: 9s - loss: 0.6026 - acc: 0.789 - ETA: 9s - loss: 0.6023 - acc: 0.790 - ETA: 9s - loss: 0.6031 - acc: 0.789 - ETA: 9s - loss: 0.6036 - acc: 0.788 - ETA: 9s - loss: 0.6051 - acc: 0.788 - ETA: 9s - loss: 0.6078 - acc: 0.786 - ETA: 9s - loss: 0.6103 - acc: 0.785 - ETA: 9s - loss: 0.6096 - acc: 0.785 - ETA: 9s - loss: 0.6112 - acc: 0.784 - ETA: 9s - loss: 0.6149 - acc: 0.783 - ETA: 8s - loss: 0.6145 - acc: 0.784 - ETA: 8s - loss: 0.6149 - acc: 0.783 - ETA: 8s - loss: 0.6147 - acc: 0.784 - ETA: 8s - loss: 0.6147 - acc: 0.784 - ETA: 8s - loss: 0.6144 - acc: 0.784 - ETA: 8s - loss: 0.6145 - acc: 0.783 - ETA: 8s - loss: 0.6158 - acc: 0.783 - ETA: 8s - loss: 0.6158 - acc: 0.783 - ETA: 8s - loss: 0.6192 - acc: 0.781 - ETA: 8s - loss: 0.6201 - acc: 0.781 - ETA: 8s - loss: 0.6213 - acc: 0.780 - ETA: 8s - loss: 0.6193 - acc: 0.781 - ETA: 8s - loss: 0.6188 - acc: 0.781 - ETA: 8s - loss: 0.6203 - acc: 0.781 - ETA: 8s - loss: 0.6193 - acc: 0.781 - ETA: 8s - loss: 0.6202 - acc: 0.781 - ETA: 8s - loss: 0.6213 - acc: 0.780 - ETA: 8s - loss: 0.6240 - acc: 0.779 - ETA: 7s - loss: 0.6230 - acc: 0.779 - ETA: 7s - loss: 0.6225 - acc: 0.779 - ETA: 7s - loss: 0.6250 - acc: 0.779 - ETA: 7s - loss: 0.6253 - acc: 0.778 - ETA: 7s - loss: 0.6268 - acc: 0.778 - ETA: 7s - loss: 0.6282 - acc: 0.777 - ETA: 7s - loss: 0.6279 - acc: 0.777 - ETA: 7s - loss: 0.6263 - acc: 0.778 - ETA: 7s - loss: 0.6256 - acc: 0.778 - ETA: 7s - loss: 0.6256 - acc: 0.778 - ETA: 7s - loss: 0.6246 - acc: 0.778 - ETA: 7s - loss: 0.6240 - acc: 0.778 - ETA: 7s - loss: 0.6243 - acc: 0.778 - ETA: 7s - loss: 0.6257 - acc: 0.777 - ETA: 7s - loss: 0.6247 - acc: 0.778 - ETA: 7s - loss: 0.6255 - acc: 0.777 - ETA: 7s - loss: 0.6250 - acc: 0.777 - ETA: 7s - loss: 0.6240 - acc: 0.778 - ETA: 7s - loss: 0.6229 - acc: 0.778 - ETA: 6s - loss: 0.6220 - acc: 0.778 - ETA: 6s - loss: 0.6219 - acc: 0.778 - ETA: 6s - loss: 0.6224 - acc: 0.778 - ETA: 6s - loss: 0.6241 - acc: 0.778 - ETA: 6s - loss: 0.6249 - acc: 0.777 - ETA: 6s - loss: 0.6244 - acc: 0.777 - ETA: 6s - loss: 0.6258 - acc: 0.777 - ETA: 6s - loss: 0.6265 - acc: 0.776 - ETA: 6s - loss: 0.6267 - acc: 0.776 - ETA: 6s - loss: 0.6267 - acc: 0.776 - ETA: 6s - loss: 0.6263 - acc: 0.776 - ETA: 6s - loss: 0.6267 - acc: 0.775 - ETA: 6s - loss: 0.6277 - acc: 0.775 - ETA: 6s - loss: 0.6278 - acc: 0.775 - ETA: 6s - loss: 0.6274 - acc: 0.775 - ETA: 6s - loss: 0.6276 - acc: 0.775 - ETA: 6s - loss: 0.6283 - acc: 0.775 - ETA: 6s - loss: 0.6267 - acc: 0.775 - ETA: 5s - loss: 0.6263 - acc: 0.776 - ETA: 5s - loss: 0.6255 - acc: 0.776 - ETA: 5s - loss: 0.6261 - acc: 0.776 - ETA: 5s - loss: 0.6257 - acc: 0.776 - ETA: 5s - loss: 0.6261 - acc: 0.776 - ETA: 5s - loss: 0.6269 - acc: 0.776 - ETA: 5s - loss: 0.6262 - acc: 0.776 - ETA: 5s - loss: 0.6263 - acc: 0.776 - ETA: 5s - loss: 0.6271 - acc: 0.776 - ETA: 5s - loss: 0.6279 - acc: 0.776 - ETA: 5s - loss: 0.6287 - acc: 0.776 - ETA: 5s - loss: 0.6286 - acc: 0.776 - ETA: 5s - loss: 0.6288 - acc: 0.776 - ETA: 5s - loss: 0.6290 - acc: 0.775 - ETA: 5s - loss: 0.6286 - acc: 0.776 - ETA: 5s - loss: 0.6285 - acc: 0.776 - ETA: 5s - loss: 0.6284 - acc: 0.776 - ETA: 5s - loss: 0.6284 - acc: 0.776 - ETA: 5s - loss: 0.6278 - acc: 0.776 - ETA: 4s - loss: 0.6273 - acc: 0.776 - ETA: 4s - loss: 0.6283 - acc: 0.776 - ETA: 4s - loss: 0.6279 - acc: 0.776 - ETA: 4s - loss: 0.6284 - acc: 0.775 - ETA: 4s - loss: 0.6287 - acc: 0.775 - ETA: 4s - loss: 0.6281 - acc: 0.776 - ETA: 4s - loss: 0.6283 - acc: 0.775 - ETA: 4s - loss: 0.6281 - acc: 0.776 - ETA: 4s - loss: 0.6285 - acc: 0.776 - ETA: 4s - loss: 0.6295 - acc: 0.776 - ETA: 4s - loss: 0.6300 - acc: 0.775 - ETA: 4s - loss: 0.6302 - acc: 0.775 - ETA: 4s - loss: 0.6304 - acc: 0.775 - ETA: 4s - loss: 0.6304 - acc: 0.776 - ETA: 4s - loss: 0.6298 - acc: 0.776 - ETA: 4s - loss: 0.6298 - acc: 0.776 - ETA: 4s - loss: 0.6307 - acc: 0.776 - ETA: 4s - loss: 0.6303 - acc: 0.776 - ETA: 4s - loss: 0.6300 - acc: 0.776 - ETA: 3s - loss: 0.6303 - acc: 0.776 - ETA: 3s - loss: 0.6299 - acc: 0.776 - ETA: 3s - loss: 0.6303 - acc: 0.776 - ETA: 3s - loss: 0.6305 - acc: 0.776 - ETA: 3s - loss: 0.6303 - acc: 0.776 - ETA: 3s - loss: 0.6307 - acc: 0.776 - ETA: 3s - loss: 0.6317 - acc: 0.776 - ETA: 3s - loss: 0.6313 - acc: 0.776 - ETA: 3s - loss: 0.6328 - acc: 0.775 - ETA: 3s - loss: 0.6325 - acc: 0.775 - ETA: 3s - loss: 0.6319 - acc: 0.775 - ETA: 3s - loss: 0.6329 - acc: 0.775 - ETA: 3s - loss: 0.6324 - acc: 0.775 - ETA: 3s - loss: 0.6327 - acc: 0.775 - ETA: 3s - loss: 0.6327 - acc: 0.775 - ETA: 3s - loss: 0.6332 - acc: 0.775 - ETA: 3s - loss: 0.6331 - acc: 0.775 - ETA: 3s - loss: 0.6323 - acc: 0.775 - ETA: 2s - loss: 0.6331 - acc: 0.775 - ETA: 2s - loss: 0.6328 - acc: 0.775 - ETA: 2s - loss: 0.6323 - acc: 0.775 - ETA: 2s - loss: 0.6324 - acc: 0.775 - ETA: 2s - loss: 0.6326 - acc: 0.775 - ETA: 2s - loss: 0.6327 - acc: 0.775 - ETA: 2s - loss: 0.6319 - acc: 0.775 - ETA: 2s - loss: 0.6313 - acc: 0.775 - ETA: 2s - loss: 0.6319 - acc: 0.775 - ETA: 2s - loss: 0.6318 - acc: 0.775 - ETA: 2s - loss: 0.6319 - acc: 0.775 - ETA: 2s - loss: 0.6314 - acc: 0.775 - ETA: 2s - loss: 0.6313 - acc: 0.776 - ETA: 2s - loss: 0.6314 - acc: 0.775 - ETA: 2s - loss: 0.6317 - acc: 0.775 - ETA: 2s - loss: 0.6314 - acc: 0.775 - ETA: 2s - loss: 0.6323 - acc: 0.775 - ETA: 2s - loss: 0.6322 - acc: 0.775 - ETA: 2s - loss: 0.6324 - acc: 0.775 - ETA: 1s - loss: 0.6321 - acc: 0.775 - ETA: 1s - loss: 0.6327 - acc: 0.774 - ETA: 1s - loss: 0.6326 - acc: 0.775 - ETA: 1s - loss: 0.6328 - acc: 0.774 - ETA: 1s - loss: 0.6331 - acc: 0.774 - ETA: 1s - loss: 0.6326 - acc: 0.775 - ETA: 1s - loss: 0.6326 - acc: 0.774 - ETA: 1s - loss: 0.6324 - acc: 0.775 - ETA: 1s - loss: 0.6332 - acc: 0.775 - ETA: 1s - loss: 0.6331 - acc: 0.775 - ETA: 1s - loss: 0.6331 - acc: 0.775 - ETA: 1s - loss: 0.6325 - acc: 0.775 - ETA: 1s - loss: 0.6323 - acc: 0.775 - ETA: 1s - loss: 0.6324 - acc: 0.775 - ETA: 1s - loss: 0.6324 - acc: 0.775 - ETA: 1s - loss: 0.6321 - acc: 0.775 - ETA: 1s - loss: 0.6318 - acc: 0.775 - ETA: 1s - loss: 0.6312 - acc: 0.775 - ETA: 1s - loss: 0.6311 - acc: 0.775 - ETA: 0s - loss: 0.6316 - acc: 0.775 - ETA: 0s - loss: 0.6316 - acc: 0.775 - ETA: 0s - loss: 0.6318 - acc: 0.775 - ETA: 0s - loss: 0.6314 - acc: 0.775 - ETA: 0s - loss: 0.6325 - acc: 0.775 - ETA: 0s - loss: 0.6324 - acc: 0.775 - ETA: 0s - loss: 0.6322 - acc: 0.775 - ETA: 0s - loss: 0.6325 - acc: 0.775 - ETA: 0s - loss: 0.6322 - acc: 0.775 - ETA: 0s - loss: 0.6326 - acc: 0.775 - ETA: 0s - loss: 0.6328 - acc: 0.774 - ETA: 0s - loss: 0.6330 - acc: 0.774 - ETA: 0s - loss: 0.6325 - acc: 0.775 - ETA: 0s - loss: 0.6324 - acc: 0.775 - ETA: 0s - loss: 0.6331 - acc: 0.775 - ETA: 0s - loss: 0.6328 - acc: 0.775 - ETA: 0s - loss: 0.6331 - acc: 0.774 - ETA: 0s - loss: 0.6331 - acc: 0.7749WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "45000/45000 [==============================] - 11s 253us/sample - loss: 0.6329 - acc: 0.7750 - val_loss: 0.7859 - val_acc: 0.7284\n",
      "Epoch 40/40\n",
      "44832/45000 [============================>.] - ETA: 15s - loss: 0.5300 - acc: 0.78 - ETA: 11s - loss: 0.6368 - acc: 0.74 - ETA: 10s - loss: 0.6750 - acc: 0.74 - ETA: 10s - loss: 0.6499 - acc: 0.75 - ETA: 10s - loss: 0.6145 - acc: 0.77 - ETA: 10s - loss: 0.6361 - acc: 0.76 - ETA: 10s - loss: 0.6398 - acc: 0.77 - ETA: 10s - loss: 0.6387 - acc: 0.77 - ETA: 10s - loss: 0.6383 - acc: 0.77 - ETA: 10s - loss: 0.6587 - acc: 0.76 - ETA: 10s - loss: 0.6564 - acc: 0.76 - ETA: 10s - loss: 0.6512 - acc: 0.76 - ETA: 10s - loss: 0.6422 - acc: 0.77 - ETA: 10s - loss: 0.6391 - acc: 0.77 - ETA: 10s - loss: 0.6407 - acc: 0.77 - ETA: 9s - loss: 0.6287 - acc: 0.7783 - ETA: 9s - loss: 0.6262 - acc: 0.778 - ETA: 9s - loss: 0.6229 - acc: 0.779 - ETA: 9s - loss: 0.6142 - acc: 0.781 - ETA: 9s - loss: 0.6099 - acc: 0.783 - ETA: 9s - loss: 0.6094 - acc: 0.783 - ETA: 9s - loss: 0.6073 - acc: 0.785 - ETA: 9s - loss: 0.6079 - acc: 0.784 - ETA: 9s - loss: 0.6108 - acc: 0.783 - ETA: 9s - loss: 0.6134 - acc: 0.780 - ETA: 9s - loss: 0.6107 - acc: 0.781 - ETA: 9s - loss: 0.6094 - acc: 0.781 - ETA: 9s - loss: 0.6101 - acc: 0.782 - ETA: 9s - loss: 0.6125 - acc: 0.781 - ETA: 9s - loss: 0.6163 - acc: 0.779 - ETA: 9s - loss: 0.6175 - acc: 0.778 - ETA: 9s - loss: 0.6180 - acc: 0.779 - ETA: 9s - loss: 0.6176 - acc: 0.779 - ETA: 9s - loss: 0.6184 - acc: 0.778 - ETA: 8s - loss: 0.6186 - acc: 0.778 - ETA: 8s - loss: 0.6193 - acc: 0.777 - ETA: 8s - loss: 0.6191 - acc: 0.777 - ETA: 8s - loss: 0.6202 - acc: 0.777 - ETA: 8s - loss: 0.6217 - acc: 0.776 - ETA: 8s - loss: 0.6192 - acc: 0.777 - ETA: 8s - loss: 0.6188 - acc: 0.777 - ETA: 8s - loss: 0.6188 - acc: 0.778 - ETA: 8s - loss: 0.6218 - acc: 0.778 - ETA: 8s - loss: 0.6205 - acc: 0.778 - ETA: 8s - loss: 0.6196 - acc: 0.778 - ETA: 8s - loss: 0.6179 - acc: 0.779 - ETA: 8s - loss: 0.6183 - acc: 0.778 - ETA: 8s - loss: 0.6167 - acc: 0.779 - ETA: 8s - loss: 0.6173 - acc: 0.779 - ETA: 8s - loss: 0.6193 - acc: 0.778 - ETA: 8s - loss: 0.6184 - acc: 0.779 - ETA: 8s - loss: 0.6172 - acc: 0.779 - ETA: 7s - loss: 0.6176 - acc: 0.779 - ETA: 7s - loss: 0.6171 - acc: 0.779 - ETA: 7s - loss: 0.6155 - acc: 0.780 - ETA: 7s - loss: 0.6166 - acc: 0.780 - ETA: 7s - loss: 0.6164 - acc: 0.780 - ETA: 7s - loss: 0.6159 - acc: 0.780 - ETA: 7s - loss: 0.6136 - acc: 0.781 - ETA: 7s - loss: 0.6134 - acc: 0.781 - ETA: 7s - loss: 0.6136 - acc: 0.781 - ETA: 7s - loss: 0.6142 - acc: 0.781 - ETA: 7s - loss: 0.6138 - acc: 0.782 - ETA: 7s - loss: 0.6149 - acc: 0.781 - ETA: 7s - loss: 0.6155 - acc: 0.780 - ETA: 7s - loss: 0.6176 - acc: 0.780 - ETA: 7s - loss: 0.6180 - acc: 0.780 - ETA: 7s - loss: 0.6181 - acc: 0.780 - ETA: 7s - loss: 0.6176 - acc: 0.781 - ETA: 7s - loss: 0.6167 - acc: 0.781 - ETA: 6s - loss: 0.6166 - acc: 0.781 - ETA: 6s - loss: 0.6157 - acc: 0.781 - ETA: 6s - loss: 0.6165 - acc: 0.781 - ETA: 6s - loss: 0.6174 - acc: 0.781 - ETA: 6s - loss: 0.6177 - acc: 0.781 - ETA: 6s - loss: 0.6169 - acc: 0.781 - ETA: 6s - loss: 0.6173 - acc: 0.781 - ETA: 6s - loss: 0.6184 - acc: 0.781 - ETA: 6s - loss: 0.6187 - acc: 0.780 - ETA: 6s - loss: 0.6209 - acc: 0.779 - ETA: 6s - loss: 0.6199 - acc: 0.780 - ETA: 6s - loss: 0.6202 - acc: 0.779 - ETA: 6s - loss: 0.6210 - acc: 0.779 - ETA: 6s - loss: 0.6213 - acc: 0.779 - ETA: 6s - loss: 0.6207 - acc: 0.779 - ETA: 6s - loss: 0.6206 - acc: 0.779 - ETA: 6s - loss: 0.6198 - acc: 0.780 - ETA: 6s - loss: 0.6202 - acc: 0.779 - ETA: 6s - loss: 0.6215 - acc: 0.779 - ETA: 5s - loss: 0.6211 - acc: 0.779 - ETA: 5s - loss: 0.6205 - acc: 0.779 - ETA: 5s - loss: 0.6205 - acc: 0.779 - ETA: 5s - loss: 0.6196 - acc: 0.780 - ETA: 5s - loss: 0.6204 - acc: 0.779 - ETA: 5s - loss: 0.6197 - acc: 0.779 - ETA: 5s - loss: 0.6192 - acc: 0.780 - ETA: 5s - loss: 0.6186 - acc: 0.780 - ETA: 5s - loss: 0.6183 - acc: 0.780 - ETA: 5s - loss: 0.6183 - acc: 0.780 - ETA: 5s - loss: 0.6177 - acc: 0.780 - ETA: 5s - loss: 0.6184 - acc: 0.780 - ETA: 5s - loss: 0.6189 - acc: 0.780 - ETA: 5s - loss: 0.6190 - acc: 0.780 - ETA: 5s - loss: 0.6185 - acc: 0.780 - ETA: 5s - loss: 0.6189 - acc: 0.780 - ETA: 5s - loss: 0.6186 - acc: 0.781 - ETA: 5s - loss: 0.6190 - acc: 0.780 - ETA: 4s - loss: 0.6193 - acc: 0.780 - ETA: 4s - loss: 0.6197 - acc: 0.780 - ETA: 4s - loss: 0.6205 - acc: 0.779 - ETA: 4s - loss: 0.6204 - acc: 0.779 - ETA: 4s - loss: 0.6205 - acc: 0.779 - ETA: 4s - loss: 0.6207 - acc: 0.779 - ETA: 4s - loss: 0.6205 - acc: 0.779 - ETA: 4s - loss: 0.6201 - acc: 0.779 - ETA: 4s - loss: 0.6193 - acc: 0.780 - ETA: 4s - loss: 0.6181 - acc: 0.780 - ETA: 4s - loss: 0.6177 - acc: 0.781 - ETA: 4s - loss: 0.6177 - acc: 0.781 - ETA: 4s - loss: 0.6182 - acc: 0.780 - ETA: 4s - loss: 0.6189 - acc: 0.780 - ETA: 4s - loss: 0.6186 - acc: 0.780 - ETA: 4s - loss: 0.6182 - acc: 0.781 - ETA: 4s - loss: 0.6180 - acc: 0.781 - ETA: 4s - loss: 0.6179 - acc: 0.781 - ETA: 4s - loss: 0.6173 - acc: 0.781 - ETA: 3s - loss: 0.6173 - acc: 0.781 - ETA: 3s - loss: 0.6190 - acc: 0.780 - ETA: 3s - loss: 0.6193 - acc: 0.780 - ETA: 3s - loss: 0.6204 - acc: 0.780 - ETA: 3s - loss: 0.6211 - acc: 0.780 - ETA: 3s - loss: 0.6218 - acc: 0.779 - ETA: 3s - loss: 0.6215 - acc: 0.779 - ETA: 3s - loss: 0.6215 - acc: 0.779 - ETA: 3s - loss: 0.6222 - acc: 0.779 - ETA: 3s - loss: 0.6226 - acc: 0.779 - ETA: 3s - loss: 0.6230 - acc: 0.779 - ETA: 3s - loss: 0.6235 - acc: 0.779 - ETA: 3s - loss: 0.6244 - acc: 0.778 - ETA: 3s - loss: 0.6239 - acc: 0.778 - ETA: 3s - loss: 0.6245 - acc: 0.778 - ETA: 3s - loss: 0.6239 - acc: 0.778 - ETA: 3s - loss: 0.6241 - acc: 0.778 - ETA: 3s - loss: 0.6243 - acc: 0.778 - ETA: 3s - loss: 0.6248 - acc: 0.778 - ETA: 2s - loss: 0.6250 - acc: 0.778 - ETA: 2s - loss: 0.6249 - acc: 0.778 - ETA: 2s - loss: 0.6253 - acc: 0.778 - ETA: 2s - loss: 0.6247 - acc: 0.778 - ETA: 2s - loss: 0.6249 - acc: 0.778 - ETA: 2s - loss: 0.6257 - acc: 0.777 - ETA: 2s - loss: 0.6245 - acc: 0.778 - ETA: 2s - loss: 0.6253 - acc: 0.778 - ETA: 2s - loss: 0.6258 - acc: 0.778 - ETA: 2s - loss: 0.6257 - acc: 0.778 - ETA: 2s - loss: 0.6255 - acc: 0.778 - ETA: 2s - loss: 0.6251 - acc: 0.778 - ETA: 2s - loss: 0.6256 - acc: 0.778 - ETA: 2s - loss: 0.6253 - acc: 0.778 - ETA: 2s - loss: 0.6258 - acc: 0.778 - ETA: 2s - loss: 0.6266 - acc: 0.777 - ETA: 2s - loss: 0.6268 - acc: 0.777 - ETA: 2s - loss: 0.6265 - acc: 0.777 - ETA: 2s - loss: 0.6262 - acc: 0.777 - ETA: 1s - loss: 0.6266 - acc: 0.777 - ETA: 1s - loss: 0.6265 - acc: 0.777 - ETA: 1s - loss: 0.6267 - acc: 0.777 - ETA: 1s - loss: 0.6263 - acc: 0.777 - ETA: 1s - loss: 0.6259 - acc: 0.777 - ETA: 1s - loss: 0.6256 - acc: 0.777 - ETA: 1s - loss: 0.6254 - acc: 0.777 - ETA: 1s - loss: 0.6248 - acc: 0.778 - ETA: 1s - loss: 0.6257 - acc: 0.777 - ETA: 1s - loss: 0.6256 - acc: 0.777 - ETA: 1s - loss: 0.6252 - acc: 0.778 - ETA: 1s - loss: 0.6250 - acc: 0.778 - ETA: 1s - loss: 0.6253 - acc: 0.778 - ETA: 1s - loss: 0.6258 - acc: 0.777 - ETA: 1s - loss: 0.6264 - acc: 0.777 - ETA: 1s - loss: 0.6266 - acc: 0.777 - ETA: 1s - loss: 0.6269 - acc: 0.777 - ETA: 1s - loss: 0.6273 - acc: 0.776 - ETA: 0s - loss: 0.6263 - acc: 0.777 - ETA: 0s - loss: 0.6265 - acc: 0.777 - ETA: 0s - loss: 0.6261 - acc: 0.777 - ETA: 0s - loss: 0.6266 - acc: 0.777 - ETA: 0s - loss: 0.6268 - acc: 0.777 - ETA: 0s - loss: 0.6266 - acc: 0.777 - ETA: 0s - loss: 0.6271 - acc: 0.777 - ETA: 0s - loss: 0.6271 - acc: 0.777 - ETA: 0s - loss: 0.6273 - acc: 0.777 - ETA: 0s - loss: 0.6273 - acc: 0.777 - ETA: 0s - loss: 0.6276 - acc: 0.776 - ETA: 0s - loss: 0.6273 - acc: 0.777 - ETA: 0s - loss: 0.6272 - acc: 0.776 - ETA: 0s - loss: 0.6273 - acc: 0.776 - ETA: 0s - loss: 0.6271 - acc: 0.777 - ETA: 0s - loss: 0.6268 - acc: 0.777 - ETA: 0s - loss: 0.6274 - acc: 0.777 - ETA: 0s - loss: 0.6278 - acc: 0.776 - ETA: 0s - loss: 0.6287 - acc: 0.7765WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "45000/45000 [==============================] - 11s 252us/sample - loss: 0.6282 - acc: 0.7767 - val_loss: 0.7606 - val_acc: 0.7342\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Objective value missing in metrics reported to the Oracle, expected: ['val_accuracy'], found: dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-188ed0adb1ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_hyper_parameter_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-a69bd8d499e6>\u001b[0m in \u001b[0;36mrun_hyper_parameter_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtuner\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuners\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0melapsed_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Elapsed time = {elapsed_time:10.4f} s, accuracy = {accuracy}, loss = {loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melapsed_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-1873ed73965a>\u001b[0m in \u001b[0;36mtuner_evaluation\u001b[0;34m(tuner, x_test, x_train, y_test, y_train)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start hyperparameter tuning\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msearch_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_EPOCH_SEARCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0msearch_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_end\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msearch_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/kerastuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/kerastuner/engine/multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0maveraged_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecution_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         self.oracle.update_trial(\n\u001b[0;32m--> 109\u001b[0;31m             trial.trial_id, metrics=averaged_metrics, step=self._reported_step)\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_configure_tensorboard_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/kerastuner/engine/oracle.py\u001b[0m in \u001b[0;36mupdate_trial\u001b[0;34m(self, trial_id, metrics, step)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \"\"\"\n\u001b[1;32m    183\u001b[0m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_objective_found\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/kerastuner/engine/oracle.py\u001b[0m in \u001b[0;36m_check_objective_found\u001b[0;34m(self, metrics)\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;34m'Objective value missing in metrics reported to the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                 'Oracle, expected: {}, found: {}'.format(\n\u001b[0;32m--> 353\u001b[0;31m                     objective_names, metrics.keys()))\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_trial_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Objective value missing in metrics reported to the Oracle, expected: ['val_accuracy'], found: dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
     ]
    }
   ],
   "source": [
    "run_hyper_parameter_training()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import setGPU\n",
    "\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "from data_reading import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obj = public_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = data_obj.load_mnist()\n",
    "img_size = x_train.shape[1]\n",
    "input_shape = (img_size, img_size, 1)\n",
    "batch_size = 128\n",
    "kernel_size = 3\n",
    "filters = 16\n",
    "latent_dim = 2\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reparameterization trick\n",
    "#instead of sampling from Q(z/x), sample eps = N(0, I)\n",
    "#then z = z_mean+sqrt(var)*eps\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = tf.keras.backend.shape(z_mean)[0]\n",
    "    dim = tf.keras.backend.int_shape(z_mean)[1]\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(batch,dim))\n",
    "    return z_mean + tf.keras.backend.exp(0.5*z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vuu/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#VAE model = encoder + decoder\n",
    "#build encoder model\n",
    "inputs = tf.keras.layers.Input(shape=input_shape, name='encoder_input')\n",
    "x = inputs\n",
    "for i in range(2):\n",
    "    filters *=2\n",
    "    x = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(x)\n",
    "    \n",
    "shape = tf.keras.backend.int_shape(x)\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
    "z_mean = tf.keras.layers.Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = tf.keras.layers.Dense(latent_dim, name='z_log_var')(x)\n",
    "z = tf.keras.layers.Lambda(sampling, output_shape=(latent_dim, ), name='z')([z_mean, z_log_var])\n",
    "\n",
    "encoder = tf.keras.models.Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "#encoder.summary()\n",
    "#plot_model(encoder, to_file='../model/vae_mnist/vae_cnn_encoder.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build decoder model\n",
    "latent_inputs = tf.keras.layers.Input(shape=(latent_dim, ), name='z_sampling')\n",
    "x = tf.keras.layers.Dense(shape[1]*shape[2]*shape[3], activation='relu')(latent_inputs)\n",
    "x = tf.keras.layers.Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "\n",
    "for i in range(2):\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters=filters, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(x)\n",
    "    filters //= 2\n",
    "    \n",
    "outputs = tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=kernel_size, activation='sigmoid', padding='same', name='decoder_output')(x)\n",
    "\n",
    "decoder = tf.keras.models.Model(latent_inputs, outputs, name='decoder')\n",
    "#decoder.summary()\n",
    "#plot_model(decoder, to_file='../model/vae_mnist/vae_cnn_decoder.png', show_shapes=True)\n",
    "\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = tf.keras.models.Model(inputs, outputs, name='vae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = (encoder, decoder)\n",
    "data = (x_test, y_test)\n",
    "\n",
    "val_mse = True\n",
    "\n",
    "if val_mse:\n",
    "    reconstruction_loss = tf.keras.losses.mse(tf.keras.backend.flatten(inputs), tf.keras.backend.flatten(outputs))\n",
    "else:\n",
    "    reconstruction_loss = tf.keras.losses.binary_crossentropy(tf.keras.backend.flatten(inputs), tf.keras.backend.flatten())\n",
    "    \n",
    "reconstruction_loss *= img_size*img_size\n",
    "kl_loss = 1 + z_log_var - tf.keras.backend.square(z_mean) - tf.keras.backend.exp(z_log_var)\n",
    "kl_loss = tf.keras.backend.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = tf.keras.backend.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='rmsprop')\n",
    "#vae.summary()\n",
    "#plot_model(vae, to_file='../model/vae_mnist/vae_cnn.png', show_shapes=True)\n",
    "\n",
    "vae.fit(x_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, None))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

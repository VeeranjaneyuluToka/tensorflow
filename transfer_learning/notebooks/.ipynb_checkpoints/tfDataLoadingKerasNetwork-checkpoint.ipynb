{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU: Setting GPU to: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vuu/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/vuu/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/vuu/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/vuu/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/vuu/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/vuu/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/vuu/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/vuu/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/vuu/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/vuu/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/vuu/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/vuu/anaconda3/envs/tfpy3_exp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import setGPU\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16949033818433704111\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13798967128644991299\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10813738189\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3313777990042199390\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:b3:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 477417605264542908\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#print(tf.config.experimental.list_physical_devices('GPU'))\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_BATCH_SIZE = 128\n",
    "_EPOCHS = 50\n",
    "_NUM_CLASSES = 76\n",
    "img_width, img_height = 299, 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_valid_lists(train_path, valid_path):\n",
    "        train_files = []\n",
    "        train_labels = []\n",
    "        \n",
    "        #generating lists of train dataset\n",
    "        for title in os.listdir(train_path):\n",
    "            title_path = train_path + title\n",
    "            for fname in os.listdir(title_path):\n",
    "                file_path = title_path + '/' + fname\n",
    "                train_files.append(file_path)\n",
    "                title = int(title)\n",
    "                train_labels.append(title)\n",
    "                \n",
    "        #generating lists of validation dataset\n",
    "        valid_files = []\n",
    "        valid_labels = []\n",
    "        for title in os.listdir(valid_path):\n",
    "            title_path = valid_path + title\n",
    "            for fname in os.listdir(title_path):\n",
    "                file_path = title_path + '/' + fname\n",
    "                valid_files.append(file_path)\n",
    "                title = int(title)\n",
    "                valid_labels.append(title)\n",
    "                \n",
    "        return (train_files, train_labels), (valid_files, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_label_index(labels):\n",
    "    init_label = labels[0]\n",
    "    label_index = 1\n",
    "    label_index_list = []\n",
    "    #title_to_index_map = {}\n",
    "    for label in labels:\n",
    "        if label != init_label:\n",
    "            init_label = label\n",
    "            label_index += 1\n",
    "        label_index_list.append(label_index)\n",
    "        #title_to_index_mapappend=(dict(label, label_index))\n",
    "            \n",
    "    return label_index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data info: 66194 66194 <class 'str'> <class 'int'>\n",
      "valid data info: 19330 19330\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate file names of training and validation as lists\n",
    "\"\"\"\n",
    "train_path = '../../../data/movie_titles/mini_data/train/'\n",
    "valid_path = '../../../data/movie_titles/mini_data/validation/'\n",
    "\n",
    "(train_files, train_labels), (valid_files, valid_labels) = generate_train_valid_lists(train_path, valid_path)\n",
    "len_train_samples = len(train_files)\n",
    "len_valid_samples = len(valid_files)\n",
    "print(\"train data info:\", len(train_files), len(train_labels), type(train_files[0]), type(train_labels[0]))\n",
    "print(\"valid data info:\", len(valid_files), len(valid_labels))\n",
    "\n",
    "\"\"\"\n",
    "Map train and validation labels to 1 to 76 range from title names\n",
    "\"\"\"\n",
    "train_label_in_classes_range = generate_label_index(train_labels)\n",
    "valid_label_in_classes_range = generate_label_index(valid_labels)\n",
    "#print(train_label_in_classes_range[:100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, ?)\n",
      "<dtype: 'uint8'>\n",
      "(299, 299, ?)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Experimenting range values with single image\n",
    "\"\"\"\n",
    "img_raw = tf.io.read_file(train_files[0])\n",
    "img_tensor = tf.image.decode_jpeg(img_raw)\n",
    "print(img_tensor.shape)\n",
    "print(img_tensor.dtype)\n",
    "img_final = tf.image.resize_images(img_tensor, [img_width, img_height])\n",
    "#img_final = tf.image.convert_image_dtype(img_final, tf.float32)\n",
    "#img_final /= 255.0\n",
    "#img_final = 2*(img_final/255.0)-1.0\n",
    "img_final = tf.keras.applications.inception_v3.preprocess_input(img_final)\n",
    "print(img_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_image(image, label):\n",
    "    img_string = tf.read_file(image)\n",
    "    img_decoded = tf.image.decode_jpeg(img_string, channels=3)\n",
    "    resized_img = tf.image.resize_images(img_decoded, [img_width, img_height])\n",
    "    img_final = tf.keras.applications.inception_v3.preprocess_input(resized_img)\n",
    "    label = tf.one_hot(tf.cast(label, tf.uint8), _NUM_CLASSES)\n",
    "    return img_final, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_images(image):\n",
    "    img_string = tf.read_file(image)\n",
    "    img_decoded = tf.image.decode_jpeg(img_string, channels=3)\n",
    "    resized_img = tf.image.resize_images(img_decoded, [img_width, img_height])\n",
    "    img_final = tf.image.convert_image_dtype(resized_img, tf.float32)\n",
    "    img_final = tf.keras.applications.inception_v3.preprocess_input(img_final)\n",
    "    return img_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocess_from_path_label(path, label):\n",
    "    label = tf.one_hot(tf.cast(label, tf.uint8), _NUM_CLASSES)\n",
    "    return _load_images(path), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "dataset.__iter__() is only supported when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7ee64b13ac64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m#plt.subplot(2, 2, n+1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#plt.imshow(image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dell/anaconda3/envs/pwcnet_test/lib/python2.7/site-packages/tensorflow/python/data/ops/dataset_ops.pyc\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m       raise RuntimeError(\"dataset.__iter__() is only supported when eager \"\n\u001b[0m\u001b[1;32m    168\u001b[0m                          \"execution is enabled.\")\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dataset.__iter__() is only supported when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "viewing a couple of image on train dataset and verify them\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "path_ds = tf.data.Dataset.from_tensor_slices((train_files, train_label_in_classes_range))\n",
    "#path_ds = tf.data.Dataset.from_tensor_slices(train_files)\n",
    "image_ds = path_ds.map(_load_image, num_parallel_calls=4)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "for n, image in enumerate(image_ds.take(4)):\n",
    "    #plt.subplot(2, 2, n+1)\n",
    "    #plt.imshow(image)\n",
    "    print(image[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_img_and_label():\n",
    "    len_img = len(train_files)\n",
    "    len_lab = len(train_labels)\n",
    "    \n",
    "    #print(len_img, len_lab)\n",
    "    \n",
    "    for i in range(0, len_img):\n",
    "        if not str(int(train_labels[i])) in train_files[i]:\n",
    "            print(train_labels[i], train_files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Display image path and associated label\n",
    "\"\"\"\n",
    "display_img_and_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_1:0\", shape=(38000,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#create tf tensors of list of files\n",
    "\n",
    "train_files_tensor = tf.constant(train_files)\n",
    "#train_labels_tensor = tf.constant(train_labels, dtype=tf.float32)\n",
    "train_labels_tensor = tf.constant(train_label_in_classes_range)\n",
    "print(train_labels_tensor)\n",
    "\n",
    "valid_files_tensor = tf.constant(valid_files)\n",
    "#valid_labels_tensor = tf.constant(valid_labels)\n",
    "valid_labels_tensor = tf.constant(valid_label_in_classes_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfdata_generator(images, labels, is_training=True, batch_size=64):\n",
    "       \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    if is_training:\n",
    "        dataset = dataset.shuffle(len_train_samples) #depends on sample size\n",
    "        \n",
    "    #dataset = dataset.apply(tf.data.experimental.map_and_batch(_load_image, batch_size, num_parallel_batches=4, drop_remainder=True if is_training else False))\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.map(load_preprocess_from_path_label, num_parallel_calls=4)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.contrib.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_model(img_shape, is_inception=True):\n",
    "    if is_inception:\n",
    "        conv_base_model = tf.keras.applications.InceptionV3(input_shape=img_shape, include_top=False, weights='imagenet')\n",
    "    else:\n",
    "        conv_base_model = tf.keras.applications.VGG16(input_shape=img_shape, include_top=False, weights='imagenet')\n",
    "        \n",
    "    #conv_base_model.summary()\n",
    "    \n",
    "    return conv_base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_pipeline():\n",
    "    train_set = tfdata_generator(train_files_tensor, train_labels_tensor, is_training=True, batch_size=_BATCH_SIZE)\n",
    "    valid_set = tfdata_generator(valid_files_tensor, valid_labels_tensor, is_training=False, batch_size=_BATCH_SIZE)\n",
    "    #print(train_set)\n",
    "    #print(valid_set)\n",
    "    \n",
    "    img_shape = (img_width, img_height, 3)\n",
    "    base_model = get_base_model(img_shape)\n",
    "    \n",
    "    head_model = base_model.output\n",
    "    head_model = tf.keras.layers.Flatten(name='flatten')(head_model)\n",
    "    head_model = tf.keras.layers.Dense(1024, activation='relu', name='dense1')(head_model)\n",
    "    head_model = tf.keras.layers.Dense(512, activation ='relu', name='dense2')(head_model)\n",
    "    head_model = tf.keras.layers.Dense(128, activation='relu', name='dense3')(head_model)\n",
    "    head_model = tf.keras.layers.Dense(_NUM_CLASSES, activation='softmax', name='final_predictions')(head_model)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=base_model.inputs, outputs=head_model)\n",
    "    print(len(model.trainable_variables))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    print(len(model.trainable_variables))\n",
    "    #model.summary()\n",
    "\n",
    "    #model.compile(optimizer=tf.train.AdamOptimizer(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    \"\"\"\n",
    "    iterator = train_set.make_one_shot_iterator()\n",
    "    images, labels = iterator.get_next()\n",
    "    \n",
    "    iterator_v = valid_set.make_one_shot_iterator()\n",
    "    v_images, v_labels = iterator_v.get_next()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        imgs = sess.run(images)\n",
    "        labls = sess.run(labels)\n",
    "        print(imgs.shape, labls.shape)\n",
    "        \n",
    "        v_imgs = sess.run(v_images)\n",
    "        v_lbls = sess.run(v_labels)\n",
    "        print(v_imgs.shape, v_lbls.shape)\"\"\"\n",
    "    \n",
    "    #model.fit(train_set.make_one_shot_iterator(), steps_per_epoch=len_train_samples //_BATCH_SIZE, epochs=_EPOCHS, validation_data=valid_set.make_one_shot_iterator(), \n",
    "    #          validation_steps=len_valid_samples //_BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "training_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
